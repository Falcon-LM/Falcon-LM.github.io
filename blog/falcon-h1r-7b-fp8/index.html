<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><script>!function(e,t){if(!e.rdt){var s,o,n=e.rdt=function(){n.sendEvent?n.sendEvent.apply(n,arguments):n.callQueue.push(arguments)};n.callQueue=[],s=t.createElement("script"),s.src="https://www.redditstatic.com/ads/pixel.js",s.async=!0,o=t.getElementsByTagName("script")[0],o.parentNode.insertBefore(s,o)}}(window,document),rdt("init","a2_f0we4sxffrnm"),rdt("track","PageVisit")</script><script async src="https://www.googletagmanager.com/gtag/js?id=AW-16575356988"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","AW-16575356988")</script><title>Falcon‑H1R-FP8: Accelerating Inference with Quantized Precision | Falcon</title>
<meta name=keywords content><meta name=description content="Falcon CHAT
Hugging Face
DISCORD
Introducing Falcon H1R 7B FP8, a fully quantized version of the Falcon H1R 7B model that packs both weights and activations into FP8 format. Using NVIDIA Model Optimizer and post-training quantization (PTQ) workflow, the FP8 quantized model preserves the original BF16 quality performance while delivering a 1.2×–1.5× throughput boost and halving GPU memory footprint.
Evaluations
The FP8 variant retains essentially the same accuracy as BF16 across all three major reasoning tasks: AIME25 drops only 0.8 % (from 83.1 % to 82.3 %), LCB‑v6 falls by 1 % (68.6 % → 67.6 %), and GPQA‑D shows a negligible 0.1 % difference (61.3 % → 61.2 %). These results confirm that the FP8 PTQ preserves benchmark performance while delivering substantial memory and throughput gains."><meta name=author content="Falcon Team"><link rel=canonical href=https://falcon-lm.github.io/blog/falcon-h1r-7b-fp8/><link crossorigin=anonymous href=/assets/css/stylesheet.8b9fa41d05770f933657a6befdf3e59416a8572dcdccb2def3ee65a2976037d3.css integrity="sha256-i5+kHQV3D5M2V6a+/fPllBaoVy3NzLLe8+5lopdgN9M=" rel="preload stylesheet" as=style><link rel=icon href=https://falcon-lm.github.io/img/favicon.png><link rel=apple-touch-icon href=https://falcon-lm.github.io/img/favicon.png><link rel=manifest href=https://falcon-lm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate hreflang=en href=https://falcon-lm.github.io/blog/falcon-h1r-7b-fp8/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.c0c4976150cc57e4e574f010d054d68896d28645b524650723d1cbb26891c0a3.js integrity="sha256-wMSXYVDMV+TldPAQ0FTWiJbShkW1JGUHI9HLsmiRwKM="></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-5PVYBMYHS6"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-5PVYBMYHS6")}</script><meta property="og:title" content="Falcon‑H1R-FP8: Accelerating Inference with Quantized Precision"><meta property="og:description" content="Falcon CHAT
Hugging Face
DISCORD
Introducing Falcon H1R 7B FP8, a fully quantized version of the Falcon H1R 7B model that packs both weights and activations into FP8 format. Using NVIDIA Model Optimizer and post-training quantization (PTQ) workflow, the FP8 quantized model preserves the original BF16 quality performance while delivering a 1.2×–1.5× throughput boost and halving GPU memory footprint.
Evaluations
The FP8 variant retains essentially the same accuracy as BF16 across all three major reasoning tasks: AIME25 drops only 0.8 % (from 83.1 % to 82.3 %), LCB‑v6 falls by 1 % (68.6 % → 67.6 %), and GPQA‑D shows a negligible 0.1 % difference (61.3 % → 61.2 %). These results confirm that the FP8 PTQ preserves benchmark performance while delivering substantial memory and throughput gains."><meta property="og:type" content="article"><meta property="og:url" content="https://falcon-lm.github.io/blog/falcon-h1r-7b-fp8/"><meta property="og:image" content="https://falcon-lm.github.io/blog/falcon-h1r-7b-fp8/cover.png"><meta property="article:section" content="blog"><meta property="article:published_time" content="2026-02-04T08:00:00+00:00"><meta property="article:modified_time" content="2026-02-04T08:00:00+00:00"><meta property="og:site_name" content="Falcon"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://falcon-lm.github.io/blog/falcon-h1r-7b-fp8/cover.png"><meta name=twitter:title content="Falcon‑H1R-FP8: Accelerating Inference with Quantized Precision"><meta name=twitter:description content="Falcon CHAT
Hugging Face
DISCORD
Introducing Falcon H1R 7B FP8, a fully quantized version of the Falcon H1R 7B model that packs both weights and activations into FP8 format. Using NVIDIA Model Optimizer and post-training quantization (PTQ) workflow, the FP8 quantized model preserves the original BF16 quality performance while delivering a 1.2×–1.5× throughput boost and halving GPU memory footprint.
Evaluations
The FP8 variant retains essentially the same accuracy as BF16 across all three major reasoning tasks: AIME25 drops only 0.8 % (from 83.1 % to 82.3 %), LCB‑v6 falls by 1 % (68.6 % → 67.6 %), and GPQA‑D shows a negligible 0.1 % difference (61.3 % → 61.2 %). These results confirm that the FP8 PTQ preserves benchmark performance while delivering substantial memory and throughput gains."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://falcon-lm.github.io/blog/"},{"@type":"ListItem","position":2,"name":"Falcon‑H1R-FP8: Accelerating Inference with Quantized Precision","item":"https://falcon-lm.github.io/blog/falcon-h1r-7b-fp8/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Falcon‑H1R-FP8: Accelerating Inference with Quantized Precision","name":"Falcon‑H1R-FP8: Accelerating Inference with Quantized Precision","description":"Falcon CHAT Hugging Face DISCORD\nIntroducing Falcon H1R 7B FP8, a fully quantized version of the Falcon H1R 7B model that packs both weights and activations into FP8 format. Using NVIDIA Model Optimizer and post-training quantization (PTQ) workflow, the FP8 quantized model preserves the original BF16 quality performance while delivering a 1.2×–1.5× throughput boost and halving GPU memory footprint.\nEvaluations The FP8 variant retains essentially the same accuracy as BF16 across all three major reasoning tasks: AIME25 drops only 0.8 % (from 83.1 % to 82.3 %), LCB‑v6 falls by 1 % (68.6 % → 67.6 %), and GPQA‑D shows a negligible 0.1 % difference (61.3 % → 61.2 %). These results confirm that the FP8 PTQ preserves benchmark performance while delivering substantial memory and throughput gains.\n","keywords":[],"articleBody":"Falcon CHAT Hugging Face DISCORD\nIntroducing Falcon H1R 7B FP8, a fully quantized version of the Falcon H1R 7B model that packs both weights and activations into FP8 format. Using NVIDIA Model Optimizer and post-training quantization (PTQ) workflow, the FP8 quantized model preserves the original BF16 quality performance while delivering a 1.2×–1.5× throughput boost and halving GPU memory footprint.\nEvaluations The FP8 variant retains essentially the same accuracy as BF16 across all three major reasoning tasks: AIME25 drops only 0.8 % (from 83.1 % to 82.3 %), LCB‑v6 falls by 1 % (68.6 % → 67.6 %), and GPQA‑D shows a negligible 0.1 % difference (61.3 % → 61.2 %). These results confirm that the FP8 PTQ preserves benchmark performance while delivering substantial memory and throughput gains.\nUnder the DeepConf test‑time filtering regime (5 repetitions, 128 rollouts per prompt), Falcon H1R 7B FP8 attains 89.3 % accuracy on AIME 2025 and 94.0 % on AIME 2024, compared to 91.3 % and 95.3 % for the BF16 baseline. The modest 1–2 % drop confirms that FP8 quantization preserves the model’s reasoning performance while still benefiting from DeepConf’s efficient trace pruning.\nInference profiling Memory Falcon H1R 7B FP8 cuts the weight memory footprint from 14.2 GB to just 7.9 GB, a reduction of roughly 44 % that enables deployment on GPUs with lower VRAM while preserving the model’s performance.\nOffline inference benchmarking Inference was benchmarked using offline vLLM on a single NVIDIA H100 GPU.\nThroughput The plot below shows that Falcon H1R 7B FP8 consistently outperforms its BF16 counterpart across all batch sizes.\nFor the Input = 512 / Output = 8k workload, FP8 yields a 20–22 % speed‑up (≈1.2×) over BF16, reaching 2682 tokens/s/GPU at a batch size of 32. For the Input = 8k / Output = 8k workload, the improvement grows to 24–31 % (≈1.3×), achieving 2220 tokens/s/GPU at a batch size of 32. Online inference benchmarking To conduct the online serving performance analysis, we utilized NVIDIA AIPerf. AIPerf is a client-side generative AI benchmarking tool that supports any inference service conforming to the OpenAI API specification. It is designed to capture critical performance metrics including Time to First Token (TTFT), Inter-Token Latency (ITL), and overall throughput.\nModels were served using online vLLM with 1k input tokens and 1k output tokens across various concurrency levels. All performance numbers are measured on a single NVIDIA H200 GPU.\nGPU Efficiency vs User Experience This chart illustrates the trade-off between total output throughput (tokens/sec) and per-user throughput (tokens/sec/user) across different concurrency levels. As concurrency increases, total throughput grows but per-user experience degrades. FP8 maintains higher throughput on both axes, demonstrating superior efficiency.\nKey Performance Improvements:\nOutput Throughput: FP8 achieves up to 12.7% higher output token throughput at concurrency 64 (4543.5 vs 4030.9 tokens/sec) Per-User Throughput: FP8 delivers 20% better tokens/sec per user at low concurrency (188.7 vs 156.7 at concurrency 1) P50 Inter-Token Latency This chart shows the median (P50) time between consecutive tokens at different concurrency levels. Lower latency means faster token generation. FP8 maintains consistently lower P50 latency across all concurrency levels, with ~11% improvement at concurrency 64 (13ms vs 14.6ms)\nTime to First Token (TTFT) This chart measures the average time until the first token is generated after receiving a request. Lower TTFT is critical for perceived responsiveness. FP8 reduces TTFT by up to 28% at high concurrency (686.2ms vs 954.3ms at concurrency 64), significantly improving user experience.\nFP8 Post-Training Quantization Process with NVIDIA Model Optimizer This section details the optimization of Falcon-H1R-7B’s inference performance through FP8 Post-Training Quantization (PTQ). To achieve this, we utilized NVIDIA Model Optimizer (ModelOpt), an open-sourced unified library designed to accelerate AI inference by compressing models using state-of-the-art optimization techniques. ModelOpt is an essential toolkit for efficient downstream deployment on NVIDIA hardware compatible with frameworks such as vLLM, TensorRT-LLM, SGLang and Dynamo.\nWhile ModelOpt supports various optimization strategies such as structured pruning and knowledge distillation, we focused specifically on PTQ, which offers the fastest path to model optimization by compressing weights from higher precisions (like FP16 or BF16) down to FP8 using a small calibration dataset. This conversion significantly reduces the model’s size and computational requirement, enabling higher inference throughput and reduced latency.\nPer‑Tensor FP8 Post‑Training Quantization ModelOpt supports FP8 recipes with different granularities balancing inference performance and model accuracy preservation. For this specific implementation, we employed Per-Tensor FP8 quantization, a technique where a single scaling factor is calculated for an entire tensor to map high-precision values into the 8-bit format. To generate these scales, ModelOpt executes a calibration step using either a public dataset or a custom dataset. To quantize Falcon-H1R-7B, the team used the default calibration dataset comprising of cnn_dailymail and nemotron-post-training-dataset-v2. During this process, ModelOpt analyzes the dynamic range of activations and weights to determine the optimal static scaling factors that minimize accuracy degradation. The final output is a quantized checkpoint containing the FP8 weights and the scaling factors for weights and activations, ready to be built into an inference engine for efficient deployment.\nQuantization Steps We started from our pre-trained checkpoint and applied per-tensor FP8 quantization using ModelOpt’s LLM quantization pipeline steps. In addition, we also quantize the KV cache to FP8 in order to save more memory footprint.\nEnvironment Setup # Start from a vLLM-enabled Docker image docker run --gpus all -it vllm/vllm-openai:latest # Clone NVIDIA Model Optimizer git clone https://github.com/NVIDIA/Model-Optimizer.git cd Model-Optimizer # Checkout to the most recent stable branch git checkout 0.39.0 # Install Model Optimizer with development dependencies pip install -e .[dev] # Navigate to the LLM PTQ example directory cd examples/llm_ptq Applying FP8 Post-Training Quantization We can directly apply FP8 quantization on Falcon-H1R-7B model using:\npython3 hf_ptq.py \\ --pyt_ckpt_path=/path/to/your/hf/checkpoint/ \\ --export_path=/path/to/save/fp8_quantized_model/ \\ --qformat=fp8 \\ --kv_cache_qformat=fp8 \\ --calib_size=512 \\ --batch_size=0 \\ --inference_tensor_parallel=1 \\ --inference_pipeline_parallel=1 \\ --export_fmt=hf \\ --trust_remote_code Key flags of the FP8 quantization process:\n--qformat=fp8: applies per-tensor FP8 quantization to all model weights --kv_cache_qformat=fp8: quantizes the KV cache to FP8 --calib_size=512: selects the samples to pass for the scales calibration, usually 512 are enough --batch_size=0: automatically find the maximum batch size --inference_tensor_parallel \u0026 --inference_pipeline_parallel: can be tuned if your model doesn’t fit in 1 GPU for the calibration process Conclusion Falcon H1R 7B FP8 preserves BF16 accuracy while cutting weight memory to 7.9 GB (≈44 %) and boosting throughput by ~20–30 % on H100/H200 GPUs. It therefore enables high‑scale, low‑VRAM inference without sacrificing performance.\nCitation @article{falcon-h1r-fp8, title={Falcon H1R 7B FP8}, author={TII and NVIDIA}, url={https://falcon-lm.github.io/blog/falcon-h1r-7b-fp8}, year={2026} } ","wordCount":"1071","inLanguage":"en","image":"https://falcon-lm.github.io/blog/falcon-h1r-7b-fp8/cover.png","datePublished":"2026-02-04T08:00:00Z","dateModified":"2026-02-04T08:00:00Z","author":{"@type":"Person","name":"Falcon Team"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://falcon-lm.github.io/blog/falcon-h1r-7b-fp8/"},"publisher":{"@type":"Organization","name":"Falcon","logo":{"@type":"ImageObject","url":"https://falcon-lm.github.io/img/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!0</script><header class=header><div class="nav-container nav-background"><nav class=nav><div class=logo><a href=/ accesskey=h title="Falcon (Alt + H)"><img src=https://falcon-lm.github.io/img/logo.svg alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://chat.falconllm.tii.ae/ title="Try Falcon Chat"><span>Try Falcon Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero-background style="background:url(cover.png)50%/cover no-repeat fixed"></div><div class=hero-gradient></div><div class=hero-blur></div><div class="hero text-light"><h1 class=post-title>Falcon‑H1R-FP8: Accelerating Inference with Quantized Precision</h1><div class=post-meta><span title='2026-02-04 08:00:00 +0000 UTC'>February 4, 2026</span>&nbsp;•&nbsp;6 min&nbsp;•&nbsp;1071 words&nbsp;•&nbsp;Falcon Team</div></div></div><main class=main><article class=post-single><figure class=entry-cover><a href=/blog/falcon-h1r-7b-fp8/cover.png target=_blank rel="noopener noreferrer"><img loading=lazy srcset="https://falcon-lm.github.io/blog/falcon-h1r-7b-fp8/cover_hu_b2187d2813f1ec5a.png 360w ,https://falcon-lm.github.io/blog/falcon-h1r-7b-fp8/cover_hu_492824bae6421e7d.png 480w ,https://falcon-lm.github.io/blog/falcon-h1r-7b-fp8/cover_hu_ee44aa23d66f0dbc.png 720w ,https://falcon-lm.github.io/blog/falcon-h1r-7b-fp8/cover_hu_6b2d212677a7532e.png 1080w ,https://falcon-lm.github.io/blog/falcon-h1r-7b-fp8/cover_hu_325949197b86f59e.png 1500w ,https://falcon-lm.github.io/blog/falcon-h1r-7b-fp8/cover.png 2788w" sizes="(min-width: 768px) 720px, 100vw" src=https://falcon-lm.github.io/blog/falcon-h1r-7b-fp8/cover.png alt width=2788 height=1317></a></figure><div class=post-content><p><a href=https://chat.falconllm.tii.ae class="btn external" target=_blank>Falcon CHAT</a>
<a href=https://huggingface.co/collections/tiiuae/falcon-h1r class="btn external" target=_blank>Hugging Face</a>
<a href=https://discord.gg/Cbek57PrZE class="btn external" target=_blank>DISCORD</a></p><p>Introducing <span class=bold><a href=https://huggingface.co/tiiuae/Falcon-H1R-7B-FP8>Falcon H1R 7B FP8</a></span>, a fully quantized version of the <a href=https://huggingface.co/tiiuae/Falcon-H1R-7B>Falcon H1R 7B</a> model that packs both weights and activations into FP8 format. Using <a href=https://github.com/NVIDIA/Model-Optimizer>NVIDIA Model Optimizer</a> and post-training quantization (PTQ) workflow, the FP8 quantized model preserves the original BF16 quality performance while delivering a 1.2×–1.5× throughput boost and halving GPU memory footprint.</p><h1 id=evaluations>Evaluations<a hidden class=anchor aria-hidden=true href=#evaluations>#</a></h1><p>The FP8 variant retains essentially the same accuracy as BF16 across all three major reasoning tasks: AIME25 drops only 0.8 % (from 83.1 % to 82.3 %), LCB‑v6 falls by 1 % (68.6 % → 67.6 %), and GPQA‑D shows a negligible 0.1 % difference (61.3 % → 61.2 %). These results confirm that the FP8 PTQ preserves benchmark performance while delivering substantial memory and throughput gains.</p><div id=chart-benchs></div><script src=https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js></script><script>(function(){let n;try{n=JSON.parse(`
[
    { "category": "AIME25", "model": "BF16", "value": 0.831 },
    { "category": "AIME25", "model": "FP8", "value": 0.823 },

    { "category": "LCB v6", "model": "BF16", "value": 0.686 },
    { "category": "LCB v6", "model": "FP8", "value": 0.676 },

    { "category": "GPQA-D", "model": "BF16", "value": 0.613 },
    { "category": "GPQA-D", "model": "FP8", "value": 0.612 }
]
`)}catch(e){console.error("Error parsing chart data:",e),n=[]}const p=[],t=p.length>0?p:Array.from(new Set(n.map(e=>e.model))),u=[],g=u.length>0?u:Array.from(new Set(n.map(e=>e.category))),b="FP8",r=b||t[0],v=!0,e={top:40,right:30,bottom:40,left:60},m=800-e.left-e.right,i=430-e.top-e.bottom,a=d3.select("#chart-benchs").append("svg").attr("width",m+e.left+e.right).attr("height",i+e.top+e.bottom).append("g").attr("transform",`translate(${e.left},${e.top})`);document.getElementById("tooltip-benchs")||d3.select("body").append("div").attr("id","tooltip-benchs").attr("class","tooltip").style("position","absolute").style("padding","10px").style("background","#f9f9f9").style("border","1px solid #ddd").style("border-radius","5px").style("pointer-events","none").style("opacity","0").style("transition","opacity 0.3s").style("font-family","inherit").style("font-size","14px").style("box-shadow","0 2px 5px rgba(0,0,0,0.1)");const h=d3.select("#tooltip-benchs"),d=d3.scaleBand().domain(g).range([0,m]).padding(.3);a.append("g").attr("transform",`translate(0,${i})`).call(d3.axisBottom(d).tickSize(0)).selectAll(".tick").each(function(e){d3.select(this).select("text").remove();const t=d3.select(this).append("foreignObject").attr("x",-50).attr("y",0).attr("width",100).attr("height",50);t.append("xhtml:div").style("font-weight","bold").style("font-family","inherit").style("word-wrap","break-word").style("text-align","center").style("width","100%").text(e)});const f=d3.scaleBand().domain(t).range([0,d.bandwidth()]).padding(.05);let s="0",o="0.9";if(s===null||o===null){const e=n.map(e=>e.value),t=(Math.max(...e)-Math.min(...e))*.1;s=s===null?Math.max(0,Math.min(...e)-t):s,o=o===null?Math.max(...e)+t:o}const l=d3.scaleLinear().domain([s,o]).range([i,0]);a.append("g").call(d3.axisLeft(l).tickFormat(e=>v?d3.format(".0%")(e):d3.format(".2f")(e))).selectAll("text").style("font-family","inherit");const c=e=>{if(e.model===r)return"#b987ff";const s=t.indexOf(e.model),o=t.length,n=128-s*(0-80)/(o-1||1);return`rgb(${n}, ${n+8}, ${n+16})`},j=e=>{if(e===r)return"#b088ff";const s=t.indexOf(e),o=t.length,i=128-s*(0-80)/(o-1||1),n=Math.min(i+30,230);return`rgb(${n}, ${n+8}, ${n+16})`};g.forEach(e=>{const t=n.filter(t=>t.category===e),s=a.append("g").attr("class",`category-group-${e}`);s.selectAll(`.bar-${e}`).data(t).enter().append("rect").attr("class","bar").attr("x",t=>d(e)+f(t.model)).attr("y",e=>l(e.value)).attr("width",f.bandwidth()).attr("height",e=>i-l(e.value)).attr("fill",e=>c(e)).attr("data-model",e=>e.model).style("transition","opacity 0.3s"),s.on("mouseover",function(n){d3.select(this).selectAll("rect").attr("stroke","#333").attr("stroke-width",2).attr("fill",function(){const e=d3.select(this).attr("data-model");return j(e)});const s=`<strong style="font-size: 16px;">${e}</strong><br/><span style="font-size: 12px;">`+t.map(e=>v?`${e.model}: ${(e.value*100).toFixed(2)}%`:`${e.model}: ${e.value.toFixed(3)}`).join("<br/>")+"</span>";h.style("opacity",1).html(s).style("left",n.pageX+15+"px").style("top",n.pageY-28+"px")}).on("mouseout",function(){d3.select(this).selectAll("rect").attr("stroke","none").attr("fill",function(){const e=d3.select(this).attr("data-model");return c({model:e})}),h.style("opacity",0)})}),a.append("text").attr("text-anchor","middle").attr("transform","rotate(-90)").attr("y",-e.left+15).attr("x",-i/2).text("Performance %").style("font-family","inherit");const y=d3.select("#chart-benchs").append("div").style("display","flex").style("justify-content","center").style("font-size","14px").style("margin-top","-10px"),_=[...t].sort((e,n)=>e===r?-1:n===r?1:t.indexOf(e)-t.indexOf(n));_.forEach(e=>{const n=c({model:e}),t=y.append("div").style("display","flex").style("align-items","center").style("margin","0 10px");t.append("div").style("width","20px").style("height","20px").style("margin-right","5px").style("background-color",n),t.append("div").text(e)})})()</script></br><p>Under the <a href=https://github.com/facebookresearch/deepconf>DeepConf</a> test‑time filtering regime (5 repetitions, 128 rollouts per prompt), Falcon H1R 7B FP8 attains 89.3 % accuracy on AIME 2025 and 94.0 % on AIME 2024, compared to 91.3 % and 95.3 % for the BF16 baseline. The modest 1–2 % drop confirms that FP8 quantization preserves the model’s reasoning performance while still benefiting from DeepConf’s efficient trace pruning.</p><div id=chart-tts></div><script src=https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js></script><script>(function(){let n;try{n=JSON.parse(`
[
    { "category": "AIME25", "model": "BF16", "value": 0.913 },
    { "category": "AIME25", "model": "FP8", "value": 0.893 },

    { "category": "AIME24", "model": "BF16", "value": 0.953 },
    { "category": "AIME24", "model": "FP8", "value": 0.94 }
]
`)}catch(e){console.error("Error parsing chart data:",e),n=[]}const p=[],t=p.length>0?p:Array.from(new Set(n.map(e=>e.model))),u=[],g=u.length>0?u:Array.from(new Set(n.map(e=>e.category))),b="FP8",r=b||t[0],v=!0,e={top:40,right:30,bottom:40,left:60},m=800-e.left-e.right,i=430-e.top-e.bottom,a=d3.select("#chart-tts").append("svg").attr("width",m+e.left+e.right).attr("height",i+e.top+e.bottom).append("g").attr("transform",`translate(${e.left},${e.top})`);document.getElementById("tooltip-tts")||d3.select("body").append("div").attr("id","tooltip-tts").attr("class","tooltip").style("position","absolute").style("padding","10px").style("background","#f9f9f9").style("border","1px solid #ddd").style("border-radius","5px").style("pointer-events","none").style("opacity","0").style("transition","opacity 0.3s").style("font-family","inherit").style("font-size","14px").style("box-shadow","0 2px 5px rgba(0,0,0,0.1)");const h=d3.select("#tooltip-tts"),d=d3.scaleBand().domain(g).range([0,m]).padding(.3);a.append("g").attr("transform",`translate(0,${i})`).call(d3.axisBottom(d).tickSize(0)).selectAll(".tick").each(function(e){d3.select(this).select("text").remove();const t=d3.select(this).append("foreignObject").attr("x",-50).attr("y",0).attr("width",100).attr("height",50);t.append("xhtml:div").style("font-weight","bold").style("font-family","inherit").style("word-wrap","break-word").style("text-align","center").style("width","100%").text(e)});const f=d3.scaleBand().domain(t).range([0,d.bandwidth()]).padding(.05);let s="0",o="0.9";if(s===null||o===null){const e=n.map(e=>e.value),t=(Math.max(...e)-Math.min(...e))*.1;s=s===null?Math.max(0,Math.min(...e)-t):s,o=o===null?Math.max(...e)+t:o}const l=d3.scaleLinear().domain([s,o]).range([i,0]);a.append("g").call(d3.axisLeft(l).tickFormat(e=>v?d3.format(".0%")(e):d3.format(".2f")(e))).selectAll("text").style("font-family","inherit");const c=e=>{if(e.model===r)return"#b987ff";const s=t.indexOf(e.model),o=t.length,n=128-s*(0-80)/(o-1||1);return`rgb(${n}, ${n+8}, ${n+16})`},j=e=>{if(e===r)return"#b088ff";const s=t.indexOf(e),o=t.length,i=128-s*(0-80)/(o-1||1),n=Math.min(i+30,230);return`rgb(${n}, ${n+8}, ${n+16})`};g.forEach(e=>{const t=n.filter(t=>t.category===e),s=a.append("g").attr("class",`category-group-${e}`);s.selectAll(`.bar-${e}`).data(t).enter().append("rect").attr("class","bar").attr("x",t=>d(e)+f(t.model)).attr("y",e=>l(e.value)).attr("width",f.bandwidth()).attr("height",e=>i-l(e.value)).attr("fill",e=>c(e)).attr("data-model",e=>e.model).style("transition","opacity 0.3s"),s.on("mouseover",function(n){d3.select(this).selectAll("rect").attr("stroke","#333").attr("stroke-width",2).attr("fill",function(){const e=d3.select(this).attr("data-model");return j(e)});const s=`<strong style="font-size: 16px;">${e}</strong><br/><span style="font-size: 12px;">`+t.map(e=>v?`${e.model}: ${(e.value*100).toFixed(2)}%`:`${e.model}: ${e.value.toFixed(3)}`).join("<br/>")+"</span>";h.style("opacity",1).html(s).style("left",n.pageX+15+"px").style("top",n.pageY-28+"px")}).on("mouseout",function(){d3.select(this).selectAll("rect").attr("stroke","none").attr("fill",function(){const e=d3.select(this).attr("data-model");return c({model:e})}),h.style("opacity",0)})}),a.append("text").attr("text-anchor","middle").attr("transform","rotate(-90)").attr("y",-e.left+15).attr("x",-i/2).text("Performance %").style("font-family","inherit");const y=d3.select("#chart-tts").append("div").style("display","flex").style("justify-content","center").style("font-size","14px").style("margin-top","-10px"),_=[...t].sort((e,n)=>e===r?-1:n===r?1:t.indexOf(e)-t.indexOf(n));_.forEach(e=>{const n=c({model:e}),t=y.append("div").style("display","flex").style("align-items","center").style("margin","0 10px");t.append("div").style("width","20px").style("height","20px").style("margin-right","5px").style("background-color",n),t.append("div").text(e)})})()</script><h1 id=inference-profiling>Inference profiling<a hidden class=anchor aria-hidden=true href=#inference-profiling>#</a></h1><h2 id=memory>Memory<a hidden class=anchor aria-hidden=true href=#memory>#</a></h2><p>Falcon H1R 7B FP8 cuts the weight memory footprint from 14.2 GB to just 7.9 GB, a reduction of roughly 44 % that enables deployment on GPUs with lower VRAM while preserving the model’s performance.</p><div id=chart-memory></div><script src=https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js></script><script>(function(){let n;try{n=JSON.parse(`
[
    { "category": "", "model": "BF16", "value": 14.2 },
    { "category": "", "model": "FP8", "value": 7.9 }
]
`)}catch(e){console.error("Error parsing chart data:",e),n=[]}const p=[],t=p.length>0?p:Array.from(new Set(n.map(e=>e.model))),u=[],g=u.length>0?u:Array.from(new Set(n.map(e=>e.category))),b="FP8",r=b||t[0],v=!1,e={top:40,right:30,bottom:40,left:60},m=800-e.left-e.right,i=430-e.top-e.bottom,a=d3.select("#chart-memory").append("svg").attr("width",m+e.left+e.right).attr("height",i+e.top+e.bottom).append("g").attr("transform",`translate(${e.left},${e.top})`);document.getElementById("tooltip-memory")||d3.select("body").append("div").attr("id","tooltip-memory").attr("class","tooltip").style("position","absolute").style("padding","10px").style("background","#f9f9f9").style("border","1px solid #ddd").style("border-radius","5px").style("pointer-events","none").style("opacity","0").style("transition","opacity 0.3s").style("font-family","inherit").style("font-size","14px").style("box-shadow","0 2px 5px rgba(0,0,0,0.1)");const h=d3.select("#tooltip-memory"),d=d3.scaleBand().domain(g).range([0,m]).padding(.3);a.append("g").attr("transform",`translate(0,${i})`).call(d3.axisBottom(d).tickSize(0)).selectAll(".tick").each(function(e){d3.select(this).select("text").remove();const t=d3.select(this).append("foreignObject").attr("x",-50).attr("y",0).attr("width",100).attr("height",50);t.append("xhtml:div").style("font-weight","bold").style("font-family","inherit").style("word-wrap","break-word").style("text-align","center").style("width","100%").text(e)});const f=d3.scaleBand().domain(t).range([0,d.bandwidth()]).padding(.05);let s="0",o="16";if(s===null||o===null){const e=n.map(e=>e.value),t=(Math.max(...e)-Math.min(...e))*.1;s=s===null?Math.max(0,Math.min(...e)-t):s,o=o===null?Math.max(...e)+t:o}const l=d3.scaleLinear().domain([s,o]).range([i,0]);a.append("g").call(d3.axisLeft(l).tickFormat(e=>v?d3.format(".0%")(e):d3.format(".2f")(e))).selectAll("text").style("font-family","inherit");const c=e=>{if(e.model===r)return"#b987ff";const s=t.indexOf(e.model),o=t.length,n=128-s*(0-80)/(o-1||1);return`rgb(${n}, ${n+8}, ${n+16})`},j=e=>{if(e===r)return"#b088ff";const s=t.indexOf(e),o=t.length,i=128-s*(0-80)/(o-1||1),n=Math.min(i+30,230);return`rgb(${n}, ${n+8}, ${n+16})`};g.forEach(e=>{const t=n.filter(t=>t.category===e),s=a.append("g").attr("class",`category-group-${e}`);s.selectAll(`.bar-${e}`).data(t).enter().append("rect").attr("class","bar").attr("x",t=>d(e)+f(t.model)).attr("y",e=>l(e.value)).attr("width",f.bandwidth()).attr("height",e=>i-l(e.value)).attr("fill",e=>c(e)).attr("data-model",e=>e.model).style("transition","opacity 0.3s"),s.on("mouseover",function(n){d3.select(this).selectAll("rect").attr("stroke","#333").attr("stroke-width",2).attr("fill",function(){const e=d3.select(this).attr("data-model");return j(e)});const s=`<strong style="font-size: 16px;">${e}</strong><br/><span style="font-size: 12px;">`+t.map(e=>v?`${e.model}: ${(e.value*100).toFixed(2)}%`:`${e.model}: ${e.value.toFixed(3)}`).join("<br/>")+"</span>";h.style("opacity",1).html(s).style("left",n.pageX+15+"px").style("top",n.pageY-28+"px")}).on("mouseout",function(){d3.select(this).selectAll("rect").attr("stroke","none").attr("fill",function(){const e=d3.select(this).attr("data-model");return c({model:e})}),h.style("opacity",0)})}),a.append("text").attr("text-anchor","middle").attr("transform","rotate(-90)").attr("y",-e.left+15).attr("x",-i/2).text("Weights memory (Gb)").style("font-family","inherit");const y=d3.select("#chart-memory").append("div").style("display","flex").style("justify-content","center").style("font-size","14px").style("margin-top","-10px"),_=[...t].sort((e,n)=>e===r?-1:n===r?1:t.indexOf(e)-t.indexOf(n));_.forEach(e=>{const n=c({model:e}),t=y.append("div").style("display","flex").style("align-items","center").style("margin","0 10px");t.append("div").style("width","20px").style("height","20px").style("margin-right","5px").style("background-color",n),t.append("div").text(e)})})()</script><h2 id=offline-inference-benchmarking>Offline inference benchmarking<a hidden class=anchor aria-hidden=true href=#offline-inference-benchmarking>#</a></h2><p>Inference was benchmarked using offline <a href=https://github.com/vllm-project/vllm>vLLM</a> on a single NVIDIA H100 GPU.</p><h3 id=throughput>Throughput<a hidden class=anchor aria-hidden=true href=#throughput>#</a></h3><p>The plot below shows that Falcon H1R 7B FP8 consistently outperforms its BF16 counterpart across all batch sizes.</p><ul><li>For the Input = 512 / Output = 8k workload, FP8 yields a 20–22 % speed‑up (≈1.2×) over BF16, reaching 2682 tokens/s/GPU at a batch size of 32.</li><li>For the Input = 8k / Output = 8k workload, the improvement grows to 24–31 % (≈1.3×), achieving 2220 tokens/s/GPU at a batch size of 32.</br></br></li></ul><div id=chart-inference class=dline-container></div><style>.dline-container{font-family:-apple-system,BlinkMacSystemFont,segoe ui,Roboto,Helvetica,Arial,sans-serif}.dline-controls{display:flex;flex-wrap:wrap;gap:16px;margin-bottom:16px;align-items:flex-start}.dline-control-group{display:flex;flex-direction:column;gap:4px}.dline-control-group>label{font-size:12px;font-weight:600;color:#6b7280;text-transform:uppercase;letter-spacing:.5px}.dline-dropdown{position:relative;min-width:220px}.dline-dropdown-button{width:100%;padding:10px 14px;background:#fff;border:1px solid #d1d5db;border-radius:8px;font-size:14px;cursor:pointer;display:flex;justify-content:space-between;align-items:center;transition:border-color .2s,box-shadow .2s}.dline-dropdown-button:hover{border-color:#9ca3af}.dline-dropdown-button:focus{outline:none;border-color:#6366f1;box-shadow:0 0 0 3px rgba(99,102,241,.1)}.dline-dropdown-menu{position:absolute;top:100%;left:0;right:0;margin-top:4px;background:#fff;border:1px solid #d1d5db;border-radius:8px;box-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -2px rgba(0,0,0,5%);z-index:1000;max-height:300px;overflow-y:auto;display:none}.dline-dropdown-menu.open{display:block}.dline-dropdown-item{padding:10px 14px;cursor:pointer;display:flex;align-items:center;gap:10px;font-size:14px;transition:background .15s}.dline-dropdown-item:hover{background:#f3f4f6}.dline-dropdown-item input[type=checkbox]{width:16px;height:16px;accent-color:#6366f1;cursor:pointer}.dline-dropdown-item label{cursor:pointer;flex:1;font-size:14px;font-weight:400;color:inherit;text-transform:none;letter-spacing:normal}.dline-select-actions{display:flex;gap:8px;padding:10px 14px;border-bottom:1px solid #e5e7eb;background:#f9fafb;border-radius:8px 8px 0 0}.dline-select-actions button{padding:5px 10px;font-size:12px;font-weight:500;background:#fff;border:1px solid #d1d5db;border-radius:4px;cursor:pointer;transition:all .15s}.dline-select-actions button:hover{background:#f3f4f6;border-color:#9ca3af}.dline-chips-section{margin-bottom:16px}.dline-chips-label{font-size:11px;font-weight:600;color:#9ca3af;text-transform:uppercase;letter-spacing:.5px;margin-bottom:6px}.dline-chip-container{display:flex;flex-wrap:wrap;gap:6px}.dline-chip{display:inline-flex;align-items:center;gap:6px;padding:5px 10px;background:#e0e7ff;color:#4338ca;border-radius:20px;font-size:12px;font-weight:500;transition:background .15s}.dline-chip:hover{background:#c7d2fe}.dline-chip.name-chip{background:#fae8ff;color:#a21caf}.dline-chip.name-chip:hover{background:#f5d0fe}.dline-chip.name-chip.highlighted{background:#d8b4fe;color:#6b21a8}.dline-chip-remove{cursor:pointer;opacity:.7;transition:opacity .15s;font-size:14px;line-height:1}.dline-chip-remove:hover{opacity:1}.dline-empty-message{text-align:center;padding:40px;color:#6b7280;font-size:14px}.dline-chart-wrapper{display:flex;justify-content:center;width:100%}.dline-legend{display:flex;flex-wrap:wrap;justify-content:center;gap:16px;margin-top:16px}.dline-legend-item{display:flex;align-items:center;gap:6px;font-size:12px}.dline-legend-line{width:20px;height:3px;border-radius:2px}</style><script src=https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js></script><script>(function(){const e="inference",h=document.getElementById(`chart-${e}`);let c;try{c=JSON.parse(`
[
    { "category": "Input=512, Output=8k", "name": "BF16", "x": 2, "y": 238, "tooltip": "tp=1, dp=1"},
    { "category": "Input=512, Output=8k", "name": "FP8", "x": 2, "y": 289, "tooltip": "tp=1, dp=1"},
    { "category": "Input=512, Output=8k", "name": "BF16", "x": 8, "y": 820, "tooltip": "tp=1, dp=1"},
    { "category": "Input=512, Output=8k", "name": "FP8", "x": 8, "y": 1003, "tooltip": "tp=1, dp=1"},
    { "category": "Input=512, Output=8k", "name": "BF16", "x": 16, "y": 1414, "tooltip": "tp=1, dp=1"},
    { "category": "Input=512, Output=8k", "name": "FP8", "x": 16, "y": 1729, "tooltip": "tp=1, dp=1"},
    { "category": "Input=512, Output=8k", "name": "BF16", "x": 32, "y": 2230, "tooltip": "tp=1, dp=1"},
    { "category": "Input=512, Output=8k", "name": "FP8", "x": 32, "y": 2682, "tooltip": "tp=1, dp=1"},

    { "category": "Input=8k, Output=8k", "name": "BF16", "x": 2, "y": 228, "tooltip": "tp=1, dp=1"},
    { "category": "Input=8k, Output=8k", "name": "FP8", "x": 2, "y": 282, "tooltip": "tp=1, dp=1"},
    { "category": "Input=8k, Output=8k", "name": "BF16", "x": 8, "y": 732, "tooltip": "tp=1, dp=1"},
    { "category": "Input=8k, Output=8k", "name": "FP8", "x": 8, "y": 933, "tooltip": "tp=1, dp=1"},
    { "category": "Input=8k, Output=8k", "name": "BF16", "x": 16, "y": 1168, "tooltip": "tp=1, dp=1"},
    { "category": "Input=8k, Output=8k", "name": "FP8", "x": 16, "y": 1505, "tooltip": "tp=1, dp=1"},
    { "category": "Input=8k, Output=8k", "name": "BF16", "x": 32, "y": 1695, "tooltip": "tp=1, dp=1"},
    { "category": "Input=8k, Output=8k", "name": "FP8", "x": 32, "y": 2220, "tooltip": "tp=1, dp=1"}

]
`)}catch(e){console.error("Error parsing chart data:",e),c=[]}const d="I/O size",p="Model precision",w="Batch size",k="Tokens / s / GPU",F="",M="",y=e=>!e||e.trim()===""?null:e.split(";").map(e=>e.trim()).filter(e=>e.length>0),A=y(F),_=y(M),s=Array.from(new Set(c.map(e=>e.name))),l=Array.from(new Set(c.map(e=>e.category))),z="FP8",o=z||s[0],C=!1,x=!1,N=800,T=500;let t=A?A.filter(e=>l.includes(e)):[...l],n=_?_.filter(e=>s.includes(e)):[...s];const u=document.createElement("div");u.className="dline-controls",h.appendChild(u);function O(t,n,s,o,i){const l=document.createElement("div");l.className="dline-control-group";const g=document.createElement("label");g.textContent=t,l.appendChild(g);const d=document.createElement("div");d.className="dline-dropdown",l.appendChild(d);const r=document.createElement("button");r.className="dline-dropdown-button",r.type="button",d.appendChild(r);function c(){const e=s.length;r.innerHTML=`
        <span>${e} of ${n.length} selected</span>
        <svg width="12" height="12" viewBox="0 0 12 12" fill="none">
          <path d="M3 4.5L6 7.5L9 4.5" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"/>
        </svg>
      `}c();const a=document.createElement("div");a.className="dline-dropdown-menu",d.appendChild(a);const u=document.createElement("div");u.className="dline-select-actions",a.appendChild(u);const h=document.createElement("button");h.type="button",h.textContent="Select All",h.onclick=e=>{e.stopPropagation(),s.length=0,s.push(...n),p(),c(),i()},u.appendChild(h);const m=document.createElement("button");m.type="button",m.textContent="Clear All",m.onclick=e=>{e.stopPropagation(),s.length=0,p(),c(),i()},u.appendChild(m);const f={};n.forEach(t=>{const r=document.createElement("div");r.className="dline-dropdown-item";const n=document.createElement("input");n.type="checkbox",n.id=`${o}-${e}-${t.replace(/[^a-zA-Z0-9]/g,"_")}`,n.checked=s.includes(t),f[t]=n,n.onchange=()=>{if(n.checked)s.includes(t)||s.push(t);else{const e=s.indexOf(t);e>-1&&s.splice(e,1)}c(),i()};const l=document.createElement("label");l.htmlFor=n.id,l.textContent=t,r.appendChild(n),r.appendChild(l),a.appendChild(r)});function p(){n.forEach(e=>{f[e]&&(f[e].checked=s.includes(e))})}return r.onclick=e=>{e.stopPropagation(),document.querySelectorAll(".dline-dropdown-menu.open").forEach(e=>{e!==a&&e.classList.remove("open")}),a.classList.toggle("open")},{element:l,updateButtonText:c,updateCheckboxes:p,getSelected:()=>s}}const i=document.createElement("div");i.className="dline-chips-section";function r(){if(i.innerHTML="",t.length>0&&t.length<l.length){const e=document.createElement("div");e.className="dline-chips-label",e.textContent=d,i.appendChild(e);const n=document.createElement("div");n.className="dline-chip-container",t.forEach(e=>{const s=document.createElement("span");s.className="dline-chip",s.innerHTML=`${e}<span class="dline-chip-remove">×</span>`,s.querySelector(".dline-chip-remove").onclick=()=>{const n=t.indexOf(e);n>-1&&t.splice(n,1),v.updateCheckboxes(),v.updateButtonText(),r(),a()},n.appendChild(s)}),i.appendChild(n)}if(n.length>0&&n.length<s.length){const e=document.createElement("div");e.className="dline-chips-label",e.style.marginTop=t.length>0&&t.length<l.length?"12px":"0",e.textContent=p,i.appendChild(e);const s=document.createElement("div");s.className="dline-chip-container",n.forEach(e=>{const t=document.createElement("span");t.className=`dline-chip name-chip${e===o?" highlighted":""}`,t.innerHTML=`${e}<span class="dline-chip-remove">×</span>`,t.querySelector(".dline-chip-remove").onclick=()=>{const t=n.indexOf(e);t>-1&&n.splice(t,1),f.updateCheckboxes(),f.updateButtonText(),r(),a()},s.appendChild(t)}),i.appendChild(s)}}const v=O(d,l,t,"cat",()=>{r(),a()});u.appendChild(v.element);const f=O(p,s,n,"name",()=>{r(),a()});u.appendChild(f.element),document.addEventListener("click",e=>{e.target.closest(".dline-dropdown")||document.querySelectorAll(".dline-dropdown-menu.open").forEach(e=>{e.classList.remove("open")})}),h.appendChild(i),r();const m=document.createElement("div");m.className="dline-chart-wrapper",h.appendChild(m);const S=document.createElement("div");S.id=`chart-svg-${e}`,m.appendChild(S);const j=document.createElement("div");j.id=`legend-${e}`,j.className="dline-legend",h.appendChild(j);const b=`tooltip-${e}`;if(!document.getElementById(b)){const e=document.createElement("div");e.id=b,e.className="tooltip",e.style.cssText=`
      position: absolute;
      padding: 12px 14px;
      background: #fff;
      border: 1px solid #e5e7eb;
      border-radius: 8px;
      pointer-events: none;
      opacity: 0;
      transition: opacity 0.2s;
      font-family: inherit;
      font-size: 14px;
      box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
      z-index: 10000;
    `,document.body.appendChild(e)}const g=d3.select(`#${b}`),E=e=>{if(e===o)return"#a855f7";const n=s.indexOf(e),i=s.length,t=140-n*60/(i-1||1);return`rgb(${t}, ${t+8}, ${t+16})`},D=e=>{if(e===o)return"#c084fc";const n=s.indexOf(e),i=s.length,a=140-n*60/(i-1||1),t=Math.min(a+30,200);return`rgb(${t}, ${t+8}, ${t+16})`};function a(){if(d3.select(`#chart-svg-${e}`).selectAll("*").remove(),d3.select(`#legend-${e}`).selectAll("*").remove(),t.length===0||n.length===0){const n=document.createElement("div");n.className="dline-empty-message",n.textContent=t.length===0?`Please select at least one ${d.toLowerCase()} to display the chart.`:`Please select at least one ${p.toLowerCase()} to display the chart.`,document.getElementById(`chart-svg-${e}`).appendChild(n);return}const A=c.filter(e=>n.includes(e.name)&&t.includes(e.category));if(A.length===0){const t=document.createElement("div");t.className="dline-empty-message",t.textContent="No data available for the selected filters.",document.getElementById(`chart-svg-${e}`).appendChild(t);return}const v={};n.forEach(e=>{const s=A.filter(t=>t.name===e),t={};s.forEach(e=>{t[e.x]||(t[e.x]={yValues:[],tooltips:[]}),t[e.x].yValues.push(e.y),e.tooltip&&t[e.x].tooltips.push(e.tooltip)});const n=Object.keys(t).map(e=>({x:parseFloat(e),y:t[e].yValues.reduce((e,t)=>e+t,0)/t[e].yValues.length,tooltip:t[e].tooltips.length>0?[...new Set(t[e].tooltips)].join("; "):null})).sort((e,t)=>e.x-t.x);n.length>0&&(v[e]=n)});const b=Object.keys(v);if(b.length===0){const t=document.createElement("div");t.className="dline-empty-message",t.textContent="No data available for the selected filters.",document.getElementById(`chart-svg-${e}`).appendChild(t);return}const s={top:30,right:30,bottom:60,left:70},f=N-s.left-s.right,a=T-s.top-s.bottom,y=Object.values(v).flat(),r=y.map(e=>e.x),u=y.map(e=>e.y),h=r.every(e=>Number.isInteger(e)),_=[...new Set(r)].sort((e,t)=>e-t),O=(Math.max(...u)-Math.min(...u))*.1||10,z=Math.max(0,Math.min(...u)-O),S=Math.max(...u)+O,i=d3.select(`#chart-svg-${e}`).append("svg").attr("width",f+s.left+s.right).attr("height",a+s.top+s.bottom).append("g").attr("transform",`translate(${s.left},${s.top})`);let l;const j=(Math.max(...r)-Math.min(...r))*.05||1,M=Math.min(...r)-j,F=Math.max(...r)+j;l=d3.scaleLinear().domain([M,F]).range([0,f]);const m=d3.scaleLinear().domain([z,S]).range([a,0]);i.append("g").attr("class","grid").attr("transform",`translate(0,${a})`).call(d3.axisBottom(l).tickSize(-a).tickFormat("").tickValues(h?_:null)).selectAll("line").style("stroke","#f3f4f6").style("stroke-width",1),i.append("g").attr("class","grid").call(d3.axisLeft(m).tickSize(-f).tickFormat("")).selectAll("line").style("stroke","#f3f4f6").style("stroke-width",1),i.selectAll(".grid").select(".domain").remove(),i.append("g").attr("transform",`translate(0,${a})`).call(d3.axisBottom(l).tickValues(h?_:null).tickFormat(e=>x?e+"%":h?e:d3.format(".1f")(e))).selectAll("text").style("font-family","inherit").style("fill","#6b7280"),i.append("g").call(d3.axisLeft(m).tickFormat(e=>C?d3.format(".0f")(e)+"%":d3.format(".1f")(e))).selectAll("text").style("font-family","inherit").style("fill","#6b7280"),i.append("text").attr("text-anchor","middle").attr("x",f/2).attr("y",a+s.bottom-15).text(w).style("font-family","inherit").style("font-size","13px").style("fill","#6b7280"),i.append("text").attr("text-anchor","middle").attr("transform","rotate(-90)").attr("x",-a/2).attr("y",-s.left+20).text(k).style("font-family","inherit").style("font-size","13px").style("fill","#6b7280");const L=d3.line().x(e=>l(e.x)).y(e=>m(e.y)).curve(d3.curveMonotoneX);b.forEach(e=>{const r=v[e],s=E(e),n=e===o,c=i.append("path").datum(r).attr("class",`line-${e.replace(/[^a-zA-Z0-9]/g,"_")}`).attr("fill","none").attr("stroke",s).attr("stroke-width",n?3:2).attr("d",L),a=c.node().getTotalLength();c.attr("stroke-dasharray",`${a} ${a}`).attr("stroke-dashoffset",a).transition().duration(800).ease(d3.easeCubicOut).attr("stroke-dashoffset",0),i.selectAll(`.point-${e.replace(/[^a-zA-Z0-9]/g,"_")}`).data(r).enter().append("circle").attr("class",`point-${e.replace(/[^a-zA-Z0-9]/g,"_")}`).attr("cx",e=>l(e.x)).attr("cy",e=>m(e.y)).attr("r",0).attr("fill",s).attr("stroke","#fff").attr("stroke-width",2).style("cursor","pointer").transition().delay(600).duration(300).attr("r",n?6:5),setTimeout(()=>{i.selectAll(`.point-${e.replace(/[^a-zA-Z0-9]/g,"_")}`).on("mouseover",function(s,i){d3.select(this).transition().duration(150).attr("r",n?8:7).attr("fill",D(e));const a=C?`${i.y.toFixed(2)}%`:i.y.toFixed(2),r=x?`${i.x}%`:h?i.x:i.x.toFixed(2);g.style("opacity",1).html(`
                <div style="font-weight: 600; font-size: 15px; margin-bottom: 6px; color: ${e===o?"#7c3aed":"#111827"};">${e}</div>
                <div style="font-size: 13px; color: #374151;"><strong>${w}:</strong> ${r}</div>
                <div style="font-size: 13px; color: #374151;"><strong>${k}:</strong> ${a}</div>
                ${i.tooltip?`<div style="font-size: 12px; color: #6b7280; margin-top: 6px; padding-top: 6px; border-top: 1px solid #e5e7eb;">${i.tooltip}</div>`:""}
                <div style="font-size: 11px; color: #9ca3af; margin-top: 6px;">Averaged over ${t.length} ${d.toLowerCase()}</div>
              `).style("left",s.pageX+15+"px").style("top",s.pageY-28+"px")}).on("mousemove",function(e){g.style("left",e.pageX+15+"px").style("top",e.pageY-28+"px")}).on("mouseout",function(){d3.select(this).transition().duration(150).attr("r",n?6:5).attr("fill",s),g.style("opacity",0)})},950)});const R=d3.select(`#legend-${e}`),P=[...b].sort((e,t)=>e===o?-1:t===o?1:0);P.forEach(e=>{const s=E(e),t=e===o,n=R.append("div").attr("class","dline-legend-item").style("font-weight",t?"600":"400").style("color",t?"#7c3aed":"#374151");n.append("div").attr("class","dline-legend-line").style("background-color",s),n.append("span").text(e)})}a()})()</script><h2 id=online-inference-benchmarking>Online inference benchmarking<a hidden class=anchor aria-hidden=true href=#online-inference-benchmarking>#</a></h2><p>To conduct the online serving performance analysis, we utilized <a href=https://github.com/ai-dynamo/aiperf>NVIDIA AIPerf</a>. AIPerf is a client-side generative AI benchmarking tool that supports any inference service conforming to the OpenAI API specification. It is designed to capture critical performance metrics including Time to First Token (TTFT), Inter-Token Latency (ITL), and overall throughput.</p><p>Models were served using online <a href=https://github.com/vllm-project/vllm>vLLM</a> with 1k input tokens and 1k output tokens across various concurrency levels. All performance numbers are measured on a single NVIDIA H200 GPU.</p><h3 id=gpu-efficiency-vs-user-experience>GPU Efficiency vs User Experience<a hidden class=anchor aria-hidden=true href=#gpu-efficiency-vs-user-experience>#</a></h3><p>This chart illustrates the trade-off between total output throughput (tokens/sec) and per-user throughput (tokens/sec/user) across different concurrency levels. As concurrency increases, total throughput grows but per-user experience degrades. FP8 maintains higher throughput on both axes, demonstrating superior efficiency.</p><p><strong>Key Performance Improvements:</strong></p><ul><li><strong>Output Throughput</strong>: FP8 achieves up to 12.7% higher output token throughput at concurrency 64 (4543.5 vs 4030.9 tokens/sec)</li><li><strong>Per-User Throughput</strong>: FP8 delivers 20% better tokens/sec per user at low concurrency (188.7 vs 156.7 at concurrency 1)</br></br></li></ul><div id=chart-gpu_efficiency class=dline-container></div><style>.dline-container{font-family:-apple-system,BlinkMacSystemFont,segoe ui,Roboto,Helvetica,Arial,sans-serif}.dline-controls{display:flex;flex-wrap:wrap;gap:16px;margin-bottom:16px;align-items:flex-start}.dline-control-group{display:flex;flex-direction:column;gap:4px}.dline-control-group>label{font-size:12px;font-weight:600;color:#6b7280;text-transform:uppercase;letter-spacing:.5px}.dline-dropdown{position:relative;min-width:220px}.dline-dropdown-button{width:100%;padding:10px 14px;background:#fff;border:1px solid #d1d5db;border-radius:8px;font-size:14px;cursor:pointer;display:flex;justify-content:space-between;align-items:center;transition:border-color .2s,box-shadow .2s}.dline-dropdown-button:hover{border-color:#9ca3af}.dline-dropdown-button:focus{outline:none;border-color:#6366f1;box-shadow:0 0 0 3px rgba(99,102,241,.1)}.dline-dropdown-menu{position:absolute;top:100%;left:0;right:0;margin-top:4px;background:#fff;border:1px solid #d1d5db;border-radius:8px;box-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -2px rgba(0,0,0,5%);z-index:1000;max-height:300px;overflow-y:auto;display:none}.dline-dropdown-menu.open{display:block}.dline-dropdown-item{padding:10px 14px;cursor:pointer;display:flex;align-items:center;gap:10px;font-size:14px;transition:background .15s}.dline-dropdown-item:hover{background:#f3f4f6}.dline-dropdown-item input[type=checkbox]{width:16px;height:16px;accent-color:#6366f1;cursor:pointer}.dline-dropdown-item label{cursor:pointer;flex:1;font-size:14px;font-weight:400;color:inherit;text-transform:none;letter-spacing:normal}.dline-select-actions{display:flex;gap:8px;padding:10px 14px;border-bottom:1px solid #e5e7eb;background:#f9fafb;border-radius:8px 8px 0 0}.dline-select-actions button{padding:5px 10px;font-size:12px;font-weight:500;background:#fff;border:1px solid #d1d5db;border-radius:4px;cursor:pointer;transition:all .15s}.dline-select-actions button:hover{background:#f3f4f6;border-color:#9ca3af}.dline-chips-section{margin-bottom:16px}.dline-chips-label{font-size:11px;font-weight:600;color:#9ca3af;text-transform:uppercase;letter-spacing:.5px;margin-bottom:6px}.dline-chip-container{display:flex;flex-wrap:wrap;gap:6px}.dline-chip{display:inline-flex;align-items:center;gap:6px;padding:5px 10px;background:#e0e7ff;color:#4338ca;border-radius:20px;font-size:12px;font-weight:500;transition:background .15s}.dline-chip:hover{background:#c7d2fe}.dline-chip.name-chip{background:#fae8ff;color:#a21caf}.dline-chip.name-chip:hover{background:#f5d0fe}.dline-chip.name-chip.highlighted{background:#d8b4fe;color:#6b21a8}.dline-chip-remove{cursor:pointer;opacity:.7;transition:opacity .15s;font-size:14px;line-height:1}.dline-chip-remove:hover{opacity:1}.dline-empty-message{text-align:center;padding:40px;color:#6b7280;font-size:14px}.dline-chart-wrapper{display:flex;justify-content:center;width:100%}.dline-legend{display:flex;flex-wrap:wrap;justify-content:center;gap:16px;margin-top:16px}.dline-legend-item{display:flex;align-items:center;gap:6px;font-size:12px}.dline-legend-line{width:20px;height:3px;border-radius:2px}</style><script src=https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js></script><script>(function(){const e="gpu_efficiency",h=document.getElementById(`chart-${e}`);let c;try{c=JSON.parse(`
[
    { "category": "GPU Efficiency vs User Experience", "name": "BF16", "x": 156.79, "y": 154.61, "tooltip": "concurrency=1"},
    { "category": "GPU Efficiency vs User Experience", "name": "BF16", "x": 153.03, "y": 298.37, "tooltip": "concurrency=2"},
    { "category": "GPU Efficiency vs User Experience", "name": "BF16", "x": 146.89, "y": 544.11, "tooltip": "concurrency=4"},
    { "category": "GPU Efficiency vs User Experience", "name": "BF16", "x": 133.42, "y": 1004.91, "tooltip": "concurrency=8"},
    { "category": "GPU Efficiency vs User Experience", "name": "BF16", "x": 117.66, "y": 1775.0, "tooltip": "concurrency=16"},
    { "category": "GPU Efficiency vs User Experience", "name": "BF16", "x": 94.07, "y": 2768.55, "tooltip": "concurrency=32"},
    { "category": "GPU Efficiency vs User Experience", "name": "BF16", "x": 68.01, "y": 4030.91, "tooltip": "concurrency=64"},

    { "category": "GPU Efficiency vs User Experience", "name": "FP8", "x": 188.74, "y": 185.45, "tooltip": "concurrency=1"},
    { "category": "GPU Efficiency vs User Experience", "name": "FP8", "x": 185.19, "y": 359.87, "tooltip": "concurrency=2"},
    { "category": "GPU Efficiency vs User Experience", "name": "FP8", "x": 176.38, "y": 687.63, "tooltip": "concurrency=4"},
    { "category": "GPU Efficiency vs User Experience", "name": "FP8", "x": 162.1, "y": 1253.06, "tooltip": "concurrency=8"},
    { "category": "GPU Efficiency vs User Experience", "name": "FP8", "x": 137.84, "y": 1990.35, "tooltip": "concurrency=16"},
    { "category": "GPU Efficiency vs User Experience", "name": "FP8", "x": 105.82, "y": 3155.06, "tooltip": "concurrency=32"},
    { "category": "GPU Efficiency vs User Experience", "name": "FP8", "x": 76.63, "y": 4543.5, "tooltip": "concurrency=64"}
]
`)}catch(e){console.error("Error parsing chart data:",e),c=[]}const d="Metric",p="Model precision",w="Tokens/sec per User",k="Output Token Throughput (tokens/sec)",F="",M="",y=e=>!e||e.trim()===""?null:e.split(";").map(e=>e.trim()).filter(e=>e.length>0),A=y(F),_=y(M),s=Array.from(new Set(c.map(e=>e.name))),l=Array.from(new Set(c.map(e=>e.category))),z="FP8",o=z||s[0],C=!1,x=!1,N=800,T=500;let t=A?A.filter(e=>l.includes(e)):[...l],n=_?_.filter(e=>s.includes(e)):[...s];const u=document.createElement("div");u.className="dline-controls",h.appendChild(u);function O(t,n,s,o,i){const l=document.createElement("div");l.className="dline-control-group";const g=document.createElement("label");g.textContent=t,l.appendChild(g);const d=document.createElement("div");d.className="dline-dropdown",l.appendChild(d);const r=document.createElement("button");r.className="dline-dropdown-button",r.type="button",d.appendChild(r);function c(){const e=s.length;r.innerHTML=`
        <span>${e} of ${n.length} selected</span>
        <svg width="12" height="12" viewBox="0 0 12 12" fill="none">
          <path d="M3 4.5L6 7.5L9 4.5" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"/>
        </svg>
      `}c();const a=document.createElement("div");a.className="dline-dropdown-menu",d.appendChild(a);const u=document.createElement("div");u.className="dline-select-actions",a.appendChild(u);const h=document.createElement("button");h.type="button",h.textContent="Select All",h.onclick=e=>{e.stopPropagation(),s.length=0,s.push(...n),p(),c(),i()},u.appendChild(h);const m=document.createElement("button");m.type="button",m.textContent="Clear All",m.onclick=e=>{e.stopPropagation(),s.length=0,p(),c(),i()},u.appendChild(m);const f={};n.forEach(t=>{const r=document.createElement("div");r.className="dline-dropdown-item";const n=document.createElement("input");n.type="checkbox",n.id=`${o}-${e}-${t.replace(/[^a-zA-Z0-9]/g,"_")}`,n.checked=s.includes(t),f[t]=n,n.onchange=()=>{if(n.checked)s.includes(t)||s.push(t);else{const e=s.indexOf(t);e>-1&&s.splice(e,1)}c(),i()};const l=document.createElement("label");l.htmlFor=n.id,l.textContent=t,r.appendChild(n),r.appendChild(l),a.appendChild(r)});function p(){n.forEach(e=>{f[e]&&(f[e].checked=s.includes(e))})}return r.onclick=e=>{e.stopPropagation(),document.querySelectorAll(".dline-dropdown-menu.open").forEach(e=>{e!==a&&e.classList.remove("open")}),a.classList.toggle("open")},{element:l,updateButtonText:c,updateCheckboxes:p,getSelected:()=>s}}const i=document.createElement("div");i.className="dline-chips-section";function r(){if(i.innerHTML="",t.length>0&&t.length<l.length){const e=document.createElement("div");e.className="dline-chips-label",e.textContent=d,i.appendChild(e);const n=document.createElement("div");n.className="dline-chip-container",t.forEach(e=>{const s=document.createElement("span");s.className="dline-chip",s.innerHTML=`${e}<span class="dline-chip-remove">×</span>`,s.querySelector(".dline-chip-remove").onclick=()=>{const n=t.indexOf(e);n>-1&&t.splice(n,1),v.updateCheckboxes(),v.updateButtonText(),r(),a()},n.appendChild(s)}),i.appendChild(n)}if(n.length>0&&n.length<s.length){const e=document.createElement("div");e.className="dline-chips-label",e.style.marginTop=t.length>0&&t.length<l.length?"12px":"0",e.textContent=p,i.appendChild(e);const s=document.createElement("div");s.className="dline-chip-container",n.forEach(e=>{const t=document.createElement("span");t.className=`dline-chip name-chip${e===o?" highlighted":""}`,t.innerHTML=`${e}<span class="dline-chip-remove">×</span>`,t.querySelector(".dline-chip-remove").onclick=()=>{const t=n.indexOf(e);t>-1&&n.splice(t,1),f.updateCheckboxes(),f.updateButtonText(),r(),a()},s.appendChild(t)}),i.appendChild(s)}}const v=O(d,l,t,"cat",()=>{r(),a()});u.appendChild(v.element);const f=O(p,s,n,"name",()=>{r(),a()});u.appendChild(f.element),document.addEventListener("click",e=>{e.target.closest(".dline-dropdown")||document.querySelectorAll(".dline-dropdown-menu.open").forEach(e=>{e.classList.remove("open")})}),h.appendChild(i),r();const m=document.createElement("div");m.className="dline-chart-wrapper",h.appendChild(m);const S=document.createElement("div");S.id=`chart-svg-${e}`,m.appendChild(S);const j=document.createElement("div");j.id=`legend-${e}`,j.className="dline-legend",h.appendChild(j);const b=`tooltip-${e}`;if(!document.getElementById(b)){const e=document.createElement("div");e.id=b,e.className="tooltip",e.style.cssText=`
      position: absolute;
      padding: 12px 14px;
      background: #fff;
      border: 1px solid #e5e7eb;
      border-radius: 8px;
      pointer-events: none;
      opacity: 0;
      transition: opacity 0.2s;
      font-family: inherit;
      font-size: 14px;
      box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
      z-index: 10000;
    `,document.body.appendChild(e)}const g=d3.select(`#${b}`),E=e=>{if(e===o)return"#a855f7";const n=s.indexOf(e),i=s.length,t=140-n*60/(i-1||1);return`rgb(${t}, ${t+8}, ${t+16})`},D=e=>{if(e===o)return"#c084fc";const n=s.indexOf(e),i=s.length,a=140-n*60/(i-1||1),t=Math.min(a+30,200);return`rgb(${t}, ${t+8}, ${t+16})`};function a(){if(d3.select(`#chart-svg-${e}`).selectAll("*").remove(),d3.select(`#legend-${e}`).selectAll("*").remove(),t.length===0||n.length===0){const n=document.createElement("div");n.className="dline-empty-message",n.textContent=t.length===0?`Please select at least one ${d.toLowerCase()} to display the chart.`:`Please select at least one ${p.toLowerCase()} to display the chart.`,document.getElementById(`chart-svg-${e}`).appendChild(n);return}const A=c.filter(e=>n.includes(e.name)&&t.includes(e.category));if(A.length===0){const t=document.createElement("div");t.className="dline-empty-message",t.textContent="No data available for the selected filters.",document.getElementById(`chart-svg-${e}`).appendChild(t);return}const v={};n.forEach(e=>{const s=A.filter(t=>t.name===e),t={};s.forEach(e=>{t[e.x]||(t[e.x]={yValues:[],tooltips:[]}),t[e.x].yValues.push(e.y),e.tooltip&&t[e.x].tooltips.push(e.tooltip)});const n=Object.keys(t).map(e=>({x:parseFloat(e),y:t[e].yValues.reduce((e,t)=>e+t,0)/t[e].yValues.length,tooltip:t[e].tooltips.length>0?[...new Set(t[e].tooltips)].join("; "):null})).sort((e,t)=>e.x-t.x);n.length>0&&(v[e]=n)});const b=Object.keys(v);if(b.length===0){const t=document.createElement("div");t.className="dline-empty-message",t.textContent="No data available for the selected filters.",document.getElementById(`chart-svg-${e}`).appendChild(t);return}const s={top:30,right:30,bottom:60,left:70},f=N-s.left-s.right,a=T-s.top-s.bottom,y=Object.values(v).flat(),r=y.map(e=>e.x),u=y.map(e=>e.y),h=r.every(e=>Number.isInteger(e)),_=[...new Set(r)].sort((e,t)=>e-t),O=(Math.max(...u)-Math.min(...u))*.1||10,z=Math.max(0,Math.min(...u)-O),S=Math.max(...u)+O,i=d3.select(`#chart-svg-${e}`).append("svg").attr("width",f+s.left+s.right).attr("height",a+s.top+s.bottom).append("g").attr("transform",`translate(${s.left},${s.top})`);let l;const j=(Math.max(...r)-Math.min(...r))*.05||1,M=Math.min(...r)-j,F=Math.max(...r)+j;l=d3.scaleLinear().domain([M,F]).range([0,f]);const m=d3.scaleLinear().domain([z,S]).range([a,0]);i.append("g").attr("class","grid").attr("transform",`translate(0,${a})`).call(d3.axisBottom(l).tickSize(-a).tickFormat("").tickValues(h?_:null)).selectAll("line").style("stroke","#f3f4f6").style("stroke-width",1),i.append("g").attr("class","grid").call(d3.axisLeft(m).tickSize(-f).tickFormat("")).selectAll("line").style("stroke","#f3f4f6").style("stroke-width",1),i.selectAll(".grid").select(".domain").remove(),i.append("g").attr("transform",`translate(0,${a})`).call(d3.axisBottom(l).tickValues(h?_:null).tickFormat(e=>x?e+"%":h?e:d3.format(".1f")(e))).selectAll("text").style("font-family","inherit").style("fill","#6b7280"),i.append("g").call(d3.axisLeft(m).tickFormat(e=>C?d3.format(".0f")(e)+"%":d3.format(".1f")(e))).selectAll("text").style("font-family","inherit").style("fill","#6b7280"),i.append("text").attr("text-anchor","middle").attr("x",f/2).attr("y",a+s.bottom-15).text(w).style("font-family","inherit").style("font-size","13px").style("fill","#6b7280"),i.append("text").attr("text-anchor","middle").attr("transform","rotate(-90)").attr("x",-a/2).attr("y",-s.left+20).text(k).style("font-family","inherit").style("font-size","13px").style("fill","#6b7280");const L=d3.line().x(e=>l(e.x)).y(e=>m(e.y)).curve(d3.curveMonotoneX);b.forEach(e=>{const r=v[e],s=E(e),n=e===o,c=i.append("path").datum(r).attr("class",`line-${e.replace(/[^a-zA-Z0-9]/g,"_")}`).attr("fill","none").attr("stroke",s).attr("stroke-width",n?3:2).attr("d",L),a=c.node().getTotalLength();c.attr("stroke-dasharray",`${a} ${a}`).attr("stroke-dashoffset",a).transition().duration(800).ease(d3.easeCubicOut).attr("stroke-dashoffset",0),i.selectAll(`.point-${e.replace(/[^a-zA-Z0-9]/g,"_")}`).data(r).enter().append("circle").attr("class",`point-${e.replace(/[^a-zA-Z0-9]/g,"_")}`).attr("cx",e=>l(e.x)).attr("cy",e=>m(e.y)).attr("r",0).attr("fill",s).attr("stroke","#fff").attr("stroke-width",2).style("cursor","pointer").transition().delay(600).duration(300).attr("r",n?6:5),setTimeout(()=>{i.selectAll(`.point-${e.replace(/[^a-zA-Z0-9]/g,"_")}`).on("mouseover",function(s,i){d3.select(this).transition().duration(150).attr("r",n?8:7).attr("fill",D(e));const a=C?`${i.y.toFixed(2)}%`:i.y.toFixed(2),r=x?`${i.x}%`:h?i.x:i.x.toFixed(2);g.style("opacity",1).html(`
                <div style="font-weight: 600; font-size: 15px; margin-bottom: 6px; color: ${e===o?"#7c3aed":"#111827"};">${e}</div>
                <div style="font-size: 13px; color: #374151;"><strong>${w}:</strong> ${r}</div>
                <div style="font-size: 13px; color: #374151;"><strong>${k}:</strong> ${a}</div>
                ${i.tooltip?`<div style="font-size: 12px; color: #6b7280; margin-top: 6px; padding-top: 6px; border-top: 1px solid #e5e7eb;">${i.tooltip}</div>`:""}
                <div style="font-size: 11px; color: #9ca3af; margin-top: 6px;">Averaged over ${t.length} ${d.toLowerCase()}</div>
              `).style("left",s.pageX+15+"px").style("top",s.pageY-28+"px")}).on("mousemove",function(e){g.style("left",e.pageX+15+"px").style("top",e.pageY-28+"px")}).on("mouseout",function(){d3.select(this).transition().duration(150).attr("r",n?6:5).attr("fill",s),g.style("opacity",0)})},950)});const R=d3.select(`#legend-${e}`),P=[...b].sort((e,t)=>e===o?-1:t===o?1:0);P.forEach(e=>{const s=E(e),t=e===o,n=R.append("div").attr("class","dline-legend-item").style("font-weight",t?"600":"400").style("color",t?"#7c3aed":"#374151");n.append("div").attr("class","dline-legend-line").style("background-color",s),n.append("span").text(e)})}a()})()</script><h3 id=p50-inter-token-latency>P50 Inter-Token Latency<a hidden class=anchor aria-hidden=true href=#p50-inter-token-latency>#</a></h3><p>This chart shows the median (P50) time between consecutive tokens at different concurrency levels. Lower latency means faster token generation. FP8 maintains consistently lower P50 latency across all concurrency levels, with ~11% improvement at concurrency 64 (13ms vs 14.6ms)</p><div id=chart-p50_latency class=dline-container></div><style>.dline-container{font-family:-apple-system,BlinkMacSystemFont,segoe ui,Roboto,Helvetica,Arial,sans-serif}.dline-controls{display:flex;flex-wrap:wrap;gap:16px;margin-bottom:16px;align-items:flex-start}.dline-control-group{display:flex;flex-direction:column;gap:4px}.dline-control-group>label{font-size:12px;font-weight:600;color:#6b7280;text-transform:uppercase;letter-spacing:.5px}.dline-dropdown{position:relative;min-width:220px}.dline-dropdown-button{width:100%;padding:10px 14px;background:#fff;border:1px solid #d1d5db;border-radius:8px;font-size:14px;cursor:pointer;display:flex;justify-content:space-between;align-items:center;transition:border-color .2s,box-shadow .2s}.dline-dropdown-button:hover{border-color:#9ca3af}.dline-dropdown-button:focus{outline:none;border-color:#6366f1;box-shadow:0 0 0 3px rgba(99,102,241,.1)}.dline-dropdown-menu{position:absolute;top:100%;left:0;right:0;margin-top:4px;background:#fff;border:1px solid #d1d5db;border-radius:8px;box-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -2px rgba(0,0,0,5%);z-index:1000;max-height:300px;overflow-y:auto;display:none}.dline-dropdown-menu.open{display:block}.dline-dropdown-item{padding:10px 14px;cursor:pointer;display:flex;align-items:center;gap:10px;font-size:14px;transition:background .15s}.dline-dropdown-item:hover{background:#f3f4f6}.dline-dropdown-item input[type=checkbox]{width:16px;height:16px;accent-color:#6366f1;cursor:pointer}.dline-dropdown-item label{cursor:pointer;flex:1;font-size:14px;font-weight:400;color:inherit;text-transform:none;letter-spacing:normal}.dline-select-actions{display:flex;gap:8px;padding:10px 14px;border-bottom:1px solid #e5e7eb;background:#f9fafb;border-radius:8px 8px 0 0}.dline-select-actions button{padding:5px 10px;font-size:12px;font-weight:500;background:#fff;border:1px solid #d1d5db;border-radius:4px;cursor:pointer;transition:all .15s}.dline-select-actions button:hover{background:#f3f4f6;border-color:#9ca3af}.dline-chips-section{margin-bottom:16px}.dline-chips-label{font-size:11px;font-weight:600;color:#9ca3af;text-transform:uppercase;letter-spacing:.5px;margin-bottom:6px}.dline-chip-container{display:flex;flex-wrap:wrap;gap:6px}.dline-chip{display:inline-flex;align-items:center;gap:6px;padding:5px 10px;background:#e0e7ff;color:#4338ca;border-radius:20px;font-size:12px;font-weight:500;transition:background .15s}.dline-chip:hover{background:#c7d2fe}.dline-chip.name-chip{background:#fae8ff;color:#a21caf}.dline-chip.name-chip:hover{background:#f5d0fe}.dline-chip.name-chip.highlighted{background:#d8b4fe;color:#6b21a8}.dline-chip-remove{cursor:pointer;opacity:.7;transition:opacity .15s;font-size:14px;line-height:1}.dline-chip-remove:hover{opacity:1}.dline-empty-message{text-align:center;padding:40px;color:#6b7280;font-size:14px}.dline-chart-wrapper{display:flex;justify-content:center;width:100%}.dline-legend{display:flex;flex-wrap:wrap;justify-content:center;gap:16px;margin-top:16px}.dline-legend-item{display:flex;align-items:center;gap:6px;font-size:12px}.dline-legend-line{width:20px;height:3px;border-radius:2px}</style><script src=https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js></script><script>(function(){const e="p50_latency",h=document.getElementById(`chart-${e}`);let c;try{c=JSON.parse(`
[
    { "category": "P50 Latency", "name": "BF16", "x": 1, "y": 6.38 },
    { "category": "P50 Latency", "name": "BF16", "x": 2, "y": 6.54 },
    { "category": "P50 Latency", "name": "BF16", "x": 4, "y": 6.8 },
    { "category": "P50 Latency", "name": "BF16", "x": 8, "y": 7.48 },
    { "category": "P50 Latency", "name": "BF16", "x": 16, "y": 8.51 },
    { "category": "P50 Latency", "name": "BF16", "x": 32, "y": 10.55 },
    { "category": "P50 Latency", "name": "BF16", "x": 64, "y": 14.62 },

    { "category": "P50 Latency", "name": "FP8", "x": 1, "y": 5.3 },
    { "category": "P50 Latency", "name": "FP8", "x": 2, "y": 5.4 },
    { "category": "P50 Latency", "name": "FP8", "x": 4, "y": 5.66 },
    { "category": "P50 Latency", "name": "FP8", "x": 8, "y": 6.16 },
    { "category": "P50 Latency", "name": "FP8", "x": 16, "y": 7.2 },
    { "category": "P50 Latency", "name": "FP8", "x": 32, "y": 9.41 },
    { "category": "P50 Latency", "name": "FP8", "x": 64, "y": 13.02 }
]
`)}catch(e){console.error("Error parsing chart data:",e),c=[]}const d="Metric",p="Model precision",w="Concurrency Level",k="P50 Inter-Token Latency (ms)",F="",M="",y=e=>!e||e.trim()===""?null:e.split(";").map(e=>e.trim()).filter(e=>e.length>0),A=y(F),_=y(M),s=Array.from(new Set(c.map(e=>e.name))),l=Array.from(new Set(c.map(e=>e.category))),z="FP8",o=z||s[0],C=!1,x=!1,N=800,T=500;let t=A?A.filter(e=>l.includes(e)):[...l],n=_?_.filter(e=>s.includes(e)):[...s];const u=document.createElement("div");u.className="dline-controls",h.appendChild(u);function O(t,n,s,o,i){const l=document.createElement("div");l.className="dline-control-group";const g=document.createElement("label");g.textContent=t,l.appendChild(g);const d=document.createElement("div");d.className="dline-dropdown",l.appendChild(d);const r=document.createElement("button");r.className="dline-dropdown-button",r.type="button",d.appendChild(r);function c(){const e=s.length;r.innerHTML=`
        <span>${e} of ${n.length} selected</span>
        <svg width="12" height="12" viewBox="0 0 12 12" fill="none">
          <path d="M3 4.5L6 7.5L9 4.5" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"/>
        </svg>
      `}c();const a=document.createElement("div");a.className="dline-dropdown-menu",d.appendChild(a);const u=document.createElement("div");u.className="dline-select-actions",a.appendChild(u);const h=document.createElement("button");h.type="button",h.textContent="Select All",h.onclick=e=>{e.stopPropagation(),s.length=0,s.push(...n),p(),c(),i()},u.appendChild(h);const m=document.createElement("button");m.type="button",m.textContent="Clear All",m.onclick=e=>{e.stopPropagation(),s.length=0,p(),c(),i()},u.appendChild(m);const f={};n.forEach(t=>{const r=document.createElement("div");r.className="dline-dropdown-item";const n=document.createElement("input");n.type="checkbox",n.id=`${o}-${e}-${t.replace(/[^a-zA-Z0-9]/g,"_")}`,n.checked=s.includes(t),f[t]=n,n.onchange=()=>{if(n.checked)s.includes(t)||s.push(t);else{const e=s.indexOf(t);e>-1&&s.splice(e,1)}c(),i()};const l=document.createElement("label");l.htmlFor=n.id,l.textContent=t,r.appendChild(n),r.appendChild(l),a.appendChild(r)});function p(){n.forEach(e=>{f[e]&&(f[e].checked=s.includes(e))})}return r.onclick=e=>{e.stopPropagation(),document.querySelectorAll(".dline-dropdown-menu.open").forEach(e=>{e!==a&&e.classList.remove("open")}),a.classList.toggle("open")},{element:l,updateButtonText:c,updateCheckboxes:p,getSelected:()=>s}}const i=document.createElement("div");i.className="dline-chips-section";function r(){if(i.innerHTML="",t.length>0&&t.length<l.length){const e=document.createElement("div");e.className="dline-chips-label",e.textContent=d,i.appendChild(e);const n=document.createElement("div");n.className="dline-chip-container",t.forEach(e=>{const s=document.createElement("span");s.className="dline-chip",s.innerHTML=`${e}<span class="dline-chip-remove">×</span>`,s.querySelector(".dline-chip-remove").onclick=()=>{const n=t.indexOf(e);n>-1&&t.splice(n,1),v.updateCheckboxes(),v.updateButtonText(),r(),a()},n.appendChild(s)}),i.appendChild(n)}if(n.length>0&&n.length<s.length){const e=document.createElement("div");e.className="dline-chips-label",e.style.marginTop=t.length>0&&t.length<l.length?"12px":"0",e.textContent=p,i.appendChild(e);const s=document.createElement("div");s.className="dline-chip-container",n.forEach(e=>{const t=document.createElement("span");t.className=`dline-chip name-chip${e===o?" highlighted":""}`,t.innerHTML=`${e}<span class="dline-chip-remove">×</span>`,t.querySelector(".dline-chip-remove").onclick=()=>{const t=n.indexOf(e);t>-1&&n.splice(t,1),f.updateCheckboxes(),f.updateButtonText(),r(),a()},s.appendChild(t)}),i.appendChild(s)}}const v=O(d,l,t,"cat",()=>{r(),a()});u.appendChild(v.element);const f=O(p,s,n,"name",()=>{r(),a()});u.appendChild(f.element),document.addEventListener("click",e=>{e.target.closest(".dline-dropdown")||document.querySelectorAll(".dline-dropdown-menu.open").forEach(e=>{e.classList.remove("open")})}),h.appendChild(i),r();const m=document.createElement("div");m.className="dline-chart-wrapper",h.appendChild(m);const S=document.createElement("div");S.id=`chart-svg-${e}`,m.appendChild(S);const j=document.createElement("div");j.id=`legend-${e}`,j.className="dline-legend",h.appendChild(j);const b=`tooltip-${e}`;if(!document.getElementById(b)){const e=document.createElement("div");e.id=b,e.className="tooltip",e.style.cssText=`
      position: absolute;
      padding: 12px 14px;
      background: #fff;
      border: 1px solid #e5e7eb;
      border-radius: 8px;
      pointer-events: none;
      opacity: 0;
      transition: opacity 0.2s;
      font-family: inherit;
      font-size: 14px;
      box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
      z-index: 10000;
    `,document.body.appendChild(e)}const g=d3.select(`#${b}`),E=e=>{if(e===o)return"#a855f7";const n=s.indexOf(e),i=s.length,t=140-n*60/(i-1||1);return`rgb(${t}, ${t+8}, ${t+16})`},D=e=>{if(e===o)return"#c084fc";const n=s.indexOf(e),i=s.length,a=140-n*60/(i-1||1),t=Math.min(a+30,200);return`rgb(${t}, ${t+8}, ${t+16})`};function a(){if(d3.select(`#chart-svg-${e}`).selectAll("*").remove(),d3.select(`#legend-${e}`).selectAll("*").remove(),t.length===0||n.length===0){const n=document.createElement("div");n.className="dline-empty-message",n.textContent=t.length===0?`Please select at least one ${d.toLowerCase()} to display the chart.`:`Please select at least one ${p.toLowerCase()} to display the chart.`,document.getElementById(`chart-svg-${e}`).appendChild(n);return}const A=c.filter(e=>n.includes(e.name)&&t.includes(e.category));if(A.length===0){const t=document.createElement("div");t.className="dline-empty-message",t.textContent="No data available for the selected filters.",document.getElementById(`chart-svg-${e}`).appendChild(t);return}const v={};n.forEach(e=>{const s=A.filter(t=>t.name===e),t={};s.forEach(e=>{t[e.x]||(t[e.x]={yValues:[],tooltips:[]}),t[e.x].yValues.push(e.y),e.tooltip&&t[e.x].tooltips.push(e.tooltip)});const n=Object.keys(t).map(e=>({x:parseFloat(e),y:t[e].yValues.reduce((e,t)=>e+t,0)/t[e].yValues.length,tooltip:t[e].tooltips.length>0?[...new Set(t[e].tooltips)].join("; "):null})).sort((e,t)=>e.x-t.x);n.length>0&&(v[e]=n)});const b=Object.keys(v);if(b.length===0){const t=document.createElement("div");t.className="dline-empty-message",t.textContent="No data available for the selected filters.",document.getElementById(`chart-svg-${e}`).appendChild(t);return}const s={top:30,right:30,bottom:60,left:70},f=N-s.left-s.right,a=T-s.top-s.bottom,y=Object.values(v).flat(),r=y.map(e=>e.x),u=y.map(e=>e.y),h=r.every(e=>Number.isInteger(e)),_=[...new Set(r)].sort((e,t)=>e-t),O=(Math.max(...u)-Math.min(...u))*.1||10,z=Math.max(0,Math.min(...u)-O),S=Math.max(...u)+O,i=d3.select(`#chart-svg-${e}`).append("svg").attr("width",f+s.left+s.right).attr("height",a+s.top+s.bottom).append("g").attr("transform",`translate(${s.left},${s.top})`);let l;const j=(Math.max(...r)-Math.min(...r))*.05||1,M=Math.min(...r)-j,F=Math.max(...r)+j;l=d3.scaleLinear().domain([M,F]).range([0,f]);const m=d3.scaleLinear().domain([z,S]).range([a,0]);i.append("g").attr("class","grid").attr("transform",`translate(0,${a})`).call(d3.axisBottom(l).tickSize(-a).tickFormat("").tickValues(h?_:null)).selectAll("line").style("stroke","#f3f4f6").style("stroke-width",1),i.append("g").attr("class","grid").call(d3.axisLeft(m).tickSize(-f).tickFormat("")).selectAll("line").style("stroke","#f3f4f6").style("stroke-width",1),i.selectAll(".grid").select(".domain").remove(),i.append("g").attr("transform",`translate(0,${a})`).call(d3.axisBottom(l).tickValues(h?_:null).tickFormat(e=>x?e+"%":h?e:d3.format(".1f")(e))).selectAll("text").style("font-family","inherit").style("fill","#6b7280"),i.append("g").call(d3.axisLeft(m).tickFormat(e=>C?d3.format(".0f")(e)+"%":d3.format(".1f")(e))).selectAll("text").style("font-family","inherit").style("fill","#6b7280"),i.append("text").attr("text-anchor","middle").attr("x",f/2).attr("y",a+s.bottom-15).text(w).style("font-family","inherit").style("font-size","13px").style("fill","#6b7280"),i.append("text").attr("text-anchor","middle").attr("transform","rotate(-90)").attr("x",-a/2).attr("y",-s.left+20).text(k).style("font-family","inherit").style("font-size","13px").style("fill","#6b7280");const L=d3.line().x(e=>l(e.x)).y(e=>m(e.y)).curve(d3.curveMonotoneX);b.forEach(e=>{const r=v[e],s=E(e),n=e===o,c=i.append("path").datum(r).attr("class",`line-${e.replace(/[^a-zA-Z0-9]/g,"_")}`).attr("fill","none").attr("stroke",s).attr("stroke-width",n?3:2).attr("d",L),a=c.node().getTotalLength();c.attr("stroke-dasharray",`${a} ${a}`).attr("stroke-dashoffset",a).transition().duration(800).ease(d3.easeCubicOut).attr("stroke-dashoffset",0),i.selectAll(`.point-${e.replace(/[^a-zA-Z0-9]/g,"_")}`).data(r).enter().append("circle").attr("class",`point-${e.replace(/[^a-zA-Z0-9]/g,"_")}`).attr("cx",e=>l(e.x)).attr("cy",e=>m(e.y)).attr("r",0).attr("fill",s).attr("stroke","#fff").attr("stroke-width",2).style("cursor","pointer").transition().delay(600).duration(300).attr("r",n?6:5),setTimeout(()=>{i.selectAll(`.point-${e.replace(/[^a-zA-Z0-9]/g,"_")}`).on("mouseover",function(s,i){d3.select(this).transition().duration(150).attr("r",n?8:7).attr("fill",D(e));const a=C?`${i.y.toFixed(2)}%`:i.y.toFixed(2),r=x?`${i.x}%`:h?i.x:i.x.toFixed(2);g.style("opacity",1).html(`
                <div style="font-weight: 600; font-size: 15px; margin-bottom: 6px; color: ${e===o?"#7c3aed":"#111827"};">${e}</div>
                <div style="font-size: 13px; color: #374151;"><strong>${w}:</strong> ${r}</div>
                <div style="font-size: 13px; color: #374151;"><strong>${k}:</strong> ${a}</div>
                ${i.tooltip?`<div style="font-size: 12px; color: #6b7280; margin-top: 6px; padding-top: 6px; border-top: 1px solid #e5e7eb;">${i.tooltip}</div>`:""}
                <div style="font-size: 11px; color: #9ca3af; margin-top: 6px;">Averaged over ${t.length} ${d.toLowerCase()}</div>
              `).style("left",s.pageX+15+"px").style("top",s.pageY-28+"px")}).on("mousemove",function(e){g.style("left",e.pageX+15+"px").style("top",e.pageY-28+"px")}).on("mouseout",function(){d3.select(this).transition().duration(150).attr("r",n?6:5).attr("fill",s),g.style("opacity",0)})},950)});const R=d3.select(`#legend-${e}`),P=[...b].sort((e,t)=>e===o?-1:t===o?1:0);P.forEach(e=>{const s=E(e),t=e===o,n=R.append("div").attr("class","dline-legend-item").style("font-weight",t?"600":"400").style("color",t?"#7c3aed":"#374151");n.append("div").attr("class","dline-legend-line").style("background-color",s),n.append("span").text(e)})}a()})()</script><h3 id=time-to-first-token-ttft>Time to First Token (TTFT)<a hidden class=anchor aria-hidden=true href=#time-to-first-token-ttft>#</a></h3><p>This chart measures the average time until the first token is generated after receiving a request. Lower TTFT is critical for perceived responsiveness. FP8 reduces TTFT by up to 28% at high concurrency (686.2ms vs 954.3ms at concurrency 64), significantly improving user experience.</p><div id=chart-ttft class=dline-container></div><style>.dline-container{font-family:-apple-system,BlinkMacSystemFont,segoe ui,Roboto,Helvetica,Arial,sans-serif}.dline-controls{display:flex;flex-wrap:wrap;gap:16px;margin-bottom:16px;align-items:flex-start}.dline-control-group{display:flex;flex-direction:column;gap:4px}.dline-control-group>label{font-size:12px;font-weight:600;color:#6b7280;text-transform:uppercase;letter-spacing:.5px}.dline-dropdown{position:relative;min-width:220px}.dline-dropdown-button{width:100%;padding:10px 14px;background:#fff;border:1px solid #d1d5db;border-radius:8px;font-size:14px;cursor:pointer;display:flex;justify-content:space-between;align-items:center;transition:border-color .2s,box-shadow .2s}.dline-dropdown-button:hover{border-color:#9ca3af}.dline-dropdown-button:focus{outline:none;border-color:#6366f1;box-shadow:0 0 0 3px rgba(99,102,241,.1)}.dline-dropdown-menu{position:absolute;top:100%;left:0;right:0;margin-top:4px;background:#fff;border:1px solid #d1d5db;border-radius:8px;box-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -2px rgba(0,0,0,5%);z-index:1000;max-height:300px;overflow-y:auto;display:none}.dline-dropdown-menu.open{display:block}.dline-dropdown-item{padding:10px 14px;cursor:pointer;display:flex;align-items:center;gap:10px;font-size:14px;transition:background .15s}.dline-dropdown-item:hover{background:#f3f4f6}.dline-dropdown-item input[type=checkbox]{width:16px;height:16px;accent-color:#6366f1;cursor:pointer}.dline-dropdown-item label{cursor:pointer;flex:1;font-size:14px;font-weight:400;color:inherit;text-transform:none;letter-spacing:normal}.dline-select-actions{display:flex;gap:8px;padding:10px 14px;border-bottom:1px solid #e5e7eb;background:#f9fafb;border-radius:8px 8px 0 0}.dline-select-actions button{padding:5px 10px;font-size:12px;font-weight:500;background:#fff;border:1px solid #d1d5db;border-radius:4px;cursor:pointer;transition:all .15s}.dline-select-actions button:hover{background:#f3f4f6;border-color:#9ca3af}.dline-chips-section{margin-bottom:16px}.dline-chips-label{font-size:11px;font-weight:600;color:#9ca3af;text-transform:uppercase;letter-spacing:.5px;margin-bottom:6px}.dline-chip-container{display:flex;flex-wrap:wrap;gap:6px}.dline-chip{display:inline-flex;align-items:center;gap:6px;padding:5px 10px;background:#e0e7ff;color:#4338ca;border-radius:20px;font-size:12px;font-weight:500;transition:background .15s}.dline-chip:hover{background:#c7d2fe}.dline-chip.name-chip{background:#fae8ff;color:#a21caf}.dline-chip.name-chip:hover{background:#f5d0fe}.dline-chip.name-chip.highlighted{background:#d8b4fe;color:#6b21a8}.dline-chip-remove{cursor:pointer;opacity:.7;transition:opacity .15s;font-size:14px;line-height:1}.dline-chip-remove:hover{opacity:1}.dline-empty-message{text-align:center;padding:40px;color:#6b7280;font-size:14px}.dline-chart-wrapper{display:flex;justify-content:center;width:100%}.dline-legend{display:flex;flex-wrap:wrap;justify-content:center;gap:16px;margin-top:16px}.dline-legend-item{display:flex;align-items:center;gap:6px;font-size:12px}.dline-legend-line{width:20px;height:3px;border-radius:2px}</style><script src=https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js></script><script>(function(){const e="ttft",h=document.getElementById(`chart-${e}`);let c;try{c=JSON.parse(`
[
    { "category": "TTFT", "name": "BF16", "x": 1, "y": 88.78 },
    { "category": "TTFT", "name": "BF16", "x": 2, "y": 168.49 },
    { "category": "TTFT", "name": "BF16", "x": 4, "y": 169.49 },
    { "category": "TTFT", "name": "BF16", "x": 8, "y": 260.83 },
    { "category": "TTFT", "name": "BF16", "x": 16, "y": 452.54 },
    { "category": "TTFT", "name": "BF16", "x": 32, "y": 703.05 },
    { "category": "TTFT", "name": "BF16", "x": 64, "y": 954.33 },

    { "category": "TTFT", "name": "FP8", "x": 1, "y": 81.87 },
    { "category": "TTFT", "name": "FP8", "x": 2, "y": 148.94 },
    { "category": "TTFT", "name": "FP8", "x": 4, "y": 145.58 },
    { "category": "TTFT", "name": "FP8", "x": 8, "y": 211.61 },
    { "category": "TTFT", "name": "FP8", "x": 16, "y": 415.61 },
    { "category": "TTFT", "name": "FP8", "x": 32, "y": 494.89 },
    { "category": "TTFT", "name": "FP8", "x": 64, "y": 686.2 }
]
`)}catch(e){console.error("Error parsing chart data:",e),c=[]}const d="Metric",p="Model precision",w="Concurrency Level",k="Avg Time to First Token (ms)",F="",M="",y=e=>!e||e.trim()===""?null:e.split(";").map(e=>e.trim()).filter(e=>e.length>0),A=y(F),_=y(M),s=Array.from(new Set(c.map(e=>e.name))),l=Array.from(new Set(c.map(e=>e.category))),z="FP8",o=z||s[0],C=!1,x=!1,N=800,T=500;let t=A?A.filter(e=>l.includes(e)):[...l],n=_?_.filter(e=>s.includes(e)):[...s];const u=document.createElement("div");u.className="dline-controls",h.appendChild(u);function O(t,n,s,o,i){const l=document.createElement("div");l.className="dline-control-group";const g=document.createElement("label");g.textContent=t,l.appendChild(g);const d=document.createElement("div");d.className="dline-dropdown",l.appendChild(d);const r=document.createElement("button");r.className="dline-dropdown-button",r.type="button",d.appendChild(r);function c(){const e=s.length;r.innerHTML=`
        <span>${e} of ${n.length} selected</span>
        <svg width="12" height="12" viewBox="0 0 12 12" fill="none">
          <path d="M3 4.5L6 7.5L9 4.5" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"/>
        </svg>
      `}c();const a=document.createElement("div");a.className="dline-dropdown-menu",d.appendChild(a);const u=document.createElement("div");u.className="dline-select-actions",a.appendChild(u);const h=document.createElement("button");h.type="button",h.textContent="Select All",h.onclick=e=>{e.stopPropagation(),s.length=0,s.push(...n),p(),c(),i()},u.appendChild(h);const m=document.createElement("button");m.type="button",m.textContent="Clear All",m.onclick=e=>{e.stopPropagation(),s.length=0,p(),c(),i()},u.appendChild(m);const f={};n.forEach(t=>{const r=document.createElement("div");r.className="dline-dropdown-item";const n=document.createElement("input");n.type="checkbox",n.id=`${o}-${e}-${t.replace(/[^a-zA-Z0-9]/g,"_")}`,n.checked=s.includes(t),f[t]=n,n.onchange=()=>{if(n.checked)s.includes(t)||s.push(t);else{const e=s.indexOf(t);e>-1&&s.splice(e,1)}c(),i()};const l=document.createElement("label");l.htmlFor=n.id,l.textContent=t,r.appendChild(n),r.appendChild(l),a.appendChild(r)});function p(){n.forEach(e=>{f[e]&&(f[e].checked=s.includes(e))})}return r.onclick=e=>{e.stopPropagation(),document.querySelectorAll(".dline-dropdown-menu.open").forEach(e=>{e!==a&&e.classList.remove("open")}),a.classList.toggle("open")},{element:l,updateButtonText:c,updateCheckboxes:p,getSelected:()=>s}}const i=document.createElement("div");i.className="dline-chips-section";function r(){if(i.innerHTML="",t.length>0&&t.length<l.length){const e=document.createElement("div");e.className="dline-chips-label",e.textContent=d,i.appendChild(e);const n=document.createElement("div");n.className="dline-chip-container",t.forEach(e=>{const s=document.createElement("span");s.className="dline-chip",s.innerHTML=`${e}<span class="dline-chip-remove">×</span>`,s.querySelector(".dline-chip-remove").onclick=()=>{const n=t.indexOf(e);n>-1&&t.splice(n,1),v.updateCheckboxes(),v.updateButtonText(),r(),a()},n.appendChild(s)}),i.appendChild(n)}if(n.length>0&&n.length<s.length){const e=document.createElement("div");e.className="dline-chips-label",e.style.marginTop=t.length>0&&t.length<l.length?"12px":"0",e.textContent=p,i.appendChild(e);const s=document.createElement("div");s.className="dline-chip-container",n.forEach(e=>{const t=document.createElement("span");t.className=`dline-chip name-chip${e===o?" highlighted":""}`,t.innerHTML=`${e}<span class="dline-chip-remove">×</span>`,t.querySelector(".dline-chip-remove").onclick=()=>{const t=n.indexOf(e);t>-1&&n.splice(t,1),f.updateCheckboxes(),f.updateButtonText(),r(),a()},s.appendChild(t)}),i.appendChild(s)}}const v=O(d,l,t,"cat",()=>{r(),a()});u.appendChild(v.element);const f=O(p,s,n,"name",()=>{r(),a()});u.appendChild(f.element),document.addEventListener("click",e=>{e.target.closest(".dline-dropdown")||document.querySelectorAll(".dline-dropdown-menu.open").forEach(e=>{e.classList.remove("open")})}),h.appendChild(i),r();const m=document.createElement("div");m.className="dline-chart-wrapper",h.appendChild(m);const S=document.createElement("div");S.id=`chart-svg-${e}`,m.appendChild(S);const j=document.createElement("div");j.id=`legend-${e}`,j.className="dline-legend",h.appendChild(j);const b=`tooltip-${e}`;if(!document.getElementById(b)){const e=document.createElement("div");e.id=b,e.className="tooltip",e.style.cssText=`
      position: absolute;
      padding: 12px 14px;
      background: #fff;
      border: 1px solid #e5e7eb;
      border-radius: 8px;
      pointer-events: none;
      opacity: 0;
      transition: opacity 0.2s;
      font-family: inherit;
      font-size: 14px;
      box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
      z-index: 10000;
    `,document.body.appendChild(e)}const g=d3.select(`#${b}`),E=e=>{if(e===o)return"#a855f7";const n=s.indexOf(e),i=s.length,t=140-n*60/(i-1||1);return`rgb(${t}, ${t+8}, ${t+16})`},D=e=>{if(e===o)return"#c084fc";const n=s.indexOf(e),i=s.length,a=140-n*60/(i-1||1),t=Math.min(a+30,200);return`rgb(${t}, ${t+8}, ${t+16})`};function a(){if(d3.select(`#chart-svg-${e}`).selectAll("*").remove(),d3.select(`#legend-${e}`).selectAll("*").remove(),t.length===0||n.length===0){const n=document.createElement("div");n.className="dline-empty-message",n.textContent=t.length===0?`Please select at least one ${d.toLowerCase()} to display the chart.`:`Please select at least one ${p.toLowerCase()} to display the chart.`,document.getElementById(`chart-svg-${e}`).appendChild(n);return}const A=c.filter(e=>n.includes(e.name)&&t.includes(e.category));if(A.length===0){const t=document.createElement("div");t.className="dline-empty-message",t.textContent="No data available for the selected filters.",document.getElementById(`chart-svg-${e}`).appendChild(t);return}const v={};n.forEach(e=>{const s=A.filter(t=>t.name===e),t={};s.forEach(e=>{t[e.x]||(t[e.x]={yValues:[],tooltips:[]}),t[e.x].yValues.push(e.y),e.tooltip&&t[e.x].tooltips.push(e.tooltip)});const n=Object.keys(t).map(e=>({x:parseFloat(e),y:t[e].yValues.reduce((e,t)=>e+t,0)/t[e].yValues.length,tooltip:t[e].tooltips.length>0?[...new Set(t[e].tooltips)].join("; "):null})).sort((e,t)=>e.x-t.x);n.length>0&&(v[e]=n)});const b=Object.keys(v);if(b.length===0){const t=document.createElement("div");t.className="dline-empty-message",t.textContent="No data available for the selected filters.",document.getElementById(`chart-svg-${e}`).appendChild(t);return}const s={top:30,right:30,bottom:60,left:70},f=N-s.left-s.right,a=T-s.top-s.bottom,y=Object.values(v).flat(),r=y.map(e=>e.x),u=y.map(e=>e.y),h=r.every(e=>Number.isInteger(e)),_=[...new Set(r)].sort((e,t)=>e-t),O=(Math.max(...u)-Math.min(...u))*.1||10,z=Math.max(0,Math.min(...u)-O),S=Math.max(...u)+O,i=d3.select(`#chart-svg-${e}`).append("svg").attr("width",f+s.left+s.right).attr("height",a+s.top+s.bottom).append("g").attr("transform",`translate(${s.left},${s.top})`);let l;const j=(Math.max(...r)-Math.min(...r))*.05||1,M=Math.min(...r)-j,F=Math.max(...r)+j;l=d3.scaleLinear().domain([M,F]).range([0,f]);const m=d3.scaleLinear().domain([z,S]).range([a,0]);i.append("g").attr("class","grid").attr("transform",`translate(0,${a})`).call(d3.axisBottom(l).tickSize(-a).tickFormat("").tickValues(h?_:null)).selectAll("line").style("stroke","#f3f4f6").style("stroke-width",1),i.append("g").attr("class","grid").call(d3.axisLeft(m).tickSize(-f).tickFormat("")).selectAll("line").style("stroke","#f3f4f6").style("stroke-width",1),i.selectAll(".grid").select(".domain").remove(),i.append("g").attr("transform",`translate(0,${a})`).call(d3.axisBottom(l).tickValues(h?_:null).tickFormat(e=>x?e+"%":h?e:d3.format(".1f")(e))).selectAll("text").style("font-family","inherit").style("fill","#6b7280"),i.append("g").call(d3.axisLeft(m).tickFormat(e=>C?d3.format(".0f")(e)+"%":d3.format(".1f")(e))).selectAll("text").style("font-family","inherit").style("fill","#6b7280"),i.append("text").attr("text-anchor","middle").attr("x",f/2).attr("y",a+s.bottom-15).text(w).style("font-family","inherit").style("font-size","13px").style("fill","#6b7280"),i.append("text").attr("text-anchor","middle").attr("transform","rotate(-90)").attr("x",-a/2).attr("y",-s.left+20).text(k).style("font-family","inherit").style("font-size","13px").style("fill","#6b7280");const L=d3.line().x(e=>l(e.x)).y(e=>m(e.y)).curve(d3.curveMonotoneX);b.forEach(e=>{const r=v[e],s=E(e),n=e===o,c=i.append("path").datum(r).attr("class",`line-${e.replace(/[^a-zA-Z0-9]/g,"_")}`).attr("fill","none").attr("stroke",s).attr("stroke-width",n?3:2).attr("d",L),a=c.node().getTotalLength();c.attr("stroke-dasharray",`${a} ${a}`).attr("stroke-dashoffset",a).transition().duration(800).ease(d3.easeCubicOut).attr("stroke-dashoffset",0),i.selectAll(`.point-${e.replace(/[^a-zA-Z0-9]/g,"_")}`).data(r).enter().append("circle").attr("class",`point-${e.replace(/[^a-zA-Z0-9]/g,"_")}`).attr("cx",e=>l(e.x)).attr("cy",e=>m(e.y)).attr("r",0).attr("fill",s).attr("stroke","#fff").attr("stroke-width",2).style("cursor","pointer").transition().delay(600).duration(300).attr("r",n?6:5),setTimeout(()=>{i.selectAll(`.point-${e.replace(/[^a-zA-Z0-9]/g,"_")}`).on("mouseover",function(s,i){d3.select(this).transition().duration(150).attr("r",n?8:7).attr("fill",D(e));const a=C?`${i.y.toFixed(2)}%`:i.y.toFixed(2),r=x?`${i.x}%`:h?i.x:i.x.toFixed(2);g.style("opacity",1).html(`
                <div style="font-weight: 600; font-size: 15px; margin-bottom: 6px; color: ${e===o?"#7c3aed":"#111827"};">${e}</div>
                <div style="font-size: 13px; color: #374151;"><strong>${w}:</strong> ${r}</div>
                <div style="font-size: 13px; color: #374151;"><strong>${k}:</strong> ${a}</div>
                ${i.tooltip?`<div style="font-size: 12px; color: #6b7280; margin-top: 6px; padding-top: 6px; border-top: 1px solid #e5e7eb;">${i.tooltip}</div>`:""}
                <div style="font-size: 11px; color: #9ca3af; margin-top: 6px;">Averaged over ${t.length} ${d.toLowerCase()}</div>
              `).style("left",s.pageX+15+"px").style("top",s.pageY-28+"px")}).on("mousemove",function(e){g.style("left",e.pageX+15+"px").style("top",e.pageY-28+"px")}).on("mouseout",function(){d3.select(this).transition().duration(150).attr("r",n?6:5).attr("fill",s),g.style("opacity",0)})},950)});const R=d3.select(`#legend-${e}`),P=[...b].sort((e,t)=>e===o?-1:t===o?1:0);P.forEach(e=>{const s=E(e),t=e===o,n=R.append("div").attr("class","dline-legend-item").style("font-weight",t?"600":"400").style("color",t?"#7c3aed":"#374151");n.append("div").attr("class","dline-legend-line").style("background-color",s),n.append("span").text(e)})}a()})()</script><h1 id=fp8-post-training-quantization-processwith-nvidia-model-optimizer>FP8 Post-Training Quantization Process with NVIDIA Model Optimizer<a hidden class=anchor aria-hidden=true href=#fp8-post-training-quantization-processwith-nvidia-model-optimizer>#</a></h1><p>This section details the optimization of Falcon-H1R-7B’s inference performance through FP8 Post-Training Quantization (PTQ). To achieve this, we utilized <a href=https://github.com/NVIDIA/Model-Optimizer>NVIDIA Model Optimizer</a> (ModelOpt), an open-sourced unified library designed to accelerate AI inference by compressing models using state-of-the-art optimization techniques. ModelOpt is an essential toolkit for efficient downstream deployment on NVIDIA hardware compatible with frameworks such as vLLM, TensorRT-LLM, SGLang and Dynamo.</p><p>While ModelOpt supports various optimization strategies such as structured pruning and knowledge distillation, we focused specifically on PTQ, which offers the fastest path to model optimization by compressing weights from higher precisions (like FP16 or BF16) down to FP8 using a small calibration dataset. This conversion significantly reduces the model’s size and computational requirement, enabling higher inference throughput and reduced latency.</p><h2 id=pertensor-fp8-posttraining-quantization>Per‑Tensor FP8 Post‑Training Quantization<a hidden class=anchor aria-hidden=true href=#pertensor-fp8-posttraining-quantization>#</a></h2><p>ModelOpt supports FP8 recipes with different granularities balancing inference performance and model accuracy preservation. For this specific implementation, we employed Per-Tensor FP8 quantization, a technique where a single scaling factor is calculated for an entire tensor to map high-precision values into the 8-bit format. To generate these scales, ModelOpt executes a calibration step using either a public dataset or a custom dataset. To quantize Falcon-H1R-7B, the team used the default calibration dataset comprising of cnn_dailymail and <a href=https://huggingface.co/datasets/nvidia/Nemotron-Post-Training-Dataset-v2>nemotron-post-training-dataset-v2</a>. During this process, ModelOpt analyzes the dynamic range of activations and weights to determine the optimal static scaling factors that minimize accuracy degradation. The final output is a quantized checkpoint containing the FP8 weights and the scaling factors for weights and activations, ready to be built into an inference engine for efficient deployment.</p><h2 id=quantization-steps>Quantization Steps<a hidden class=anchor aria-hidden=true href=#quantization-steps>#</a></h2><p>We started from our pre-trained checkpoint and applied per-tensor FP8 quantization using ModelOpt’s LLM quantization pipeline steps. In addition, we also quantize the KV cache to FP8 in order to save more memory footprint.</p><h3 id=environment-setup>Environment Setup<a hidden class=anchor aria-hidden=true href=#environment-setup>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Start from a vLLM-enabled Docker image</span>
</span></span><span class=line><span class=cl>docker run --gpus all -it vllm/vllm-openai:latest
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Clone NVIDIA Model Optimizer</span>
</span></span><span class=line><span class=cl>git clone https://github.com/NVIDIA/Model-Optimizer.git
</span></span><span class=line><span class=cl><span class=nb>cd</span> Model-Optimizer
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Checkout to the most recent stable branch</span>
</span></span><span class=line><span class=cl>git checkout 0.39.0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install Model Optimizer with development dependencies</span>
</span></span><span class=line><span class=cl>pip install -e .<span class=o>[</span>dev<span class=o>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Navigate to the LLM PTQ example directory</span>
</span></span><span class=line><span class=cl><span class=nb>cd</span> examples/llm_ptq
</span></span></code></pre></div><h3 id=applying-fp8-post-training-quantization>Applying FP8 Post-Training Quantization<a hidden class=anchor aria-hidden=true href=#applying-fp8-post-training-quantization>#</a></h3><p>We can directly apply FP8 quantization on Falcon-H1R-7B model using:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python3 hf_ptq.py <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --pyt_ckpt_path<span class=o>=</span>/path/to/your/hf/checkpoint/ <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --export_path<span class=o>=</span>/path/to/save/fp8_quantized_model/ <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --qformat<span class=o>=</span>fp8 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --kv_cache_qformat<span class=o>=</span>fp8 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --calib_size<span class=o>=</span><span class=m>512</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --batch_size<span class=o>=</span><span class=m>0</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --inference_tensor_parallel<span class=o>=</span><span class=m>1</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --inference_pipeline_parallel<span class=o>=</span><span class=m>1</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --export_fmt<span class=o>=</span>hf <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --trust_remote_code
</span></span></code></pre></div><p>Key flags of the FP8 quantization process:</p><ul><li><code>--qformat=fp8</code>: applies per-tensor FP8 quantization to all model weights</li><li><code>--kv_cache_qformat=fp8</code>: quantizes the KV cache to FP8</li><li><code>--calib_size=512</code>: selects the samples to pass for the scales calibration, usually 512 are enough</li><li><code>--batch_size=0</code>: automatically find the maximum batch size</li><li><code>--inference_tensor_parallel & --inference_pipeline_parallel</code>: can be tuned if your model doesn’t fit in 1 GPU for the calibration process</li></ul><h1 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h1><p><span class=bold>Falcon H1R 7B FP8</span> preserves BF16 accuracy while cutting weight memory to 7.9 GB (≈44 %) and boosting throughput by ~20–30 % on H100/H200 GPUs.
It therefore enables high‑scale, low‑VRAM inference without sacrificing performance.</p><h1 id=citation>Citation<a hidden class=anchor aria-hidden=true href=#citation>#</a></h1><div class=highlight><pre tabindex=0 class=chroma><code class=language-latex data-lang=latex><span class=line><span class=cl>@article<span class=nb>{</span>falcon-h1r-fp8,
</span></span><span class=line><span class=cl>  title=<span class=nb>{</span>Falcon H1R 7B FP8<span class=nb>}</span>,
</span></span><span class=line><span class=cl>  author=<span class=nb>{</span>TII and NVIDIA<span class=nb>}</span>,
</span></span><span class=line><span class=cl>  url=<span class=nb>{</span>https://falcon-lm.github.io/blog/falcon-h1r-7b-fp8<span class=nb>}</span>,
</span></span><span class=line><span class=cl>  year=<span class=nb>{</span>2026<span class=nb>}</span>
</span></span><span class=line><span class=cl><span class=nb>}</span>
</span></span></code></pre></div><div class=post-contributors><div class=contributors-section><h4>Contributors - TII</h4><div class=contributors-grid><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/puneesh_khanna.jpg alt="Puneesh Khanna" class=contributor-image><p class=contributor-name>Puneesh Khanna</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/slim_frikha.jpg alt="Slim Frikha" class=contributor-image><p class=contributor-name>Slim Frikha</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/iheb_chaabane.jpg alt="Iheb Chaabane" class=contributor-image><p class=contributor-name>Iheb Chaabane</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/mohamed_seddik.png alt="Mohamed El Amine Seddik" class=contributor-image><p class=contributor-name>Mohamed El Amine Seddik</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/saarah_abdulla.png alt="Saarah Abdulla" class=contributor-image><p class=contributor-name>Saarah Abdulla</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/hakim_hacid.png alt="Hakim Hacid" class=contributor-image><p class=contributor-name>Hakim Hacid</p></div></div></div><div class=contributors-section><h4>Contributors - NVIDIA</h4><div class=contributors-grid><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/default.png alt="Sergio Perez" class=contributor-image><p class=contributor-name>Sergio Perez</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/default.png alt="Mireille Fares" class=contributor-image><p class=contributor-name>Mireille Fares</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/default.png alt="Liana Mikaelyan" class=contributor-image><p class=contributor-name>Liana Mikaelyan</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/default.png alt="Amit Kushwaha" class=contributor-image><p class=contributor-name>Amit Kushwaha</p></div></div></div></div></div></article></main><footer class=footer><span>&copy; 2026 <a href=https://falcon-lm.github.io/>Falcon</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a>
</span><span><a href=https://falconllm.tii.ae/falcon-terms-and-conditions.html rel="noopener noreferrer" target=_blank>| Terms and Conditions</a>
</span><span><a href=https://www.tii.ae/privacy-policy rel="noopener noreferrer" target=_blank>| Privacy Policy</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)"}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>