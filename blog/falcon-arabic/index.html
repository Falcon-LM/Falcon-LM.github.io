<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><script>!function(e,t){if(!e.rdt){var s,o,n=e.rdt=function(){n.sendEvent?n.sendEvent.apply(n,arguments):n.callQueue.push(arguments)};n.callQueue=[],s=t.createElement("script"),s.src="https://www.redditstatic.com/ads/pixel.js",s.async=!0,o=t.getElementsByTagName("script")[0],o.parentNode.insertBefore(s,o)}}(window,document),rdt("init","a2_f0we4sxffrnm"),rdt("track","PageVisit")</script><script async src="https://www.googletagmanager.com/gtag/js?id=AW-16575356988"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","AW-16575356988")</script><title>Falcon-Arabic: A Breakthrough in Arabic Language Models | Falcon</title>
<meta name=keywords content><meta name=description content="
Check out the Arabic version translated by Falcon-Arabic
We are excited to introduce Falcon-Arabic, a 7B parameter Language Model that sets a new benchmark for Arabic NLP. Built on the Falcon 3 architecture, Falcon-Arabic is a multilingual model that supports Arabic, English, and several other languages. It excels in general knowledge, Arabic grammar, mathematical reasoning, complex problem solving, and understanding the rich diversity of Arabic dialects. Falcon-Arabic supports a context length of 32,000 tokens, allowing it to handle long documents and enabling advanced applications like retrieval-augmented generation (RAG), in-depth content creation, and knowledge-intensive tasks."><meta name=author content="Falcon Team"><link rel=canonical href=https://falcon-lm.github.io/blog/falcon-arabic/><link crossorigin=anonymous href=/assets/css/stylesheet.8b9fa41d05770f933657a6befdf3e59416a8572dcdccb2def3ee65a2976037d3.css integrity="sha256-i5+kHQV3D5M2V6a+/fPllBaoVy3NzLLe8+5lopdgN9M=" rel="preload stylesheet" as=style><link rel=icon href=https://falcon-lm.github.io/img/favicon.png><link rel=apple-touch-icon href=https://falcon-lm.github.io/img/favicon.png><link rel=manifest href=https://falcon-lm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate hreflang=en href=https://falcon-lm.github.io/blog/falcon-arabic/><link rel=alternate hreflang=ar href=https://falcon-lm.github.io/ar/blog/falcon-arabic/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.c0c4976150cc57e4e574f010d054d68896d28645b524650723d1cbb26891c0a3.js integrity="sha256-wMSXYVDMV+TldPAQ0FTWiJbShkW1JGUHI9HLsmiRwKM="></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-5PVYBMYHS6"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-5PVYBMYHS6")}</script><meta property="og:title" content="Falcon-Arabic: A Breakthrough in Arabic Language Models"><meta property="og:description" content="
Check out the Arabic version translated by Falcon-Arabic
We are excited to introduce Falcon-Arabic, a 7B parameter Language Model that sets a new benchmark for Arabic NLP. Built on the Falcon 3 architecture, Falcon-Arabic is a multilingual model that supports Arabic, English, and several other languages. It excels in general knowledge, Arabic grammar, mathematical reasoning, complex problem solving, and understanding the rich diversity of Arabic dialects. Falcon-Arabic supports a context length of 32,000 tokens, allowing it to handle long documents and enabling advanced applications like retrieval-augmented generation (RAG), in-depth content creation, and knowledge-intensive tasks."><meta property="og:type" content="article"><meta property="og:url" content="https://falcon-lm.github.io/blog/falcon-arabic/"><meta property="og:image" content="https://falcon-lm.github.io/blog/falcon-arabic/cover_1.png"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-05-21T12:00:00+00:00"><meta property="article:modified_time" content="2025-05-21T12:00:00+00:00"><meta property="og:site_name" content="Falcon"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://falcon-lm.github.io/blog/falcon-arabic/cover_1.png"><meta name=twitter:title content="Falcon-Arabic: A Breakthrough in Arabic Language Models"><meta name=twitter:description content="
Check out the Arabic version translated by Falcon-Arabic
We are excited to introduce Falcon-Arabic, a 7B parameter Language Model that sets a new benchmark for Arabic NLP. Built on the Falcon 3 architecture, Falcon-Arabic is a multilingual model that supports Arabic, English, and several other languages. It excels in general knowledge, Arabic grammar, mathematical reasoning, complex problem solving, and understanding the rich diversity of Arabic dialects. Falcon-Arabic supports a context length of 32,000 tokens, allowing it to handle long documents and enabling advanced applications like retrieval-augmented generation (RAG), in-depth content creation, and knowledge-intensive tasks."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://falcon-lm.github.io/blog/"},{"@type":"ListItem","position":2,"name":"Falcon-Arabic: A Breakthrough in Arabic Language Models","item":"https://falcon-lm.github.io/blog/falcon-arabic/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Falcon-Arabic: A Breakthrough in Arabic Language Models","name":"Falcon-Arabic: A Breakthrough in Arabic Language Models","description":" Check out the Arabic version translated by Falcon-Arabic\nWe are excited to introduce Falcon-Arabic, a 7B parameter Language Model that sets a new benchmark for Arabic NLP. Built on the Falcon 3 architecture, Falcon-Arabic is a multilingual model that supports Arabic, English, and several other languages. It excels in general knowledge, Arabic grammar, mathematical reasoning, complex problem solving, and understanding the rich diversity of Arabic dialects. Falcon-Arabic supports a context length of 32,000 tokens, allowing it to handle long documents and enabling advanced applications like retrieval-augmented generation (RAG), in-depth content creation, and knowledge-intensive tasks.\n","keywords":[],"articleBody":" Check out the Arabic version translated by Falcon-Arabic\nWe are excited to introduce Falcon-Arabic, a 7B parameter Language Model that sets a new benchmark for Arabic NLP. Built on the Falcon 3 architecture, Falcon-Arabic is a multilingual model that supports Arabic, English, and several other languages. It excels in general knowledge, Arabic grammar, mathematical reasoning, complex problem solving, and understanding the rich diversity of Arabic dialects. Falcon-Arabic supports a context length of 32,000 tokens, allowing it to handle long documents and enabling advanced applications like retrieval-augmented generation (RAG), in-depth content creation, and knowledge-intensive tasks.\nFalcon-Arabic redefines the boundaries of what is possible for Arabic Language Models. It significantly outperforms other Arabic LLMs in its size category and even models up to four times larger across both Arabic-native models and those adapted from other languages. This makes Falcon-Arabic not only a state-of-the-art model in terms of performance, but also a uniquely efficient and accessible solution for developers and researchers working with the Arabic language.\nüöÄ Introducing Falcon-Arabic: Advancing LLMs for the Arabic-Speaking World In recent years, Large Language Models (LLMs) have transformed Artificial Intelligence, powering tools for translation, content creation, virtual assistance, and more. Yet much of this progress has focused on highly represented languages like English, leaving languages such as Arabic underrepresented. Arabic presents unique challenges it‚Äôs morphologically rich, diglossic (spanning both Modern Standard Arabic (MSA) and diverse regional dialects), and used across a vast and culturally varied population. Developing robust Arabic LLMs is essential to ensure Arabic-speaking communities are fully included in the AI revolution.\nWith this goal in mind, we‚Äôre introducing Falcon-Arabic a specialized adaptation of the Falcon 3 model family, developed by the Technology Innovation Institute (TII) in the UAE. The Falcon models have earned global recognition for their multilingual strength and open-source approach. Falcon-Arabic builds on this legacy, bringing advanced language understanding and generation to Arabic. By training the model to handle both Modern Standard Arabic and key dialects, Falcon-Arabic fills a critical gap in language technology enabling more natural, intelligent, and inclusive Arabic AI across the Gulf, Middle East, and North Africa.\nü¶Ö Falcon-Arabic Has Landed - Here‚Äôs the Training Recipe üß™ Building Falcon-Arabic started with a strategic decision: rather than training a model from scratch, we chose to adapt a strong multilingual foundation. In the Arabic LLM landscape, three main approaches exist: training from scratch (e.g., Jais-native), adapting multilingual models (like Allam or Fanar), or using models that natively support Arabic alongside other languages (such as Qwen or LLaMA). Observing the Open Arabic LLM Leaderboard, it became clear that adapted and multilingual models consistently outperformed others in both efficiency and capability. To build on that momentum, we selected Falcon 3-7B, a model that strikes a practical balance between performance and resource efficiency within the Falcon 3 family developed by the Technology Innovation Institute (TII).\nThe core challenge was adapting Falcon 3-7B, which originally lacked Arabic support at the tokenizer and embedding level. We addressed this by extending the tokenizer‚Äôs vocabulary with 32,000 Arabic-specific tokens, and applying a novel embedding initialization strategy based on textual similarity. This technique mapped new Arabic tokens to semantically related embeddings from the existing vocabulary, allowing the model to inherit prior knowledge and accelerate learning particularly around sentiment, abstract concepts, and reasoning patterns. This gave Falcon-Arabic a head start in understanding and generating high-quality Arabic text.\nWith the tokenizer and embeddings in place, we began continuous pretraining on high-quality, 100% native Arabic datasets, avoiding the use of machine-translated content to minimize cultural bias and preserve linguistic authenticity. Training followed a multi-stage curriculum: early stages focused on general knowledge and dialect-rich Arabic content to stabilize the model and reinforce logical capabilities, while later phases emphasized math, code, and reasoning. The result is a model that not only speaks Arabic fluently across dialects, but also retains Falcon‚Äôs multilingual and reasoning strengths pushing the boundaries for Arabic-first AI.\nAverage Performance of Pretrained Models üìä Falcon-Arabic: Raising the Bar in Arabic LLMs We evaluated Falcon-Arabic on OALL v2, the leading benchmark for Arabic Language Models. It includes six multiple-choice tasks such as Arabic MMLU (native and translated), Arabic Exams, Alghafa, MadinahQA, Aratrust and one generative benchmark, Alrage. Falcon-Arabic outperforms all existing Arabic LLMs in its size range and even surpasses models up to 4√ó larger. It leads in key benchmarks like Arabic MMLU, Exams, MadinahQA, and Aratrust, setting a new standard for Arabic-first Language Models.\nComparison Table of Pretrained Models Model Average ALGhafa ArabicMMLU Exams MadinahQA AraTrust ALRAGE ArbMMLU-HT AceGPT-v2-32B 61.74 54.93 63.15 48.6 59.71 83.96 68.96 52.87 Qwen2.5-14B 54.26 69.32 46.37 37.43 30.38 70.46 74.03 51.84 AceGPT-13B 47.21 48.23 41.38 36.87 35.37 56.51 79.96 32.12 Llama-3.1-8B 51.64 64.34 52.28 40.04 43.08 71.98 47.08 42.67 Qwen2.5-7B 41.97 31.72 37.36 37.99 27.11 53.66 62.68 43.30 Falcon-Arabic-7B-Base 62.57 67.17 64.85 52.89 48.79 85.36 63.71 55.25 The evaluation details (log probabilities, predictions and LLM as judge metrics) of Falcon-Arabic-7B-Base are available on https://huggingface.co/datasets/tiiuae/Falcon-Arabic-7B-Base-details\nüó£Ô∏è From Pretraining to Instruct: Aligning Falcon-Arabic for Conversations After finalizing the base model training, we performed a post-training alignment phase to fine-tune Falcon-Arabic‚Äôs responses according to human preferences. This phase began with supervised fine-tuning (SFT) using a combination of high-quality public datasets and internally collected native Arabic instruction data, covering a range of tasks and conversational scenarios.\nTo further enhance alignment, we applied Direct Preference Optimization (DPO) a reinforcement learning-based method that tunes the model to prefer outputs that humans rate as more helpful, safe, and relevant. This two-step process ensures that Falcon-Arabic Instruct not only understands Arabic well but responds in a way that aligns with real user expectations.\nAverage Performance of Instruct Models As shown in the results plots, Falcon-Arabic Instruct leads the pack, outperforming all other Instruct-aligned Arabic LLMs in its size class and even models significantly larger across multiple benchmarks. The model demonstrates strong performance in both instruction following and open-ended dialogue, setting a new standard for Arabic conversational AI.\nPerformance of Instruct Models by Benchmark Comparison Table of Instruct Models Model Average ALGhafa ALRAGE AraTrust ArabicMMLU ArbMMLU-HT Exams MadinahQA aya-expanse-32b 67.17 77.61 79.64 89.00 60.63 58.86 51.02 53.45 c4ai-command-r7b-arabic-02-2025 67.07 74.84 75.90 80.47 59.34 50.14 64.99 63.84 ALLaM-7B-Instruct-preview 65.25 69.49 76.81 86.93 64.90 52.81 51.58 54.24 Yehia-7B-preview 65.68 70.81 76.64 87.49 64.90 53.40 52.14 54.37 Qwen2-7B-Instruct 63.61 73.24 71.13 82.77 60.01 51.30 47.30 59.50 Falcon-Arabic-7B-Instruct 68.03 72.40 71.77 82.54 68.23 55.37 53.25 72.95 The evaluation details (log probabilities, predictions and LLM as judge metrics) of Falcon-Arabic-7B-Instruct are available on https://huggingface.co/datasets/tiiuae/Falcon-Arabic-7B-Instruct-details\nüîì Unlocking the Potential of Arabic AI Falcon-Arabic sets a new benchmark for Arabic Language Models. With only 7B parameters, it delivers state-of-the-art performance outperforming models of similar size and even those several times larger across key benchmarks like Arabic MMLU, MadinahQA, and Aratrust. It combines fluency in Modern Standard Arabic, strong understanding of regional dialects, and robust reasoning and multilingual capabilities, making it ideal for a wide range of applications: from Arabic-first chatbots and educational tools to content generation, code assistance, and document understanding.\nTo give you a hands-on feel for what Falcon-Arabic can do, we built a simple demo that showcases its capabilities in machine translation even though the model hasn‚Äôt been fine-tuned specifically for that task. The tool runs purely on Falcon-7B-Arabic-Instruct, and the results are surprisingly strong across various translation directions. You can try it yourself through the demo linked just below. In fact, we used the same setup to translate this blog post into Arabic for our Arabic-speaking audience. Check it out here üöÄ. And if you‚Äôre curious to explore more, we also provide access to a live playground where you can interact with Falcon-Arabic Instruct and experience its performance across different tasks ‚ú®.\nüó£Ô∏è Chat with Falcon-Arabic üìä View evaluation details on ü§ó collection ‚ö†Ô∏è Limitations Like all Large Language Models, Falcon-Arabic inherits some common limitations. These include occasional hallucinations (producing plausible but incorrect outputs), sensitivity to how prompts are phrased, and varying performance across very long contexts. While Falcon-Arabic is designed to reduce these issues especially for Arabic tasks users should still apply critical thinking when interpreting results, particularly in high-stakes or fact-sensitive use cases.\nCitation If you find this work helpful for your research or projects, please consider citing it.\n@misc{falcon-arabic, title = {Falcon-Arabic: A Breakthrough in Arabic Language Models}, author = {Falcon-LLM Team}, month = {May}, url = {https://falcon-lm.github.io/blog/falcon-arabic}, year = {2025} } ","wordCount":"1384","inLanguage":"en","image":"https://falcon-lm.github.io/blog/falcon-arabic/cover_1.png","datePublished":"2025-05-21T12:00:00Z","dateModified":"2025-05-21T12:00:00Z","author":{"@type":"Person","name":"Falcon Team"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://falcon-lm.github.io/blog/falcon-arabic/"},"publisher":{"@type":"Organization","name":"Falcon","logo":{"@type":"ImageObject","url":"https://falcon-lm.github.io/img/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!0</script><header class=header><div class="nav-container nav-background"><nav class=nav><div class=logo><a href=/ accesskey=h title="Falcon (Alt + H)"><img src=https://falcon-lm.github.io/img/logo.svg alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://chat.falconllm.tii.ae/ title="Try Falcon Chat"><span>Try Falcon Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero-background style="background:url(/img/falcon_arabic_cover.png)50%/cover no-repeat fixed"></div><div class=hero-gradient></div><div class=hero-blur></div><div class="hero text-light"><h1 class=post-title>Falcon-Arabic: A Breakthrough in Arabic Language Models</h1><div class=post-meta><span title='2025-05-21 12:00:00 +0000 UTC'>May 21, 2025</span>&nbsp;‚Ä¢&nbsp;7 min&nbsp;‚Ä¢&nbsp;1384 words&nbsp;‚Ä¢&nbsp;Falcon Team&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://falcon-lm.github.io/ar/blog/falcon-arabic/>Arabic</a></li></ul></div></div></div><main class=main><article class=post-single><figure class=entry-cover><a href=/blog/falcon-arabic/cover_1.png target=_blank rel="noopener noreferrer"><img loading=lazy srcset="https://falcon-lm.github.io/blog/falcon-arabic/cover_1_hu_f91e8c4b5b2aaa53.png 360w ,https://falcon-lm.github.io/blog/falcon-arabic/cover_1_hu_36104b4ab20431ec.png 480w ,https://falcon-lm.github.io/blog/falcon-arabic/cover_1_hu_b035990eacb93ea9.png 720w ,https://falcon-lm.github.io/blog/falcon-arabic/cover_1_hu_867e866c47fd45ed.png 1080w ,https://falcon-lm.github.io/blog/falcon-arabic/cover_1_hu_2061a7903fd7b483.png 1500w ,https://falcon-lm.github.io/blog/falcon-arabic/cover_1.png 1536w" sizes="(min-width: 768px) 720px, 100vw" src=https://falcon-lm.github.io/blog/falcon-arabic/cover_1.png alt width=1536 height=1024></a></figure><div class=post-content><blockquote><p>Check out the <a href=https://falcon-lm.github.io/ar/blog/falcon-arabic/>Arabic version</a> translated by <strong>Falcon-Arabic</strong></p></blockquote><p>We are excited to introduce <strong>Falcon-Arabic</strong>, a 7B parameter Language Model that sets a new benchmark for Arabic NLP. Built on the Falcon 3 architecture, Falcon-Arabic is a multilingual model that supports Arabic, English, and several other languages. It excels in general knowledge, Arabic grammar, mathematical reasoning, complex problem solving, and understanding the rich diversity of Arabic dialects. Falcon-Arabic supports a context length of 32,000 tokens, allowing it to handle long documents and enabling advanced applications like retrieval-augmented generation (RAG), in-depth content creation, and knowledge-intensive tasks.</p><p>Falcon-Arabic redefines the boundaries of what is possible for Arabic Language Models. It significantly outperforms other Arabic LLMs in its size category and even models up to four times larger across both Arabic-native models and those adapted from other languages. This makes Falcon-Arabic not only a state-of-the-art model in terms of performance, but also a uniquely efficient and accessible solution for developers and researchers working with the Arabic language.</p><h2 id=-introducing-falcon-arabic-advancing-llms-for-the-arabic-speaking-world>üöÄ Introducing Falcon-Arabic: Advancing LLMs for the Arabic-Speaking World<a hidden class=anchor aria-hidden=true href=#-introducing-falcon-arabic-advancing-llms-for-the-arabic-speaking-world>#</a></h2><p>In recent years, Large Language Models (LLMs) have transformed Artificial Intelligence, powering tools for translation, content creation, virtual assistance, and more. Yet much of this progress has focused on highly represented languages like English, leaving languages such as Arabic underrepresented. Arabic presents unique challenges it&rsquo;s morphologically rich, diglossic (spanning both Modern Standard Arabic (MSA) and diverse regional dialects), and used across a vast and culturally varied population. Developing robust Arabic LLMs is essential to ensure Arabic-speaking communities are fully included in the AI revolution.</p><p>With this goal in mind, we‚Äôre introducing <strong>Falcon-Arabic</strong> a specialized adaptation of the <a href=https://huggingface.co/collections/tiiuae/falcon3-67605ae03578be86e4e87026><strong>Falcon 3</strong> model family</a>, developed by the <a href=https://www.tii.ae/><strong>Technology Innovation Institute (TII)</strong></a> in the UAE. The Falcon models have earned global recognition for their multilingual strength and open-source approach. Falcon-Arabic builds on this legacy, bringing advanced language understanding and generation to Arabic. By training the model to handle both Modern Standard Arabic and key dialects, Falcon-Arabic fills a critical gap in language technology enabling more natural, intelligent, and inclusive Arabic AI across the Gulf, Middle East, and North Africa.</p><p><a id=pull-figures></a></p><div style=display:flex;justify-content:center;flex-wrap:wrap;gap:20px><img src=./radar.png alt="Pretrained models performance" style=width:100%;max-width:800px;height:auto></div><h2 id=-falcon-arabic-has-landed---heres-the-training-recipe->ü¶Ö Falcon-Arabic Has Landed - Here‚Äôs the Training Recipe üß™<a hidden class=anchor aria-hidden=true href=#-falcon-arabic-has-landed---heres-the-training-recipe->#</a></h2><p>Building Falcon-Arabic started with a strategic decision: rather than training a model from scratch, we chose to adapt a strong multilingual foundation. In the Arabic LLM landscape, three main approaches exist: training from scratch (e.g., Jais-native), adapting multilingual models (like Allam or Fanar), or using models that natively support Arabic alongside other languages (such as Qwen or LLaMA). Observing the <a href=https://huggingface.co/spaces/OALL/Open-Arabic-LLM-Leaderboard>Open Arabic LLM Leaderboard</a>, it became clear that adapted and multilingual models consistently outperformed others in both efficiency and capability. To build on that momentum, we selected <strong>Falcon 3-7B</strong>, a model that strikes a practical balance between performance and resource efficiency within the Falcon 3 family developed by the <strong>Technology Innovation Institute (TII)</strong>.</p><p>The core challenge was adapting <a href=https://huggingface.co/tiiuae/Falcon3-7B-Base>Falcon 3-7B</a>, which originally lacked Arabic support at the tokenizer and embedding level. We addressed this by extending the tokenizer‚Äôs vocabulary with <strong>32,000 Arabic-specific tokens</strong>, and applying a <strong>novel embedding initialization strategy</strong> based on <strong>textual similarity</strong>. This technique mapped new Arabic tokens to semantically related embeddings from the existing vocabulary, allowing the model to inherit prior knowledge and accelerate learning particularly around sentiment, abstract concepts, and reasoning patterns. This gave Falcon-Arabic a head start in understanding and generating high-quality Arabic text.</p><p>With the tokenizer and embeddings in place, we began <strong>continuous pretraining</strong> on high-quality, <strong>100% native Arabic datasets</strong>, avoiding the use of machine-translated content to minimize cultural bias and preserve linguistic authenticity. Training followed a <strong>multi-stage curriculum</strong>: early stages focused on <strong>general knowledge and dialect-rich Arabic content</strong> to stabilize the model and reinforce logical capabilities, while later phases emphasized <strong>math, code, and reasoning</strong>. The result is a model that not only speaks Arabic fluently across dialects, but also retains Falcon‚Äôs multilingual and reasoning strengths pushing the boundaries for Arabic-first AI.</p><h3 id=average-performance-of-pretrained-models>Average Performance of Pretrained Models<a hidden class=anchor aria-hidden=true href=#average-performance-of-pretrained-models>#</a></h3><div id=chart-pretrained-avg></div><script src=https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js></script><script>(function(){let n;try{n=JSON.parse(`
[
    {"category": "Average", "model": "AceGPT-v2-32B", "value": 0.6174},
    {"category": "Average", "model": "Qwen2.5-14B", "value": 0.5426},
    {"category": "Average", "model": "AceGPT-13B", "value": 0.4721},
    {"category": "Average", "model": "Llama-3.1-8B", "value": 0.5164},
    {"category": "Average", "model": "Qwen2.5-7B", "value": 0.41969999999999996},
    {"category": "Average", "model": "Falcon-Arabic-7B-Base", "value": 0.6257}
]
`)}catch(e){console.error("Error parsing chart data:",e),n=[]}const p=[],t=p.length>0?p:Array.from(new Set(n.map(e=>e.model))),u=[],g=u.length>0?u:Array.from(new Set(n.map(e=>e.category))),b="Falcon-Arabic-7B-Base",r=b||t[0],v=!0,e={top:40,right:30,bottom:40,left:60},m=800-e.left-e.right,i=430-e.top-e.bottom,a=d3.select("#chart-pretrained-avg").append("svg").attr("width",m+e.left+e.right).attr("height",i+e.top+e.bottom).append("g").attr("transform",`translate(${e.left},${e.top})`);document.getElementById("tooltip-pretrained-avg")||d3.select("body").append("div").attr("id","tooltip-pretrained-avg").attr("class","tooltip").style("position","absolute").style("padding","10px").style("background","#f9f9f9").style("border","1px solid #ddd").style("border-radius","5px").style("pointer-events","none").style("opacity","0").style("transition","opacity 0.3s").style("font-family","inherit").style("font-size","14px").style("box-shadow","0 2px 5px rgba(0,0,0,0.1)");const h=d3.select("#tooltip-pretrained-avg"),d=d3.scaleBand().domain(g).range([0,m]).padding(.3);a.append("g").attr("transform",`translate(0,${i})`).call(d3.axisBottom(d).tickSize(0)).selectAll(".tick").each(function(e){d3.select(this).select("text").remove();const t=d3.select(this).append("foreignObject").attr("x",-50).attr("y",0).attr("width",100).attr("height",50);t.append("xhtml:div").style("font-weight","bold").style("font-family","inherit").style("word-wrap","break-word").style("text-align","center").style("width","100%").text(e)});const f=d3.scaleBand().domain(t).range([0,d.bandwidth()]).padding(.05);let s="0.40",o="0.7";if(s===null||o===null){const e=n.map(e=>e.value),t=(Math.max(...e)-Math.min(...e))*.1;s=s===null?Math.max(0,Math.min(...e)-t):s,o=o===null?Math.max(...e)+t:o}const l=d3.scaleLinear().domain([s,o]).range([i,0]);a.append("g").call(d3.axisLeft(l).tickFormat(e=>v?d3.format(".0%")(e):d3.format(".2f")(e))).selectAll("text").style("font-family","inherit");const c=e=>{if(e.model===r)return"#b987ff";const s=t.indexOf(e.model),o=t.length,n=128-s*(0-80)/(o-1||1);return`rgb(${n}, ${n+8}, ${n+16})`},j=e=>{if(e===r)return"#b088ff";const s=t.indexOf(e),o=t.length,i=128-s*(0-80)/(o-1||1),n=Math.min(i+30,230);return`rgb(${n}, ${n+8}, ${n+16})`};g.forEach(e=>{const t=n.filter(t=>t.category===e),s=a.append("g").attr("class",`category-group-${e}`);s.selectAll(`.bar-${e}`).data(t).enter().append("rect").attr("class","bar").attr("x",t=>d(e)+f(t.model)).attr("y",e=>l(e.value)).attr("width",f.bandwidth()).attr("height",e=>i-l(e.value)).attr("fill",e=>c(e)).attr("data-model",e=>e.model).style("transition","opacity 0.3s"),s.on("mouseover",function(n){d3.select(this).selectAll("rect").attr("stroke","#333").attr("stroke-width",2).attr("fill",function(){const e=d3.select(this).attr("data-model");return j(e)});const s=`<strong style="font-size: 16px;">${e}</strong><br/><span style="font-size: 12px;">`+t.map(e=>v?`${e.model}: ${(e.value*100).toFixed(2)}%`:`${e.model}: ${e.value.toFixed(3)}`).join("<br/>")+"</span>";h.style("opacity",1).html(s).style("left",n.pageX+15+"px").style("top",n.pageY-28+"px")}).on("mouseout",function(){d3.select(this).selectAll("rect").attr("stroke","none").attr("fill",function(){const e=d3.select(this).attr("data-model");return c({model:e})}),h.style("opacity",0)})}),a.append("text").attr("text-anchor","middle").attr("transform","rotate(-90)").attr("y",-e.left+15).attr("x",-i/2).text("Score %").style("font-family","inherit");const y=d3.select("#chart-pretrained-avg").append("div").style("display","flex").style("justify-content","center").style("font-size","14px").style("margin-top","-10px"),_=[...t].sort((e,n)=>e===r?-1:n===r?1:t.indexOf(e)-t.indexOf(n));_.forEach(e=>{const n=c({model:e}),t=y.append("div").style("display","flex").style("align-items","center").style("margin","0 10px");t.append("div").style("width","20px").style("height","20px").style("margin-right","5px").style("background-color",n),t.append("div").text(e)})})()</script><h2 id=-falcon-arabic-raising-the-bar-in-arabic-llms>üìä Falcon-Arabic: Raising the Bar in Arabic LLMs<a hidden class=anchor aria-hidden=true href=#-falcon-arabic-raising-the-bar-in-arabic-llms>#</a></h2><p>We evaluated Falcon-Arabic on <strong><a href=https://huggingface.co/spaces/OALL/Open-Arabic-LLM-Leaderboard>OALL v2</a></strong>, the leading benchmark for Arabic Language Models. It includes six multiple-choice tasks such as Arabic MMLU (native and translated), Arabic Exams, Alghafa, MadinahQA, Aratrust and one generative benchmark, Alrage. <strong>Falcon-Arabic outperforms all existing Arabic LLMs in its size range and even surpasses models up to 4√ó larger</strong>. It leads in key benchmarks like Arabic MMLU, Exams, MadinahQA, and Aratrust, setting a new standard for Arabic-first Language Models.</p><div id=chart-pretrained-detailed></div><script src=https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js></script><script>(function(){let n;try{n=JSON.parse(`
[
    {"category": "ALGhafa", "model": "AceGPT-v2-32B", "value": 0.5493},
    {"category": "ALGhafa", "model": "Qwen2.5-14B", "value": 0.6931999999999999},
    {"category": "ALGhafa", "model": "AceGPT-13B", "value": 0.48229999999999995},
    {"category": "ALGhafa", "model": "Llama-3.1-8B", "value": 0.6434000000000001},
    {"category": "ALGhafa", "model": "Qwen2.5-7B", "value": 0.3172},
    {"category": "ALGhafa", "model": "Falcon-Arabic-7B-Base", "value": 0.67},
    {"category": "ArabicMMLU", "model": "AceGPT-v2-32B", "value": 0.6315},
    {"category": "ArabicMMLU", "model": "Qwen2.5-14B", "value": 0.4637},
    {"category": "ArabicMMLU", "model": "AceGPT-13B", "value": 0.4138},
    {"category": "ArabicMMLU", "model": "Llama-3.1-8B", "value": 0.5228},
    {"category": "ArabicMMLU", "model": "Qwen2.5-7B", "value": 0.3736},
    {"category": "ArabicMMLU", "model": "Falcon-Arabic-7B-Base", "value": 0.65},
    {"category": "Exams", "model": "AceGPT-v2-32B", "value": 0.486},
    {"category": "Exams", "model": "Qwen2.5-14B", "value": 0.3743},
    {"category": "Exams", "model": "AceGPT-13B", "value": 0.36869999999999997},
    {"category": "Exams", "model": "Llama-3.1-8B", "value": 0.4004},
    {"category": "Exams", "model": "Qwen2.5-7B", "value": 0.3799},
    {"category": "Exams", "model": "Falcon-Arabic-7B-Base", "value": 0.53},
    {"category": "MadinahQA", "model": "AceGPT-v2-32B", "value": 0.5971},
    {"category": "MadinahQA", "model": "Qwen2.5-14B", "value": 0.3038},
    {"category": "MadinahQA", "model": "AceGPT-13B", "value": 0.35369999999999996},
    {"category": "MadinahQA", "model": "Llama-3.1-8B", "value": 0.43079999999999996},
    {"category": "MadinahQA", "model": "Qwen2.5-7B", "value": 0.2711},
    {"category": "MadinahQA", "model": "Falcon-Arabic-7B-Base", "value": 0.49},
    {"category": "AraTrust", "model": "AceGPT-v2-32B", "value": 0.8396},
    {"category": "AraTrust", "model": "Qwen2.5-14B", "value": 0.7045999999999999},
    {"category": "AraTrust", "model": "AceGPT-13B", "value": 0.5650999999999999},
    {"category": "AraTrust", "model": "Llama-3.1-8B", "value": 0.7198},
    {"category": "AraTrust", "model": "Qwen2.5-7B", "value": 0.5366},
    {"category": "AraTrust", "model": "Falcon-Arabic-7B-Base", "value": 0.85},
    {"category": "ALRAGE", "model": "AceGPT-v2-32B", "value": 0.6896},
    {"category": "ALRAGE", "model": "Qwen2.5-14B", "value": 0.7403},
    {"category": "ALRAGE", "model": "AceGPT-13B", "value": 0.7996},
    {"category": "ALRAGE", "model": "Llama-3.1-8B", "value": 0.4708},
    {"category": "ALRAGE", "model": "Qwen2.5-7B", "value": 0.6268},
    {"category": "ALRAGE", "model": "Falcon-Arabic-7B-Base", "value": 0.64},
    {"category": "ArbMMLU-HT", "model": "AceGPT-v2-32B", "value": 0.5287},
    {"category": "ArbMMLU-HT", "model": "Qwen2.5-14B", "value": 0.5184000000000001},
    {"category": "ArbMMLU-HT", "model": "AceGPT-13B", "value": 0.3212},
    {"category": "ArbMMLU-HT", "model": "Llama-3.1-8B", "value": 0.4267},
    {"category": "ArbMMLU-HT", "model": "Qwen2.5-7B", "value": 0.433},
    {"category": "ArbMMLU-HT", "model": "Falcon-Arabic-7B-Base", "value": 0.55}
]
`)}catch(e){console.error("Error parsing chart data:",e),n=[]}const p=[],t=p.length>0?p:Array.from(new Set(n.map(e=>e.model))),u=[],g=u.length>0?u:Array.from(new Set(n.map(e=>e.category))),b="Falcon-Arabic-7B-Base",r=b||t[0],v=!0,e={top:40,right:30,bottom:40,left:60},m=800-e.left-e.right,i=430-e.top-e.bottom,a=d3.select("#chart-pretrained-detailed").append("svg").attr("width",m+e.left+e.right).attr("height",i+e.top+e.bottom).append("g").attr("transform",`translate(${e.left},${e.top})`);document.getElementById("tooltip-pretrained-detailed")||d3.select("body").append("div").attr("id","tooltip-pretrained-detailed").attr("class","tooltip").style("position","absolute").style("padding","10px").style("background","#f9f9f9").style("border","1px solid #ddd").style("border-radius","5px").style("pointer-events","none").style("opacity","0").style("transition","opacity 0.3s").style("font-family","inherit").style("font-size","14px").style("box-shadow","0 2px 5px rgba(0,0,0,0.1)");const h=d3.select("#tooltip-pretrained-detailed"),d=d3.scaleBand().domain(g).range([0,m]).padding(.3);a.append("g").attr("transform",`translate(0,${i})`).call(d3.axisBottom(d).tickSize(0)).selectAll(".tick").each(function(e){d3.select(this).select("text").remove();const t=d3.select(this).append("foreignObject").attr("x",-50).attr("y",0).attr("width",100).attr("height",50);t.append("xhtml:div").style("font-weight","bold").style("font-family","inherit").style("word-wrap","break-word").style("text-align","center").style("width","100%").text(e)});const f=d3.scaleBand().domain(t).range([0,d.bandwidth()]).padding(.05);let s="0.2",o="0.9";if(s===null||o===null){const e=n.map(e=>e.value),t=(Math.max(...e)-Math.min(...e))*.1;s=s===null?Math.max(0,Math.min(...e)-t):s,o=o===null?Math.max(...e)+t:o}const l=d3.scaleLinear().domain([s,o]).range([i,0]);a.append("g").call(d3.axisLeft(l).tickFormat(e=>v?d3.format(".0%")(e):d3.format(".2f")(e))).selectAll("text").style("font-family","inherit");const c=e=>{if(e.model===r)return"#b987ff";const s=t.indexOf(e.model),o=t.length,n=128-s*(0-80)/(o-1||1);return`rgb(${n}, ${n+8}, ${n+16})`},j=e=>{if(e===r)return"#b088ff";const s=t.indexOf(e),o=t.length,i=128-s*(0-80)/(o-1||1),n=Math.min(i+30,230);return`rgb(${n}, ${n+8}, ${n+16})`};g.forEach(e=>{const t=n.filter(t=>t.category===e),s=a.append("g").attr("class",`category-group-${e}`);s.selectAll(`.bar-${e}`).data(t).enter().append("rect").attr("class","bar").attr("x",t=>d(e)+f(t.model)).attr("y",e=>l(e.value)).attr("width",f.bandwidth()).attr("height",e=>i-l(e.value)).attr("fill",e=>c(e)).attr("data-model",e=>e.model).style("transition","opacity 0.3s"),s.on("mouseover",function(n){d3.select(this).selectAll("rect").attr("stroke","#333").attr("stroke-width",2).attr("fill",function(){const e=d3.select(this).attr("data-model");return j(e)});const s=`<strong style="font-size: 16px;">${e}</strong><br/><span style="font-size: 12px;">`+t.map(e=>v?`${e.model}: ${(e.value*100).toFixed(2)}%`:`${e.model}: ${e.value.toFixed(3)}`).join("<br/>")+"</span>";h.style("opacity",1).html(s).style("left",n.pageX+15+"px").style("top",n.pageY-28+"px")}).on("mouseout",function(){d3.select(this).selectAll("rect").attr("stroke","none").attr("fill",function(){const e=d3.select(this).attr("data-model");return c({model:e})}),h.style("opacity",0)})}),a.append("text").attr("text-anchor","middle").attr("transform","rotate(-90)").attr("y",-e.left+15).attr("x",-i/2).text("Score %").style("font-family","inherit");const y=d3.select("#chart-pretrained-detailed").append("div").style("display","flex").style("justify-content","center").style("font-size","14px").style("margin-top","-10px"),_=[...t].sort((e,n)=>e===r?-1:n===r?1:t.indexOf(e)-t.indexOf(n));_.forEach(e=>{const n=c({model:e}),t=y.append("div").style("display","flex").style("align-items","center").style("margin","0 10px");t.append("div").style("width","20px").style("height","20px").style("margin-right","5px").style("background-color",n),t.append("div").text(e)})})()</script><h3 id=comparison-table-of-pretrained-models>Comparison Table of Pretrained Models<a hidden class=anchor aria-hidden=true href=#comparison-table-of-pretrained-models>#</a></h3><div class=custom-table><table><thead><tr><th>Model</th><th>Average</th><th>ALGhafa</th><th>ArabicMMLU</th><th>Exams</th><th>MadinahQA</th><th>AraTrust</th><th>ALRAGE</th><th>ArbMMLU-HT</th></tr></thead><tbody><tr><td>AceGPT-v2-32B</td><td>61.74</td><td>54.93</td><td>63.15</td><td>48.6</td><td><u>59.71</td><td>83.96</td><td>68.96</td><td>52.87</td></tr><tr><td>Qwen2.5-14B</td><td>54.26</td><td><u>69.32</u></td><td>46.37</td><td>37.43</td><td>30.38</td><td>70.46</td><td>74.03</td><td>51.84</td></tr><tr><td>AceGPT-13B</td><td>47.21</td><td>48.23</td><td>41.38</td><td>36.87</td><td>35.37</td><td>56.51</td><td><u>79.96</td><td>32.12</td></tr><tr><td>Llama-3.1-8B</td><td>51.64</td><td>64.34</td><td>52.28</td><td>40.04</td><td>43.08</td><td>71.98</td><td>47.08</td><td>42.67</td></tr><tr><td>Qwen2.5-7B</td><td>41.97</td><td>31.72</td><td>37.36</td><td>37.99</td><td>27.11</td><td>53.66</td><td>62.68</td><td>43.30</td></tr><tr><td><strong>Falcon-Arabic-7B-Base</strong></td><td><u>62.57</u></td><td>67.17</td><td><u>64.85</td><td><u>52.89</td><td>48.79</td><td><u>85.36</td><td>63.71</td><td><u>55.25</td></tr><tr><td></div></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><blockquote><p>The evaluation details (log probabilities, predictions and LLM as judge metrics) of <strong>Falcon-Arabic-7B-Base</strong> are available on <a href=https://huggingface.co/datasets/tiiuae/Falcon-Arabic-7B-Base-details>https://huggingface.co/datasets/tiiuae/Falcon-Arabic-7B-Base-details</a></p></blockquote><h2 id=-from-pretraining-to-instruct-aligning-falcon-arabic-for-conversations>üó£Ô∏è From Pretraining to Instruct: Aligning Falcon-Arabic for Conversations<a hidden class=anchor aria-hidden=true href=#-from-pretraining-to-instruct-aligning-falcon-arabic-for-conversations>#</a></h2><p>After finalizing the base model training, we performed a <strong>post-training alignment</strong> phase to fine-tune Falcon-Arabic‚Äôs responses according to human preferences. This phase began with <strong>supervised fine-tuning (SFT)</strong> using a combination of high-quality public datasets and internally collected <strong>native Arabic instruction data</strong>, covering a range of tasks and conversational scenarios.</p><p>To further enhance alignment, we applied <strong>Direct Preference Optimization (DPO)</strong> a reinforcement learning-based method that tunes the model to prefer outputs that humans rate as more helpful, safe, and relevant. This two-step process ensures that Falcon-Arabic Instruct not only understands Arabic well but responds in a way that aligns with real user expectations.</p><h3 id=average-performance-of-instruct-models>Average Performance of Instruct Models<a hidden class=anchor aria-hidden=true href=#average-performance-of-instruct-models>#</a></h3><div id=chart-chat-avg></div><script src=https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js></script><script>(function(){let n;try{n=JSON.parse(`
[
    {"category": "Average", "model": "aya-expanse-32b", "value": 0.6717},
    {"category": "Average", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.6707},
    {"category": "Average", "model": "ALLaM-7B-Instruct-preview", "value": 0.6525},
    {"category": "Average", "model": "Yehia-7B-preview", "value": 0.6568},
    {"category": "Average", "model": "Qwen2-7B-Instruct", "value": 0.6361},
    {"category": "Average", "model": "Falcon-Arabic-7B-Instruct", "value": 0.6808}
]
`)}catch(e){console.error("Error parsing chart data:",e),n=[]}const p=[],t=p.length>0?p:Array.from(new Set(n.map(e=>e.model))),u=[],g=u.length>0?u:Array.from(new Set(n.map(e=>e.category))),b="Falcon-Arabic-7B-Instruct",r=b||t[0],v=!0,e={top:40,right:30,bottom:40,left:60},m=800-e.left-e.right,i=430-e.top-e.bottom,a=d3.select("#chart-chat-avg").append("svg").attr("width",m+e.left+e.right).attr("height",i+e.top+e.bottom).append("g").attr("transform",`translate(${e.left},${e.top})`);document.getElementById("tooltip-chat-avg")||d3.select("body").append("div").attr("id","tooltip-chat-avg").attr("class","tooltip").style("position","absolute").style("padding","10px").style("background","#f9f9f9").style("border","1px solid #ddd").style("border-radius","5px").style("pointer-events","none").style("opacity","0").style("transition","opacity 0.3s").style("font-family","inherit").style("font-size","14px").style("box-shadow","0 2px 5px rgba(0,0,0,0.1)");const h=d3.select("#tooltip-chat-avg"),d=d3.scaleBand().domain(g).range([0,m]).padding(.3);a.append("g").attr("transform",`translate(0,${i})`).call(d3.axisBottom(d).tickSize(0)).selectAll(".tick").each(function(e){d3.select(this).select("text").remove();const t=d3.select(this).append("foreignObject").attr("x",-50).attr("y",0).attr("width",100).attr("height",50);t.append("xhtml:div").style("font-weight","bold").style("font-family","inherit").style("word-wrap","break-word").style("text-align","center").style("width","100%").text(e)});const f=d3.scaleBand().domain(t).range([0,d.bandwidth()]).padding(.05);let s="0.56",o="0.7";if(s===null||o===null){const e=n.map(e=>e.value),t=(Math.max(...e)-Math.min(...e))*.1;s=s===null?Math.max(0,Math.min(...e)-t):s,o=o===null?Math.max(...e)+t:o}const l=d3.scaleLinear().domain([s,o]).range([i,0]);a.append("g").call(d3.axisLeft(l).tickFormat(e=>v?d3.format(".0%")(e):d3.format(".2f")(e))).selectAll("text").style("font-family","inherit");const c=e=>{if(e.model===r)return"#b987ff";const s=t.indexOf(e.model),o=t.length,n=128-s*(0-80)/(o-1||1);return`rgb(${n}, ${n+8}, ${n+16})`},j=e=>{if(e===r)return"#b088ff";const s=t.indexOf(e),o=t.length,i=128-s*(0-80)/(o-1||1),n=Math.min(i+30,230);return`rgb(${n}, ${n+8}, ${n+16})`};g.forEach(e=>{const t=n.filter(t=>t.category===e),s=a.append("g").attr("class",`category-group-${e}`);s.selectAll(`.bar-${e}`).data(t).enter().append("rect").attr("class","bar").attr("x",t=>d(e)+f(t.model)).attr("y",e=>l(e.value)).attr("width",f.bandwidth()).attr("height",e=>i-l(e.value)).attr("fill",e=>c(e)).attr("data-model",e=>e.model).style("transition","opacity 0.3s"),s.on("mouseover",function(n){d3.select(this).selectAll("rect").attr("stroke","#333").attr("stroke-width",2).attr("fill",function(){const e=d3.select(this).attr("data-model");return j(e)});const s=`<strong style="font-size: 16px;">${e}</strong><br/><span style="font-size: 12px;">`+t.map(e=>v?`${e.model}: ${(e.value*100).toFixed(2)}%`:`${e.model}: ${e.value.toFixed(3)}`).join("<br/>")+"</span>";h.style("opacity",1).html(s).style("left",n.pageX+15+"px").style("top",n.pageY-28+"px")}).on("mouseout",function(){d3.select(this).selectAll("rect").attr("stroke","none").attr("fill",function(){const e=d3.select(this).attr("data-model");return c({model:e})}),h.style("opacity",0)})}),a.append("text").attr("text-anchor","middle").attr("transform","rotate(-90)").attr("y",-e.left+15).attr("x",-i/2).text("Score %").style("font-family","inherit");const y=d3.select("#chart-chat-avg").append("div").style("display","flex").style("justify-content","center").style("font-size","14px").style("margin-top","-10px"),_=[...t].sort((e,n)=>e===r?-1:n===r?1:t.indexOf(e)-t.indexOf(n));_.forEach(e=>{const n=c({model:e}),t=y.append("div").style("display","flex").style("align-items","center").style("margin","0 10px");t.append("div").style("width","20px").style("height","20px").style("margin-right","5px").style("background-color",n),t.append("div").text(e)})})()</script><p>As shown in the results plots, <strong>Falcon-Arabic Instruct leads the pack</strong>, outperforming all other Instruct-aligned Arabic LLMs in its size class and even models significantly larger across multiple benchmarks. The model demonstrates strong performance in both instruction following and open-ended dialogue, setting a new standard for Arabic conversational AI.</p><h3 id=performance-of-instruct-models-by-benchmark>Performance of Instruct Models by Benchmark<a hidden class=anchor aria-hidden=true href=#performance-of-instruct-models-by-benchmark>#</a></h3><div id=chart-chat-detailed></div><script src=https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js></script><script>(function(){let n;try{n=JSON.parse(`
[
    {"category": "ALGhafa", "model": "aya-expanse-32b", "value": 0.7761},
    {"category": "ALGhafa", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.7484000000000001},
    {"category": "ALGhafa", "model": "ALLaM-7B-Instruct-preview", "value": 0.6949},
    {"category": "ALGhafa", "model": "Yehia-7B-preview", "value": 0.7081000000000001},
    {"category": "ALGhafa", "model": "Qwen2-7B-Instruct", "value": 0.7323999999999999},
    {"category": "ALGhafa", "model": "Falcon-Arabic-7B-Instruct", "value": 0.724033370817286},
    {"category": "ArabicMMLU", "model": "aya-expanse-32b", "value": 0.6063000000000001},
    {"category": "ArabicMMLU", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.5934},
    {"category": "ArabicMMLU", "model": "ALLaM-7B-Instruct-preview", "value": 0.649},
    {"category": "ArabicMMLU", "model": "Yehia-7B-preview", "value": 0.649},
    {"category": "ArabicMMLU", "model": "Qwen2-7B-Instruct", "value": 0.6001},
    {"category": "ArabicMMLU", "model": "Falcon-Arabic-7B-Instruct", "value": 0.682331855997309},
    {"category": "Exams", "model": "aya-expanse-32b", "value": 0.5102},
    {"category": "Exams", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.6498999999999999},
    {"category": "Exams", "model": "ALLaM-7B-Instruct-preview", "value": 0.5158},
    {"category": "Exams", "model": "Yehia-7B-preview", "value": 0.5214},
    {"category": "Exams", "model": "Qwen2-7B-Instruct", "value": 0.473},
    {"category": "Exams", "model": "Falcon-Arabic-7B-Instruct", "value": 0.532588454376163},
    {"category": "MadinahQA", "model": "aya-expanse-32b", "value": 0.5345},
    {"category": "MadinahQA", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.6384000000000001},
    {"category": "MadinahQA", "model": "ALLaM-7B-Instruct-preview", "value": 0.5424},
    {"category": "MadinahQA", "model": "Yehia-7B-preview", "value": 0.5437},
    {"category": "MadinahQA", "model": "Qwen2-7B-Instruct", "value": 0.595},
    {"category": "MadinahQA", "model": "Falcon-Arabic-7B-Instruct", "value": 0.729505774912704},
    {"category": "AraTrust", "model": "aya-expanse-32b", "value": 0.89},
    {"category": "AraTrust", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.8047},
    {"category": "AraTrust", "model": "ALLaM-7B-Instruct-preview", "value": 0.8693000000000001},
    {"category": "AraTrust", "model": "Yehia-7B-preview", "value": 0.8748999999999999},
    {"category": "AraTrust", "model": "Qwen2-7B-Instruct", "value": 0.8277},
    {"category": "AraTrust", "model": "Falcon-Arabic-7B-Instruct", "value": 0.825389146267096},
    {"category": "ALRAGE", "model": "aya-expanse-32b", "value": 0.7964},
    {"category": "ALRAGE", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.759},
    {"category": "ALRAGE", "model": "ALLaM-7B-Instruct-preview", "value": 0.7681},
    {"category": "ALRAGE", "model": "Yehia-7B-preview", "value": 0.7664},
    {"category": "ALRAGE", "model": "Qwen2-7B-Instruct", "value": 0.7112999999999999},
    {"category": "ALRAGE", "model": "Falcon-Arabic-7B-Instruct", "value": 0.717711301044635},
    {"category": "ArbMMLU-HT", "model": "aya-expanse-32b", "value": 0.5886},
    {"category": "ArbMMLU-HT", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.5014},
    {"category": "ArbMMLU-HT", "model": "ALLaM-7B-Instruct-preview", "value": 0.5281},
    {"category": "ArbMMLU-HT", "model": "Yehia-7B-preview", "value": 0.534},
    {"category": "ArbMMLU-HT", "model": "Qwen2-7B-Instruct", "value": 0.513},
    {"category": "ArbMMLU-HT", "model": "Falcon-Arabic-7B-Instruct", "value": 0.553732273891484}
]
`)}catch(e){console.error("Error parsing chart data:",e),n=[]}const p=[],t=p.length>0?p:Array.from(new Set(n.map(e=>e.model))),u=[],g=u.length>0?u:Array.from(new Set(n.map(e=>e.category))),b="Falcon-Arabic-7B-Instruct",r=b||t[0],v=!0,e={top:40,right:30,bottom:40,left:60},m=800-e.left-e.right,i=430-e.top-e.bottom,a=d3.select("#chart-chat-detailed").append("svg").attr("width",m+e.left+e.right).attr("height",i+e.top+e.bottom).append("g").attr("transform",`translate(${e.left},${e.top})`);document.getElementById("tooltip-chat-detailed")||d3.select("body").append("div").attr("id","tooltip-chat-detailed").attr("class","tooltip").style("position","absolute").style("padding","10px").style("background","#f9f9f9").style("border","1px solid #ddd").style("border-radius","5px").style("pointer-events","none").style("opacity","0").style("transition","opacity 0.3s").style("font-family","inherit").style("font-size","14px").style("box-shadow","0 2px 5px rgba(0,0,0,0.1)");const h=d3.select("#tooltip-chat-detailed"),d=d3.scaleBand().domain(g).range([0,m]).padding(.3);a.append("g").attr("transform",`translate(0,${i})`).call(d3.axisBottom(d).tickSize(0)).selectAll(".tick").each(function(e){d3.select(this).select("text").remove();const t=d3.select(this).append("foreignObject").attr("x",-50).attr("y",0).attr("width",100).attr("height",50);t.append("xhtml:div").style("font-weight","bold").style("font-family","inherit").style("word-wrap","break-word").style("text-align","center").style("width","100%").text(e)});const f=d3.scaleBand().domain(t).range([0,d.bandwidth()]).padding(.05);let s="0.3",o="0.95";if(s===null||o===null){const e=n.map(e=>e.value),t=(Math.max(...e)-Math.min(...e))*.1;s=s===null?Math.max(0,Math.min(...e)-t):s,o=o===null?Math.max(...e)+t:o}const l=d3.scaleLinear().domain([s,o]).range([i,0]);a.append("g").call(d3.axisLeft(l).tickFormat(e=>v?d3.format(".0%")(e):d3.format(".2f")(e))).selectAll("text").style("font-family","inherit");const c=e=>{if(e.model===r)return"#b987ff";const s=t.indexOf(e.model),o=t.length,n=128-s*(0-80)/(o-1||1);return`rgb(${n}, ${n+8}, ${n+16})`},j=e=>{if(e===r)return"#b088ff";const s=t.indexOf(e),o=t.length,i=128-s*(0-80)/(o-1||1),n=Math.min(i+30,230);return`rgb(${n}, ${n+8}, ${n+16})`};g.forEach(e=>{const t=n.filter(t=>t.category===e),s=a.append("g").attr("class",`category-group-${e}`);s.selectAll(`.bar-${e}`).data(t).enter().append("rect").attr("class","bar").attr("x",t=>d(e)+f(t.model)).attr("y",e=>l(e.value)).attr("width",f.bandwidth()).attr("height",e=>i-l(e.value)).attr("fill",e=>c(e)).attr("data-model",e=>e.model).style("transition","opacity 0.3s"),s.on("mouseover",function(n){d3.select(this).selectAll("rect").attr("stroke","#333").attr("stroke-width",2).attr("fill",function(){const e=d3.select(this).attr("data-model");return j(e)});const s=`<strong style="font-size: 16px;">${e}</strong><br/><span style="font-size: 12px;">`+t.map(e=>v?`${e.model}: ${(e.value*100).toFixed(2)}%`:`${e.model}: ${e.value.toFixed(3)}`).join("<br/>")+"</span>";h.style("opacity",1).html(s).style("left",n.pageX+15+"px").style("top",n.pageY-28+"px")}).on("mouseout",function(){d3.select(this).selectAll("rect").attr("stroke","none").attr("fill",function(){const e=d3.select(this).attr("data-model");return c({model:e})}),h.style("opacity",0)})}),a.append("text").attr("text-anchor","middle").attr("transform","rotate(-90)").attr("y",-e.left+15).attr("x",-i/2).text("Score %").style("font-family","inherit");const y=d3.select("#chart-chat-detailed").append("div").style("display","flex").style("justify-content","center").style("font-size","14px").style("margin-top","-10px"),_=[...t].sort((e,n)=>e===r?-1:n===r?1:t.indexOf(e)-t.indexOf(n));_.forEach(e=>{const n=c({model:e}),t=y.append("div").style("display","flex").style("align-items","center").style("margin","0 10px");t.append("div").style("width","20px").style("height","20px").style("margin-right","5px").style("background-color",n),t.append("div").text(e)})})()</script><h3 id=comparison-table-of-instruct-models>Comparison Table of Instruct Models<a hidden class=anchor aria-hidden=true href=#comparison-table-of-instruct-models>#</a></h3><div class=custom-table><table><thead><tr><th style=text-align:left>Model</th><th style=text-align:right>Average</th><th style=text-align:right>ALGhafa</th><th style=text-align:right>ALRAGE</th><th style=text-align:right>AraTrust</th><th style=text-align:right>ArabicMMLU</th><th style=text-align:right>ArbMMLU-HT</th><th style=text-align:right>Exams</th><th style=text-align:right>MadinahQA</th></tr></thead><tbody><tr><td style=text-align:left>aya-expanse-32b</td><td style=text-align:right>67.17</td><td style=text-align:right><u>77.61</td><td style=text-align:right><u>79.64</td><td style=text-align:right><u>89.00</td><td style=text-align:right>60.63</td><td style=text-align:right><u>58.86</td><td style=text-align:right>51.02</td><td style=text-align:right>53.45</td></tr><tr><td style=text-align:left>c4ai-command-r7b-arabic-02-2025</td><td style=text-align:right>67.07</td><td style=text-align:right>74.84</td><td style=text-align:right>75.90</td><td style=text-align:right>80.47</td><td style=text-align:right>59.34</td><td style=text-align:right>50.14</td><td style=text-align:right><u>64.99</td><td style=text-align:right>63.84</td></tr><tr><td style=text-align:left>ALLaM-7B-Instruct-preview</td><td style=text-align:right>65.25</td><td style=text-align:right>69.49</td><td style=text-align:right>76.81</td><td style=text-align:right>86.93</td><td style=text-align:right>64.90</td><td style=text-align:right>52.81</td><td style=text-align:right>51.58</td><td style=text-align:right>54.24</td></tr><tr><td style=text-align:left>Yehia-7B-preview</td><td style=text-align:right>65.68</td><td style=text-align:right>70.81</td><td style=text-align:right>76.64</td><td style=text-align:right>87.49</td><td style=text-align:right>64.90</td><td style=text-align:right>53.40</td><td style=text-align:right>52.14</td><td style=text-align:right>54.37</td></tr><tr><td style=text-align:left>Qwen2-7B-Instruct</td><td style=text-align:right>63.61</td><td style=text-align:right>73.24</td><td style=text-align:right>71.13</td><td style=text-align:right>82.77</td><td style=text-align:right>60.01</td><td style=text-align:right>51.30</td><td style=text-align:right>47.30</td><td style=text-align:right>59.50</td></tr><tr><td style=text-align:left><strong>Falcon-Arabic-7B-Instruct</strong></td><td style=text-align:right><u>68.03</td><td style=text-align:right>72.40</td><td style=text-align:right>71.77</td><td style=text-align:right>82.54</td><td style=text-align:right><u>68.23</td><td style=text-align:right>55.37</td><td style=text-align:right>53.25</td><td style=text-align:right><u>72.95</td></tr><tr><td style=text-align:left></div></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><blockquote><p>The evaluation details (log probabilities, predictions and LLM as judge metrics) of <strong>Falcon-Arabic-7B-Instruct</strong> are available on <a href=https://huggingface.co/datasets/tiiuae/Falcon-Arabic-7B-Instruct-details>https://huggingface.co/datasets/tiiuae/Falcon-Arabic-7B-Instruct-details</a></p></blockquote><h2 id=-unlocking-the-potential-of-arabic-ai>üîì Unlocking the Potential of Arabic AI<a hidden class=anchor aria-hidden=true href=#-unlocking-the-potential-of-arabic-ai>#</a></h2><p>Falcon-Arabic sets a new benchmark for Arabic Language Models. With only 7B parameters, it delivers state-of-the-art performance outperforming models of similar size and even those several times larger across key benchmarks like Arabic MMLU, MadinahQA, and Aratrust. It combines fluency in Modern Standard Arabic, strong understanding of regional dialects, and robust reasoning and multilingual capabilities, making it ideal for a wide range of applications: from Arabic-first chatbots and educational tools to content generation, code assistance, and document understanding.</p><p>To give you a hands-on feel for what Falcon-Arabic can do, we built a simple demo that showcases its capabilities in <strong>machine translation</strong> even though the model hasn‚Äôt been fine-tuned specifically for that task. The tool runs purely on <strong>Falcon-7B-Arabic-Instruct</strong>, and the results are surprisingly strong across various translation directions. You can try it yourself through the demo linked just below. In fact, we used the same setup to translate this blog post into Arabic for our Arabic-speaking audience. Check it out <a href=https://falcon-lm.github.io/ar/blog/falcon-arabic/>here</a> üöÄ. And if you&rsquo;re curious to explore more, we also provide access to a live <a href="https://chat.falconllm.tii.ae/?model=Falcon-Arabic">playground</a> where you can interact with Falcon-Arabic Instruct and experience its performance across different tasks ‚ú®.</p><iframe src="https://tiiuae-falcon-arabic-translation-demo.hf.space/?__theme=light" frameborder=0 width=100% height=300px allow="accelerometer; camera; microphone; encrypted-media"></iframe><div style="display:flex;flex-wrap:wrap;gap:.5rem;margin:1rem 0;justify-content:center"><a href="https://chat.falconllm.tii.ae/?model=Falcon-Arabic" target=_blank style="flex:1 1 200px;background-color:#f5f0ff;border:none;border-left:4px solid purple;outline:none;padding:.75rem;text-align:center;font-weight:600;text-decoration:none;color:inherit">üó£Ô∏è <span style=color:purple;text-decoration:underline>Chat with Falcon-Arabic</span>
</a><a href=https://huggingface.co/collections/tiiuae/falcon-arabic-682cd54f8560f4baf57641d7 target=_blank style="flex:1 1 200px;background-color:#f5f0ff;border-buttom:none;border-left:4px solid purple;outline:none;padding:.75rem;text-align:center;font-weight:600;text-decoration:none;color:inherit">üìä <span style=color:purple;text-decoration:underline>View evaluation details on ü§ó collection</span></a></div><h2 id=-limitations>‚ö†Ô∏è Limitations<a hidden class=anchor aria-hidden=true href=#-limitations>#</a></h2><p>Like all Large Language Models, Falcon-Arabic inherits some common limitations. These include occasional <strong>hallucinations</strong> (producing plausible but incorrect outputs), <strong>sensitivity to how prompts are phrased</strong>, and varying performance across very long contexts. While Falcon-Arabic is designed to reduce these issues especially for Arabic tasks users should still apply critical thinking when interpreting results, particularly in high-stakes or fact-sensitive use cases.</p><h2 id=citation>Citation<a hidden class=anchor aria-hidden=true href=#citation>#</a></h2><p>If you find this work helpful for your research or projects, please consider citing it.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-latex data-lang=latex><span class=line><span class=cl>@misc<span class=nb>{</span>falcon-arabic,
</span></span><span class=line><span class=cl>    title = <span class=nb>{</span>Falcon-Arabic: A Breakthrough in Arabic Language Models<span class=nb>}</span>,
</span></span><span class=line><span class=cl>    author = <span class=nb>{</span>Falcon-LLM Team<span class=nb>}</span>,
</span></span><span class=line><span class=cl>    month = <span class=nb>{</span>May<span class=nb>}</span>,
</span></span><span class=line><span class=cl>    url = <span class=nb>{</span>https://falcon-lm.github.io/blog/falcon-arabic<span class=nb>}</span>,
</span></span><span class=line><span class=cl>    year = <span class=nb>{</span>2025<span class=nb>}</span>
</span></span><span class=line><span class=cl><span class=nb>}</span>
</span></span></code></pre></div><div class=post-contributors><div class=contributors-section><h4>Core Contributors</h4><div class=contributors-grid><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/basma_boussaha.jpg alt="Basma El Amel Boussaha" class=contributor-image><p class=contributor-name>Basma El Amel Boussaha</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/mohammed_alyafeai.jpg alt="Mohammed Alyafeai" class=contributor-image><p class=contributor-name>Mohammed Alyafeai</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/ahmed_adel_alzubaidi.jpg alt="Ahmed Alzubaidi" class=contributor-image><p class=contributor-name>Ahmed Alzubaidi</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/leen_al_qadi.jpg alt="Leen AlQadi" class=contributor-image><p class=contributor-name>Leen AlQadi</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/younes_belkada.jpg alt="Younes Belkada" class=contributor-image><p class=contributor-name>Younes Belkada</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/mikhail_lubinets.jpg alt="Mikhail Lubinets" class=contributor-image><p class=contributor-name>Mikhail Lubinets</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/hakim_hacid.png alt="Hakim Hacid" class=contributor-image><p class=contributor-name>Hakim Hacid</p></div></div></div><br></div></div></article></main><footer class=footer><span>&copy; 2026 <a href=https://falcon-lm.github.io/>Falcon</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a>
</span><span><a href=https://falconllm.tii.ae/falcon-terms-and-conditions.html rel="noopener noreferrer" target=_blank>| Terms and Conditions</a>
</span><span><a href=https://www.tii.ae/privacy-policy rel="noopener noreferrer" target=_blank>| Privacy Policy</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)"}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>