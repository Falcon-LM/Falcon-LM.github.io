<!doctype html><html lang=ar dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Falcon-Arabic: نقلة نوعية في نماذج اللغة العربية | Falcon</title>
<meta name=keywords content><meta name=description content="
  
    تنبيه: تم ترجمة هذا المقال بواسطة Falcon-Arabic 🦅
  


نحن متحمسون للإعلان عن Falcon-Arabic، نموذج لغوي كبير يحتوي على 7 مليار معامل ويعد معيارًا جديدًا لمعالجة اللغة العربية طبيعيًا. مبني على بنية Falcon 3 المتعددة اللغات، يدعم Falcon-Arabic اللغة العربية واللغة الإنجليزية وعدد من اللغات الأخرى. يتفوق في المعرفة العامة والقواعد النحوية العربية والاستدلال الرياضي وحل المشاكل المعقدة وفهم تنوع اللهجات العربية.
يدعم Falcon-Arabic  طول سياق بمقدار 32 ألف رمز  (token)، مما يمكنه من التعامل مع الوثائق الطويلة، وتمكين تطبيقات متقدمة مثل توليد المحتوى المدعوم بالاسترجاع (RAG)، وإنشاء محتوى عميق، والمهام المعرفية."><meta name=author content="Falcon Team"><link rel=canonical href=https://falcon-lm.github.io/ar/blog/falcon-arabic/><link crossorigin=anonymous href=/assets/css/stylesheet.8b9fa41d05770f933657a6befdf3e59416a8572dcdccb2def3ee65a2976037d3.css integrity="sha256-i5+kHQV3D5M2V6a+/fPllBaoVy3NzLLe8+5lopdgN9M=" rel="preload stylesheet" as=style><link rel=icon href=https://falcon-lm.github.io/img/favicon.png><link rel=apple-touch-icon href=https://falcon-lm.github.io/img/favicon.png><link rel=manifest href=https://falcon-lm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate hreflang=en href=https://falcon-lm.github.io/blog/falcon-arabic/><link rel=alternate hreflang=ar href=https://falcon-lm.github.io/ar/blog/falcon-arabic/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.c0c4976150cc57e4e574f010d054d68896d28645b524650723d1cbb26891c0a3.js integrity="sha256-wMSXYVDMV+TldPAQ0FTWiJbShkW1JGUHI9HLsmiRwKM="></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-5PVYBMYHS6"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-5PVYBMYHS6")}</script><meta property="og:title" content="Falcon-Arabic: نقلة نوعية في نماذج اللغة العربية"><meta property="og:description" content="
  
    تنبيه: تم ترجمة هذا المقال بواسطة Falcon-Arabic 🦅
  


نحن متحمسون للإعلان عن Falcon-Arabic، نموذج لغوي كبير يحتوي على 7 مليار معامل ويعد معيارًا جديدًا لمعالجة اللغة العربية طبيعيًا. مبني على بنية Falcon 3 المتعددة اللغات، يدعم Falcon-Arabic اللغة العربية واللغة الإنجليزية وعدد من اللغات الأخرى. يتفوق في المعرفة العامة والقواعد النحوية العربية والاستدلال الرياضي وحل المشاكل المعقدة وفهم تنوع اللهجات العربية.
يدعم Falcon-Arabic  طول سياق بمقدار 32 ألف رمز  (token)، مما يمكنه من التعامل مع الوثائق الطويلة، وتمكين تطبيقات متقدمة مثل توليد المحتوى المدعوم بالاسترجاع (RAG)، وإنشاء محتوى عميق، والمهام المعرفية."><meta property="og:type" content="article"><meta property="og:url" content="https://falcon-lm.github.io/ar/blog/falcon-arabic/"><meta property="og:image" content="https://falcon-lm.github.io/ar/blog/falcon-arabic/cover_1.png"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-05-21T12:00:00+00:00"><meta property="article:modified_time" content="2025-05-21T12:00:00+00:00"><meta property="og:site_name" content="Falcon"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://falcon-lm.github.io/ar/blog/falcon-arabic/cover_1.png"><meta name=twitter:title content="Falcon-Arabic: نقلة نوعية في نماذج اللغة العربية"><meta name=twitter:description content="
  
    تنبيه: تم ترجمة هذا المقال بواسطة Falcon-Arabic 🦅
  


نحن متحمسون للإعلان عن Falcon-Arabic، نموذج لغوي كبير يحتوي على 7 مليار معامل ويعد معيارًا جديدًا لمعالجة اللغة العربية طبيعيًا. مبني على بنية Falcon 3 المتعددة اللغات، يدعم Falcon-Arabic اللغة العربية واللغة الإنجليزية وعدد من اللغات الأخرى. يتفوق في المعرفة العامة والقواعد النحوية العربية والاستدلال الرياضي وحل المشاكل المعقدة وفهم تنوع اللهجات العربية.
يدعم Falcon-Arabic  طول سياق بمقدار 32 ألف رمز  (token)، مما يمكنه من التعامل مع الوثائق الطويلة، وتمكين تطبيقات متقدمة مثل توليد المحتوى المدعوم بالاسترجاع (RAG)، وإنشاء محتوى عميق، والمهام المعرفية."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://falcon-lm.github.io/ar/blog/"},{"@type":"ListItem","position":2,"name":"Falcon-Arabic: نقلة نوعية في نماذج اللغة العربية","item":"https://falcon-lm.github.io/ar/blog/falcon-arabic/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Falcon-Arabic: نقلة نوعية في نماذج اللغة العربية","name":"Falcon-Arabic: نقلة نوعية في نماذج اللغة العربية","description":" تنبيه: تم ترجمة هذا المقال بواسطة Falcon-Arabic 🦅 نحن متحمسون للإعلان عن Falcon-Arabic، نموذج لغوي كبير يحتوي على 7 مليار معامل ويعد معيارًا جديدًا لمعالجة اللغة العربية طبيعيًا. مبني على بنية Falcon 3 المتعددة اللغات، يدعم Falcon-Arabic اللغة العربية واللغة الإنجليزية وعدد من اللغات الأخرى. يتفوق في المعرفة العامة والقواعد النحوية العربية والاستدلال الرياضي وحل المشاكل المعقدة وفهم تنوع اللهجات العربية.\nيدعم Falcon-Arabic طول سياق بمقدار 32 ألف رمز (token)، مما يمكنه من التعامل مع الوثائق الطويلة، وتمكين تطبيقات متقدمة مثل توليد المحتوى المدعوم بالاسترجاع (RAG)، وإنشاء محتوى عميق، والمهام المعرفية.\n","keywords":[],"articleBody":" تنبيه: تم ترجمة هذا المقال بواسطة Falcon-Arabic 🦅 نحن متحمسون للإعلان عن Falcon-Arabic، نموذج لغوي كبير يحتوي على 7 مليار معامل ويعد معيارًا جديدًا لمعالجة اللغة العربية طبيعيًا. مبني على بنية Falcon 3 المتعددة اللغات، يدعم Falcon-Arabic اللغة العربية واللغة الإنجليزية وعدد من اللغات الأخرى. يتفوق في المعرفة العامة والقواعد النحوية العربية والاستدلال الرياضي وحل المشاكل المعقدة وفهم تنوع اللهجات العربية.\nيدعم Falcon-Arabic طول سياق بمقدار 32 ألف رمز (token)، مما يمكنه من التعامل مع الوثائق الطويلة، وتمكين تطبيقات متقدمة مثل توليد المحتوى المدعوم بالاسترجاع (RAG)، وإنشاء محتوى عميق، والمهام المعرفية.\nيقوم Falcon-Arabic بإعادة تعريف حدود ما يمكن تحقيقه فيما يتعلق بالنماذج اللغوية العربية. فهو يفوق بكثير النماذج الأخرى ذات الحجم المماثل وحتى تلك الأكبر بأربعة أضعاف، سواء كانت نماذج عربية الأصل أو نماذج تم تكييفها من لغات أخرى. وهذا يجعل Falcon-Arabic ليس فقط نموذجاً رائداً من حيث الأداء، بل أيضاً حلاً فريداً وفعالاً ومتاحاً للباحثين والمطورين المهتمين باللغة العربية.\n🚀 نقدم Falcon-Arabic: نحو تطوير نماذج لغوية كبيرة للعالم الناطق بالعربية في السنوات الأخيرة، قامت النماذج اللغوية الكبيرة بإحداث قفزة نوعية في الذكاء الاصطناعي، وتمكنت من توفير أدوات للترجمة وإنشاء المحتوى والمساعدة الافتراضية وغيرها الكثير. ولكن معظم هذا التقدم ركز على لغات معينة مثل الإنجليزية، تاركاً لغات اخرى، مثل العربية، دون تمثيل كافٍ. تشكل اللغة العربية تحديات فريدة فهي غنية بالنحو، ثنائية اللهجة (تشمل كلاً من اللغة العربية المعاصرة واللهجات المحلية المتنوعة)، وتستخدم من قبل سكان متنوعين ثقافيا. إن تطوير نماذج اللغة العربية متقدمة المستوى يعد أمراً ضرورياً لضمان حصول المجتمعات الناطقة بالعربية على المزايا التي نشهدها مع ثورة الذكاء الاصطناعي.\nبناءً على هذه الرؤية، نعلن لكم عن Falcon-Arabic، نسخة متخصصة من عائلة نماذج Falcon 3، المطورة من قبل معهد الابتكار التكنولوجي (TII) في دولة الإمارات العربية المتحدة. اكتسبت عائلة Falcon شهرة عالمية بفضل قدرتها القوية على التعامل مع اللغات المتعددة ونهجها المفتوح المصدر. يبني Falcon-Arabic على هذا الإرث، حيث يجلب قدرات متقدمة في فهم اللغة العربية وتوليدها. ومن خلال تدريب النموذج للتعامل مع اللغة العربية المعاصرة وبعض اللهجات المحورية، يملأ Falcon-Arabic فجوة حرجة في تكنولوجيا اللغة، مما يمكّن ذكاءً عربيًا أكثر طبيعية وذكيًا وشاملًا عبر الخليج والشرق الأوسط وشمال أفريقيا.\n🦅 Falcon-Arabic قد حطّ رحاله - إليكم وصفة التدريب 🧪 بدأ بناء Falcon-Arabic بقرار استراتيجي: بدلاً من تدريب نموذج من الصفر، اخترنا تكييف أساس متعدد اللغات قوي. وفي مشهد نماذج اللغة العربية، هناك ثلاث طرق رئيسية: التدريب من الصفر (على سبيل المثال، Jais-native)، تكييف النماذج متعددة اللغات (مثل Allam أو Fanar)، أو استخدام نماذج تدعم اللغة العربية ضمن مجموعة من اللغات الأخرى (مثل Qwen أو LLaMA). عند النظر إلى لوحة صدارة النماذج العربية المفتوحة، أصبح من الواضح أن النماذج المتكيفة والمتعددة اللغات تفوقت باستمرار على غيرها من حيث الكفاءة والقدرة. للاستفادة من هذا الزخم، قمنا باختيار Falcon 3-7B، وهو نموذج يحقق توازن عملي بين الأداء وكفاءة الموارد ضمن عائلة Falcon 3 المطورة من قبل معهد الابتكار التكنولوجي (TII).\nكان التحدي الأساسي هو تكييف Falcon 3-7B، الذي يفتقر أصلاً لدعم اللغة العربية على مستوى المحلل الصرفي (tokenizer) أو التمثيلات الأولية (embeddings). لقد عالجنا ذلك بإضافة “32,000 رمز عربي محدد” إلى قاموس المحلل اللغوي، وتطبيق استراتيجية جديدة لتهيئة التمثيلات الأولية مبنية على تشابه النصوص. تعمل هذه التقنية على تعيين الرموز العربية الجديدة إلى تمثيلات مشابهة معنويًا من المفردات الأصلية، مما يسمح للنموذج باكتساب المعرفة السابقة وتسريع التعلم خاصة حول المشاعر والمفاهيم المجردة وأنماط الاستدلال. أعطى هذا Falcon-Arabic بداية جيدة لفهم وإنتاج نص عالي الجودة باللغة العربية.\nمع تجهيز المحلل الصرفي والتمثيلات الأولية، بدأنا بتدريب مستمر باستخدام مجموعات بيانات عالية الجودة بنسبة 100٪ أصلية باللغة العربية، وتجنبنا استخدام المحتوى المترجم آلياً لتقليل الانحياز الثقافي وحفظ الأصالة اللغوية. اتبع التدريب منهجاً متعدد المراحل: ركزت المراحل المبكرة على “المعرفة العامة ومحتوى غني باللهجة العربية” لتثبيت النموذج وتعزيز القدرات المنطقية، بينما ركزت المراحل اللاحقة على “الرياضيات والبرمجة والاستدلال”. كانت النتيجة نموذج يتحدث العربية بطلاقة و بلهجات عديدة ويحتفظ بقوة Falcon متعددة اللغات وقدرات الاستدلال، دافعًا حدود الذكاء الاصطناعي باللغة العربية.\nمتوسط أداء النماذج المسبقة التدريب 📊 Falcon-Arabic: الارتقاء بمعايير النماذج اللغوية العربية الكبيرة قمنا بتقييم Falcon-Arabic على OALL v2، وهو المعيار الرائد لتقييم النماذج اللغوية العربية. يتضمن هذا المعيار ست مهام من نوع الاختيار من متعدد مثل Arabic MMLU (بالنسختين الأصلية والمترجمة)، وArabic Exams، وAlghafa، وMadinahQA، وAratrust، بالإضافة إلى معيار توليدي واحد هو Alrage.\nيتفوق Falcon-Arabic على جميع النماذج العربية الموجودة ضمن نفس الفئة الحجمية، بل ويتجاوز أداء نماذج أكبر منه حتى بأربع مرات. وقد تصدّر نتائج معايير رئيسية مثل Arabic MMLU، وExams، وMadinahQA، وAratrust، مما يضع معيارًا جديدًا للنماذج اللغوية المصممة خصيصًا للغة العربية.\nجدول مقارنة النماذج المسبقة التدريب Model Average ALGhafa ArabicMMLU Exams MadinahQA AraTrust ALRAGE ArbMMLU-HT AceGPT-v2-32B 61.74 54.93 63.15 48.6 59.71 83.96 68.96 52.87 Qwen2.5-14B 54.26 69.32 46.37 37.43 30.38 70.46 74.03 51.84 AceGPT-13B 47.21 48.23 41.38 36.87 35.37 56.51 79.96 32.12 gemma-2-9b-it 46.64 47.92 36.28 27.93 31.7 77.15 80.47 25.01 Llama-3.1-8B 51.64 64.34 52.28 40.04 43.08 71.98 47.08 42.67 Qwen2.5-7B 41.97 31.72 37.36 37.99 27.11 53.66 62.68 43.30 Falcon-Arabic-7B-Base 62.57 67.17 64.85 52.89 48.79 85.36 63.71 55.25 تفاصيل التقييم (log probabilities، التنبؤات ومعايير LLM كحكم) لـ Falcon-Arabic-7B-Base متاحة على https://huggingface.co/datasets/tiiuae/Falcon-Arabic-7B-Base-details\n🗣️ من التدريب الأولي إلى الدردشة: تدريب Falcon-Arabic على المحادثات بعد الانتهاء من مرحلة تدريب النموذج الأساسي، أجرينا مرحلة “التوافق بعد التدريب” لضبط ردود Falcon-Arabic وفقًا لتفضيلات البشر. بدأت هذه المرحلة بمرحلة “الصقل الخاضعة للإشراف” (SFT) باستخدام مزيج من مجموعات بيانات عامة عالية الجودة وبيانات داخلية مجمعة “باللغة العربية الأصلية”، تغطي مجموعة واسعة من المهام وسيناريوهات المحادثة.\nلتعزيز التوافق بشكل أكبر، طبقنا طريقة “تحسين التفضيل المباشر” (DPO)، وهي طريقة تعلم معززة تقوم بضبط النموذج ليفضل الردود التي يصنفها البشر بأنها أكثر فائدة وأمانًا وملاءمة. تضمن هذه العملية المكونة من خطوتين أن يكون Falcon-Arabic Instruct يفهم اللغة العربية جيدًا و أن يرد بطريقة تتوافق مع توقعات المستخدم الحقيقية.\nمتوسط أداء نماذج المحادثة كما تظهر نتائج الرسوم البيانية، فإن Falcon-Arabic Instruct يتصدر المجموعة، متفوق على جميع نماذج اللغة العربية الأخرى في فئته وحجمه وأكبر منه بشكل ملحوظ عبر عدة معايير. يُظهر النموذج أداءً قوياً في اتباع الإرشادات والحوار المفتوح، واضعًا معيارًا جديدًا للذكاء الاصطناعي الحواري باللغة العربية. أداء نماذج المحادثة عبر معايير التقييم جدول مقارنة نماذج المحادثة Model Average ALGhafa ALRAGE AraTrust ArabicMMLU ArbMMLU-HT Exams MadinahQA aya-expanse-32b 67.17 77.61 79.64 89.00 60.63 58.86 51.02 53.45 c4ai-command-r7b-arabic-02-2025 67.07 74.84 75.90 80.47 59.34 50.14 64.99 63.84 ALLaM-7B-Instruct-preview 65.25 69.49 76.81 86.93 64.90 52.81 51.58 54.24 Yehia-7B-preview 65.68 70.81 76.64 87.49 64.90 53.40 52.14 54.37 Qwen2-7B-Instruct 63.61 73.24 71.13 82.77 60.01 51.30 47.30 59.50 Falcon-Arabic-7B-Instruct 68.03 72.40 71.77 82.54 68.23 55.37 53.25 72.95 تفاصيل التقييم (log probabilities، التنبؤات ومعايير LLM كحكم) لـ Falcon-Arabic-7B-Instruct متاحة على https://huggingface.co/datasets/tiiuae/Falcon-Arabic-7B-Instruct-details\n🔓 إطلاق العنان لإمكانات الذكاء الاصطناعي العربي يتحدى Falcon-Arabic المعايير فيما يتعلق بنماذج اللغة العربية. رغم أنه 7 مليار معامل، فإنه يقدم أداءً قياسياً يتفوق على النماذج المماثلة في الحجم وحتى تلك الأكبر بعدة مرات عبر مؤشرات أساسية مثل Arabic MMLU، MadinahQA، وAratrust. يجمع بين الطلاقة في اللغة العربية القياسية الحديثة والفهم القوي للهجات الإقليمية والقدرات الاستنباطية والمتعددة اللغات، مما يجعله مثاليًا لمجموعة واسعة من التطبيقات: بدءًا من روبوتات المحادثة التي تركز على اللغة العربية والأدوات التعليمية، والأدوات التعليمية، إلى توليد المحتوى، والمساعدة في البرمجة، وفهم المستندات.\nلإعطائك فكرة عملية عما يمكن أن يفعله Falcon-Arabic ، قمنا ببناء عرض بسيط يُظهر قدراته في “الترجمة” رغم أن النموذج لم يتم ضبطه خصيصًا لهذا الغرض. تعمل الأداة بالكامل باستخدام “Falcon-7B-Arabic-Instruct”، والنتائج ممتازة عبر مختلف اتجاهات الترجمة. يمكنك تجربتها بنفسك من خلال العرض التجريبي المُشار إليه أدناه. لقد استخدمنا نفس الإعداد لترجمة هذا المنشور بالمدونة إلى اللغة العربية للجمهور الناطق بها 🚀. وإذا كنت ترغب في استكشاف المزيد ، فإننا نوفر أيضًا منصة تمكنك من التفاعل مع Falcon-Arabic Instruct وتجربة أدائه عبر مهام مختلفة ✨.\n🔗 اختبر النموذج 📊 عرض المجموعات والتقييمات🤗 ⚠️ القيود مثل جميع النماذج اللغوية الضخمة، يرث Falcon-Arabic بعض القيود الشائعة. وتشمل هذه أحيانًا “الهلوسات” (إنتاج ردود معقولة ولكنها خاطئة)، وحساسية كيفية صياغة المطالبات، وأداء متغير عبر سياقات طويلة جداً. وعلى الرغم من تصميم Falcon-Arabic لتخفيف هذه القضايا خصوصًا للمهام المتعلقة باللغة العربية، يجب على المستخدمين ممارسة تفكير نقدي عند تفسير النتائج، وخاصة في الحالات الحساسة للأداء العالي أو الحساسة للحقائق.\nالاستشهاد إذا وجدت هذا العمل مفيدًا لبحثك أو مشاريعك، يرجى إضافة الاقتباس عنه.\n@misc{falcon-arabic, title = {Falcon-Arabic: A Breakthrough in Arabic Language Models}, author = {Falcon-LLM Team}, month = {May}, url = {https://falcon-lm.github.io/blog/falcon-arabic}, year = {2025} } ","wordCount":"1329","inLanguage":"ar","image":"https://falcon-lm.github.io/ar/blog/falcon-arabic/cover_1.png","datePublished":"2025-05-21T12:00:00Z","dateModified":"2025-05-21T12:00:00Z","author":{"@type":"Person","name":"Falcon Team"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://falcon-lm.github.io/ar/blog/falcon-arabic/"},"publisher":{"@type":"Organization","name":"Falcon","logo":{"@type":"ImageObject","url":"https://falcon-lm.github.io/img/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!0</script><header class=header><div class="nav-container nav-background"><nav class=nav><div class=logo><a href=/ accesskey=h title="Falcon (Alt + H)"><img src=https://falcon-lm.github.io/img/logo.svg alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://chat.falconllm.tii.ae/ title="Try Falcon Chat"><span>Try Falcon Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero-background style="background:url(/img/falcon_arabic_cover.png)50%/cover no-repeat fixed"></div><div class=hero-gradient></div><div class=hero-blur></div><div class="hero text-light"><h1 class=post-title>Falcon-Arabic: نقلة نوعية في نماذج اللغة العربية</h1><div class=post-meta><span title='2025-05-21 12:00:00 +0000 UTC'>مايو 21, 2025</span>&nbsp;•&nbsp;بضع ثوان&nbsp;•&nbsp;1329 words&nbsp;•&nbsp;Falcon Team&nbsp;|&nbsp;ترجمات أخرى:<ul class=i18n_list><li><a href=https://falcon-lm.github.io/blog/falcon-arabic/>English</a></li></ul></div></div></div><main class=main><article class=post-single><figure class=entry-cover><a href=/ar/blog/falcon-arabic/cover_1.png target=_blank rel="noopener noreferrer"><img loading=lazy srcset="https://falcon-lm.github.io/blog/falcon-arabic/cover_1_hu_f91e8c4b5b2aaa53.png 360w ,https://falcon-lm.github.io/blog/falcon-arabic/cover_1_hu_36104b4ab20431ec.png 480w ,https://falcon-lm.github.io/blog/falcon-arabic/cover_1_hu_b035990eacb93ea9.png 720w ,https://falcon-lm.github.io/blog/falcon-arabic/cover_1_hu_867e866c47fd45ed.png 1080w ,https://falcon-lm.github.io/blog/falcon-arabic/cover_1_hu_2061a7903fd7b483.png 1500w ,https://falcon-lm.github.io/blog/falcon-arabic/cover_1.png 1536w" sizes="(min-width: 768px) 720px, 100vw" src=https://falcon-lm.github.io/blog/falcon-arabic/cover_1.png alt width=1536 height=1024></a></figure><div class=post-content><div dir=rtl class=translation-notice><p>تنبيه: تم ترجمة هذا المقال بواسطة <span class=llm-name>Falcon-Arabic</span> 🦅</p></div><div dir=rtl><p>نحن متحمسون للإعلان عن Falcon-Arabic، نموذج لغوي كبير يحتوي على 7 مليار معامل ويعد معيارًا جديدًا لمعالجة اللغة العربية طبيعيًا. مبني على بنية Falcon 3 المتعددة اللغات، يدعم Falcon-Arabic اللغة العربية واللغة الإنجليزية وعدد من اللغات الأخرى. يتفوق في المعرفة العامة والقواعد النحوية العربية والاستدلال الرياضي وحل المشاكل المعقدة وفهم تنوع اللهجات العربية.</p><p>يدعم Falcon-Arabic طول سياق بمقدار 32 ألف رمز (token)، مما يمكنه من التعامل مع الوثائق الطويلة، وتمكين تطبيقات متقدمة مثل توليد المحتوى المدعوم بالاسترجاع (RAG)، وإنشاء محتوى عميق، والمهام المعرفية.</p><p>يقوم Falcon-Arabic بإعادة تعريف حدود ما يمكن تحقيقه فيما يتعلق بالنماذج اللغوية العربية. فهو يفوق بكثير النماذج الأخرى ذات الحجم المماثل وحتى تلك الأكبر بأربعة أضعاف، سواء كانت نماذج عربية الأصل أو نماذج تم تكييفها من لغات أخرى. وهذا يجعل Falcon-Arabic ليس فقط نموذجاً رائداً من حيث الأداء، بل أيضاً حلاً فريداً وفعالاً ومتاحاً للباحثين والمطورين المهتمين باللغة العربية.</p><h2 id=-نقدم-falcon-arabic-نحو-تطوير-نماذج-لغوية-كبيرة-للعالم-الناطق-بالعربية>🚀 نقدم Falcon-Arabic: نحو تطوير نماذج لغوية كبيرة للعالم الناطق بالعربية<a hidden class=anchor aria-hidden=true href=#-نقدم-falcon-arabic-نحو-تطوير-نماذج-لغوية-كبيرة-للعالم-الناطق-بالعربية>#</a></h2><p>في السنوات الأخيرة، قامت النماذج اللغوية الكبيرة بإحداث قفزة نوعية في الذكاء الاصطناعي، وتمكنت من توفير أدوات للترجمة وإنشاء المحتوى والمساعدة الافتراضية وغيرها الكثير. ولكن معظم هذا التقدم ركز على لغات معينة مثل الإنجليزية، تاركاً لغات اخرى، مثل العربية، دون تمثيل كافٍ. تشكل اللغة العربية تحديات فريدة فهي غنية بالنحو، ثنائية اللهجة (تشمل كلاً من اللغة العربية المعاصرة واللهجات المحلية المتنوعة)، وتستخدم من قبل سكان متنوعين ثقافيا. إن تطوير نماذج اللغة العربية متقدمة المستوى يعد أمراً ضرورياً لضمان حصول المجتمعات الناطقة بالعربية على المزايا التي نشهدها مع ثورة الذكاء الاصطناعي.</p><p>بناءً على هذه الرؤية، نعلن لكم عن <strong>Falcon-Arabic</strong>، نسخة متخصصة من <a href=https://huggingface.co/collections/tiiuae/falcon3-67605ae03578be86e4e87026>عائلة نماذج <strong>Falcon 3</strong></a>، المطورة من قبل <a href=https://www.tii.ae/><strong>معهد الابتكار التكنولوجي (TII)</strong></a> في دولة الإمارات العربية المتحدة. اكتسبت عائلة Falcon شهرة عالمية بفضل قدرتها القوية على التعامل مع اللغات المتعددة ونهجها المفتوح المصدر. يبني Falcon-Arabic على هذا الإرث، حيث يجلب قدرات متقدمة في فهم اللغة العربية وتوليدها. ومن خلال تدريب النموذج للتعامل مع اللغة العربية المعاصرة وبعض اللهجات المحورية، يملأ Falcon-Arabic فجوة حرجة في تكنولوجيا اللغة، مما يمكّن ذكاءً عربيًا أكثر طبيعية وذكيًا وشاملًا عبر الخليج والشرق الأوسط وشمال أفريقيا.</p><figure><img src=/blog/falcon-arabic/radar.png alt="Pretrained models performance"></figure><h2 id=-falcon-arabic-قد-حط-رحاله----إليكم-وصفة-التدريب->🦅 Falcon-Arabic قد حطّ رحاله - إليكم وصفة التدريب 🧪<a hidden class=anchor aria-hidden=true href=#-falcon-arabic-قد-حط-رحاله----إليكم-وصفة-التدريب->#</a></h2><p>بدأ بناء Falcon-Arabic بقرار استراتيجي: بدلاً من تدريب نموذج من الصفر، اخترنا تكييف أساس متعدد اللغات قوي. وفي مشهد نماذج اللغة العربية، هناك ثلاث طرق رئيسية: التدريب من الصفر (على سبيل المثال، Jais-native)، تكييف النماذج متعددة اللغات (مثل Allam أو Fanar)، أو استخدام نماذج تدعم اللغة العربية ضمن مجموعة من اللغات الأخرى (مثل Qwen أو LLaMA). عند النظر إلى <a href=https://huggingface.co/spaces/OALL/Open-Arabic-LLM-Leaderboard>لوحة صدارة النماذج العربية المفتوحة</a>، أصبح من الواضح أن النماذج المتكيفة والمتعددة اللغات تفوقت باستمرار على غيرها من حيث الكفاءة والقدرة. للاستفادة من هذا الزخم، قمنا باختيار Falcon 3-7B، وهو نموذج يحقق توازن عملي بين الأداء وكفاءة الموارد ضمن عائلة Falcon 3 المطورة من قبل معهد الابتكار التكنولوجي (TII).</p><p>كان التحدي الأساسي هو تكييف <a href=https://huggingface.co/tiiuae/Falcon3-7B-Base>Falcon 3-7B</a>، الذي يفتقر أصلاً لدعم اللغة العربية على مستوى المحلل الصرفي (tokenizer) أو التمثيلات الأولية (embeddings). لقد عالجنا ذلك بإضافة &ldquo;32,000 رمز عربي محدد&rdquo; إلى قاموس المحلل اللغوي، وتطبيق استراتيجية جديدة لتهيئة التمثيلات الأولية مبنية على تشابه النصوص. تعمل هذه التقنية على تعيين الرموز العربية الجديدة إلى تمثيلات مشابهة معنويًا من المفردات الأصلية، مما يسمح للنموذج باكتساب المعرفة السابقة وتسريع التعلم خاصة حول المشاعر والمفاهيم المجردة وأنماط الاستدلال. أعطى هذا Falcon-Arabic بداية جيدة لفهم وإنتاج نص عالي الجودة باللغة العربية.</p><p>مع تجهيز المحلل الصرفي والتمثيلات الأولية، بدأنا بتدريب مستمر باستخدام مجموعات بيانات عالية الجودة بنسبة 100٪ أصلية باللغة العربية، وتجنبنا استخدام المحتوى المترجم آلياً لتقليل الانحياز الثقافي وحفظ الأصالة اللغوية. اتبع التدريب منهجاً متعدد المراحل: ركزت المراحل المبكرة على &ldquo;المعرفة العامة ومحتوى غني باللهجة العربية&rdquo; لتثبيت النموذج وتعزيز القدرات المنطقية، بينما ركزت المراحل اللاحقة على &ldquo;الرياضيات والبرمجة والاستدلال&rdquo;. كانت النتيجة نموذج يتحدث العربية بطلاقة و بلهجات عديدة ويحتفظ بقوة Falcon متعددة اللغات وقدرات الاستدلال، دافعًا حدود الذكاء الاصطناعي باللغة العربية.</p><h3 id=متوسط-أداء-النماذج-المسبقة-التدريب>متوسط أداء النماذج المسبقة التدريب<a hidden class=anchor aria-hidden=true href=#متوسط-أداء-النماذج-المسبقة-التدريب>#</a></h3><div id=chart-pretrained-avg></div><script src=https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js></script><script>(function(){let n;try{n=JSON.parse(`
[
    {"category": "Average", "model": "AceGPT-v2-32B", "value": 0.6174},
    {"category": "Average", "model": "Qwen2.5-14B", "value": 0.5426},
    {"category": "Average", "model": "AceGPT-13B", "value": 0.4721},
    {"category": "Average", "model": "gemma-2-9b-it", "value": 0.4664},
    {"category": "Average", "model": "Llama-3.1-8B", "value": 0.5164},
    {"category": "Average", "model": "Qwen2.5-7B", "value": 0.41969999999999996},
    {"category": "Average", "model": "Falcon-Arabic-7B-Base", "value": 0.6257}
]
`)}catch(e){console.error("Error parsing chart data:",e),n=[]}const p=[],t=p.length>0?p:Array.from(new Set(n.map(e=>e.model))),u=[],g=u.length>0?u:Array.from(new Set(n.map(e=>e.category))),b="Falcon-Arabic-7B-Base",r=b||t[0],v=!0,e={top:40,right:30,bottom:40,left:60},m=800-e.left-e.right,i=430-e.top-e.bottom,a=d3.select("#chart-pretrained-avg").append("svg").attr("width",m+e.left+e.right).attr("height",i+e.top+e.bottom).append("g").attr("transform",`translate(${e.left},${e.top})`);document.getElementById("tooltip-pretrained-avg")||d3.select("body").append("div").attr("id","tooltip-pretrained-avg").attr("class","tooltip").style("position","absolute").style("padding","10px").style("background","#f9f9f9").style("border","1px solid #ddd").style("border-radius","5px").style("pointer-events","none").style("opacity","0").style("transition","opacity 0.3s").style("font-family","inherit").style("font-size","14px").style("box-shadow","0 2px 5px rgba(0,0,0,0.1)");const h=d3.select("#tooltip-pretrained-avg"),d=d3.scaleBand().domain(g).range([0,m]).padding(.3);a.append("g").attr("transform",`translate(0,${i})`).call(d3.axisBottom(d).tickSize(0)).selectAll(".tick").each(function(e){d3.select(this).select("text").remove();const t=d3.select(this).append("foreignObject").attr("x",-50).attr("y",0).attr("width",100).attr("height",50);t.append("xhtml:div").style("font-weight","bold").style("font-family","inherit").style("word-wrap","break-word").style("text-align","center").style("width","100%").text(e)});const f=d3.scaleBand().domain(t).range([0,d.bandwidth()]).padding(.05);let s="0.40",o="0.7";if(s===null||o===null){const e=n.map(e=>e.value),t=(Math.max(...e)-Math.min(...e))*.1;s=s===null?Math.max(0,Math.min(...e)-t):s,o=o===null?Math.max(...e)+t:o}const l=d3.scaleLinear().domain([s,o]).range([i,0]);a.append("g").call(d3.axisLeft(l).tickFormat(e=>v?d3.format(".0%")(e):d3.format(".2f")(e))).selectAll("text").style("font-family","inherit");const c=e=>{if(e.model===r)return"#b987ff";const s=t.indexOf(e.model),o=t.length,n=128-s*(0-80)/(o-1||1);return`rgb(${n}, ${n+8}, ${n+16})`},j=e=>{if(e===r)return"#b088ff";const s=t.indexOf(e),o=t.length,i=128-s*(0-80)/(o-1||1),n=Math.min(i+30,230);return`rgb(${n}, ${n+8}, ${n+16})`};g.forEach(e=>{const t=n.filter(t=>t.category===e),s=a.append("g").attr("class",`category-group-${e}`);s.selectAll(`.bar-${e}`).data(t).enter().append("rect").attr("class","bar").attr("x",t=>d(e)+f(t.model)).attr("y",e=>l(e.value)).attr("width",f.bandwidth()).attr("height",e=>i-l(e.value)).attr("fill",e=>c(e)).attr("data-model",e=>e.model).style("transition","opacity 0.3s"),s.on("mouseover",function(n){d3.select(this).selectAll("rect").attr("stroke","#333").attr("stroke-width",2).attr("fill",function(){const e=d3.select(this).attr("data-model");return j(e)});const s=`<strong style="font-size: 16px;">${e}</strong><br/><span style="font-size: 12px;">`+t.map(e=>v?`${e.model}: ${(e.value*100).toFixed(2)}%`:`${e.model}: ${e.value.toFixed(3)}`).join("<br/>")+"</span>";h.style("opacity",1).html(s).style("left",n.pageX+15+"px").style("top",n.pageY-28+"px")}).on("mouseout",function(){d3.select(this).selectAll("rect").attr("stroke","none").attr("fill",function(){const e=d3.select(this).attr("data-model");return c({model:e})}),h.style("opacity",0)})}),a.append("text").attr("text-anchor","middle").attr("transform","rotate(-90)").attr("y",-e.left+15).attr("x",-i/2).text("Score %").style("font-family","inherit");const y=d3.select("#chart-pretrained-avg").append("div").style("display","flex").style("justify-content","center").style("font-size","14px").style("margin-top","-10px"),_=[...t].sort((e,n)=>e===r?-1:n===r?1:t.indexOf(e)-t.indexOf(n));_.forEach(e=>{const n=c({model:e}),t=y.append("div").style("display","flex").style("align-items","center").style("margin","0 10px");t.append("div").style("width","20px").style("height","20px").style("margin-right","5px").style("background-color",n),t.append("div").text(e)})})()</script><h2 id=-falcon-arabic-الارتقاء-بمعايير-النماذج-اللغوية-العربية-الكبيرة>📊 Falcon-Arabic: الارتقاء بمعايير النماذج اللغوية العربية الكبيرة<a hidden class=anchor aria-hidden=true href=#-falcon-arabic-الارتقاء-بمعايير-النماذج-اللغوية-العربية-الكبيرة>#</a></h2><p>قمنا بتقييم <strong>Falcon-Arabic</strong> على <strong><a href=https://huggingface.co/spaces/OALL/Open-Arabic-LLM-Leaderboard>OALL v2</a></strong>، وهو المعيار الرائد لتقييم النماذج اللغوية العربية. يتضمن هذا المعيار ست مهام من نوع الاختيار من متعدد مثل Arabic MMLU (بالنسختين الأصلية والمترجمة)، وArabic Exams، وAlghafa، وMadinahQA، وAratrust، بالإضافة إلى معيار توليدي واحد هو Alrage.<br><strong>يتفوق Falcon-Arabic على جميع النماذج العربية الموجودة ضمن نفس الفئة الحجمية، بل ويتجاوز أداء نماذج أكبر منه حتى بأربع مرات</strong>. وقد تصدّر نتائج معايير رئيسية مثل Arabic MMLU، وExams، وMadinahQA، وAratrust، مما يضع معيارًا جديدًا للنماذج اللغوية المصممة خصيصًا للغة العربية.</p><div id=chart-pretrained-detailed></div><script src=https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js></script><script>(function(){let n;try{n=JSON.parse(`
[
    {"category": "ALGhafa", "model": "AceGPT-v2-32B", "value": 0.5493},
    {"category": "ALGhafa", "model": "Qwen2.5-14B", "value": 0.6931999999999999},
    {"category": "ALGhafa", "model": "AceGPT-13B", "value": 0.48229999999999995},
    {"category": "ALGhafa", "model": "gemma-2-9b-it", "value": 0.4792},
    {"category": "ALGhafa", "model": "Llama-3.1-8B", "value": 0.6434000000000001},
    {"category": "ALGhafa", "model": "Qwen2.5-7B", "value": 0.3172},
    {"category": "ALGhafa", "model": "Falcon-Arabic-7B-Base", "value": 0.67},
    {"category": "ArabicMMLU", "model": "AceGPT-v2-32B", "value": 0.6315},
    {"category": "ArabicMMLU", "model": "Qwen2.5-14B", "value": 0.4637},
    {"category": "ArabicMMLU", "model": "AceGPT-13B", "value": 0.4138},
    {"category": "ArabicMMLU", "model": "gemma-2-9b-it", "value": 0.3628},
    {"category": "ArabicMMLU", "model": "Llama-3.1-8B", "value": 0.5228},
    {"category": "ArabicMMLU", "model": "Qwen2.5-7B", "value": 0.3736},
    {"category": "ArabicMMLU", "model": "Falcon-Arabic-7B-Base", "value": 0.65},
    {"category": "Exams", "model": "AceGPT-v2-32B", "value": 0.486},
    {"category": "Exams", "model": "Qwen2.5-14B", "value": 0.3743},
    {"category": "Exams", "model": "AceGPT-13B", "value": 0.36869999999999997},
    {"category": "Exams", "model": "gemma-2-9b-it", "value": 0.2793},
    {"category": "Exams", "model": "Llama-3.1-8B", "value": 0.4004},
    {"category": "Exams", "model": "Qwen2.5-7B", "value": 0.3799},
    {"category": "Exams", "model": "Falcon-Arabic-7B-Base", "value": 0.53},
    {"category": "MadinahQA", "model": "AceGPT-v2-32B", "value": 0.5971},
    {"category": "MadinahQA", "model": "Qwen2.5-14B", "value": 0.3038},
    {"category": "MadinahQA", "model": "AceGPT-13B", "value": 0.35369999999999996},
    {"category": "MadinahQA", "model": "gemma-2-9b-it", "value": 0.317},
    {"category": "MadinahQA", "model": "Llama-3.1-8B", "value": 0.43079999999999996},
    {"category": "MadinahQA", "model": "Qwen2.5-7B", "value": 0.2711},
    {"category": "MadinahQA", "model": "Falcon-Arabic-7B-Base", "value": 0.49},
    {"category": "AraTrust", "model": "AceGPT-v2-32B", "value": 0.8396},
    {"category": "AraTrust", "model": "Qwen2.5-14B", "value": 0.7045999999999999},
    {"category": "AraTrust", "model": "AceGPT-13B", "value": 0.5650999999999999},
    {"category": "AraTrust", "model": "gemma-2-9b-it", "value": 0.7715},
    {"category": "AraTrust", "model": "Llama-3.1-8B", "value": 0.7198},
    {"category": "AraTrust", "model": "Qwen2.5-7B", "value": 0.5366},
    {"category": "AraTrust", "model": "Falcon-Arabic-7B-Base", "value": 0.85},
    {"category": "ALRAGE", "model": "AceGPT-v2-32B", "value": 0.6896},
    {"category": "ALRAGE", "model": "Qwen2.5-14B", "value": 0.7403},
    {"category": "ALRAGE", "model": "AceGPT-13B", "value": 0.7996},
    {"category": "ALRAGE", "model": "gemma-2-9b-it", "value": 0.8047},
    {"category": "ALRAGE", "model": "Llama-3.1-8B", "value": 0.4708},
    {"category": "ALRAGE", "model": "Qwen2.5-7B", "value": 0.6268},
    {"category": "ALRAGE", "model": "Falcon-Arabic-7B-Base", "value": 0.64},
    {"category": "ArbMMLU-HT", "model": "AceGPT-v2-32B", "value": 0.5287},
    {"category": "ArbMMLU-HT", "model": "Qwen2.5-14B", "value": 0.5184000000000001},
    {"category": "ArbMMLU-HT", "model": "AceGPT-13B", "value": 0.3212},
    {"category": "ArbMMLU-HT", "model": "gemma-2-9b-it", "value": 0.2501},
    {"category": "ArbMMLU-HT", "model": "Llama-3.1-8B", "value": 0.4267},
    {"category": "ArbMMLU-HT", "model": "Qwen2.5-7B", "value": 0.433},
    {"category": "ArbMMLU-HT", "model": "Falcon-Arabic-7B-Base", "value": 0.55}
]
`)}catch(e){console.error("Error parsing chart data:",e),n=[]}const p=[],t=p.length>0?p:Array.from(new Set(n.map(e=>e.model))),u=[],g=u.length>0?u:Array.from(new Set(n.map(e=>e.category))),b="Falcon-Arabic-7B-Base",r=b||t[0],v=!0,e={top:40,right:30,bottom:40,left:60},m=800-e.left-e.right,i=430-e.top-e.bottom,a=d3.select("#chart-pretrained-detailed").append("svg").attr("width",m+e.left+e.right).attr("height",i+e.top+e.bottom).append("g").attr("transform",`translate(${e.left},${e.top})`);document.getElementById("tooltip-pretrained-detailed")||d3.select("body").append("div").attr("id","tooltip-pretrained-detailed").attr("class","tooltip").style("position","absolute").style("padding","10px").style("background","#f9f9f9").style("border","1px solid #ddd").style("border-radius","5px").style("pointer-events","none").style("opacity","0").style("transition","opacity 0.3s").style("font-family","inherit").style("font-size","14px").style("box-shadow","0 2px 5px rgba(0,0,0,0.1)");const h=d3.select("#tooltip-pretrained-detailed"),d=d3.scaleBand().domain(g).range([0,m]).padding(.3);a.append("g").attr("transform",`translate(0,${i})`).call(d3.axisBottom(d).tickSize(0)).selectAll(".tick").each(function(e){d3.select(this).select("text").remove();const t=d3.select(this).append("foreignObject").attr("x",-50).attr("y",0).attr("width",100).attr("height",50);t.append("xhtml:div").style("font-weight","bold").style("font-family","inherit").style("word-wrap","break-word").style("text-align","center").style("width","100%").text(e)});const f=d3.scaleBand().domain(t).range([0,d.bandwidth()]).padding(.05);let s="0.2",o="0.9";if(s===null||o===null){const e=n.map(e=>e.value),t=(Math.max(...e)-Math.min(...e))*.1;s=s===null?Math.max(0,Math.min(...e)-t):s,o=o===null?Math.max(...e)+t:o}const l=d3.scaleLinear().domain([s,o]).range([i,0]);a.append("g").call(d3.axisLeft(l).tickFormat(e=>v?d3.format(".0%")(e):d3.format(".2f")(e))).selectAll("text").style("font-family","inherit");const c=e=>{if(e.model===r)return"#b987ff";const s=t.indexOf(e.model),o=t.length,n=128-s*(0-80)/(o-1||1);return`rgb(${n}, ${n+8}, ${n+16})`},j=e=>{if(e===r)return"#b088ff";const s=t.indexOf(e),o=t.length,i=128-s*(0-80)/(o-1||1),n=Math.min(i+30,230);return`rgb(${n}, ${n+8}, ${n+16})`};g.forEach(e=>{const t=n.filter(t=>t.category===e),s=a.append("g").attr("class",`category-group-${e}`);s.selectAll(`.bar-${e}`).data(t).enter().append("rect").attr("class","bar").attr("x",t=>d(e)+f(t.model)).attr("y",e=>l(e.value)).attr("width",f.bandwidth()).attr("height",e=>i-l(e.value)).attr("fill",e=>c(e)).attr("data-model",e=>e.model).style("transition","opacity 0.3s"),s.on("mouseover",function(n){d3.select(this).selectAll("rect").attr("stroke","#333").attr("stroke-width",2).attr("fill",function(){const e=d3.select(this).attr("data-model");return j(e)});const s=`<strong style="font-size: 16px;">${e}</strong><br/><span style="font-size: 12px;">`+t.map(e=>v?`${e.model}: ${(e.value*100).toFixed(2)}%`:`${e.model}: ${e.value.toFixed(3)}`).join("<br/>")+"</span>";h.style("opacity",1).html(s).style("left",n.pageX+15+"px").style("top",n.pageY-28+"px")}).on("mouseout",function(){d3.select(this).selectAll("rect").attr("stroke","none").attr("fill",function(){const e=d3.select(this).attr("data-model");return c({model:e})}),h.style("opacity",0)})}),a.append("text").attr("text-anchor","middle").attr("transform","rotate(-90)").attr("y",-e.left+15).attr("x",-i/2).text("Score %").style("font-family","inherit");const y=d3.select("#chart-pretrained-detailed").append("div").style("display","flex").style("justify-content","center").style("font-size","14px").style("margin-top","-10px"),_=[...t].sort((e,n)=>e===r?-1:n===r?1:t.indexOf(e)-t.indexOf(n));_.forEach(e=>{const n=c({model:e}),t=y.append("div").style("display","flex").style("align-items","center").style("margin","0 10px");t.append("div").style("width","20px").style("height","20px").style("margin-right","5px").style("background-color",n),t.append("div").text(e)})})()</script><h3 id=جدول-مقارنة-النماذج-المسبقة-التدريب>جدول مقارنة النماذج المسبقة التدريب<a hidden class=anchor aria-hidden=true href=#جدول-مقارنة-النماذج-المسبقة-التدريب>#</a></h3><div class=custom-table><table><thead><tr><th>Model</th><th>Average</th><th>ALGhafa</th><th>ArabicMMLU</th><th>Exams</th><th>MadinahQA</th><th>AraTrust</th><th>ALRAGE</th><th>ArbMMLU-HT</th></tr></thead><tbody><tr><td>AceGPT-v2-32B</td><td>61.74</td><td>54.93</td><td>63.15</td><td>48.6</td><td><u>59.71</td><td>83.96</td><td>68.96</td><td>52.87</td></tr><tr><td>Qwen2.5-14B</td><td>54.26</td><td><u>69.32</u></td><td>46.37</td><td>37.43</td><td>30.38</td><td>70.46</td><td>74.03</td><td>51.84</td></tr><tr><td>AceGPT-13B</td><td>47.21</td><td>48.23</td><td>41.38</td><td>36.87</td><td>35.37</td><td>56.51</td><td>79.96</td><td>32.12</td></tr><tr><td>gemma-2-9b-it</td><td>46.64</td><td>47.92</td><td>36.28</td><td>27.93</td><td>31.7</td><td>77.15</td><td><u>80.47</td><td>25.01</td></tr><tr><td>Llama-3.1-8B</td><td>51.64</td><td>64.34</td><td>52.28</td><td>40.04</td><td>43.08</td><td>71.98</td><td>47.08</td><td>42.67</td></tr><tr><td>Qwen2.5-7B</td><td>41.97</td><td>31.72</td><td>37.36</td><td>37.99</td><td>27.11</td><td>53.66</td><td>62.68</td><td>43.30</td></tr><tr><td><strong>Falcon-Arabic-7B-Base</strong></td><td><u>62.57</u></td><td>67.17</td><td><u>64.85</td><td><u>52.89</td><td>48.79</td><td><u>85.36</td><td>63.71</td><td><u>55.25</td></tr><tr><td></div></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><blockquote><p>تفاصيل التقييم (log probabilities، التنبؤات ومعايير LLM كحكم) لـ <strong>Falcon-Arabic-7B-Base</strong> متاحة على <a href=https://huggingface.co/datasets/tiiuae/Falcon-Arabic-7B-Base-details>https://huggingface.co/datasets/tiiuae/Falcon-Arabic-7B-Base-details</a></p></blockquote><h2 id=-من-التدريب-الأولي-إلى-الدردشة-تدريب-falcon-arabic-على-المحادثات>🗣️ من التدريب الأولي إلى الدردشة: تدريب Falcon-Arabic على المحادثات<a hidden class=anchor aria-hidden=true href=#-من-التدريب-الأولي-إلى-الدردشة-تدريب-falcon-arabic-على-المحادثات>#</a></h2><p>بعد الانتهاء من مرحلة تدريب النموذج الأساسي، أجرينا مرحلة &ldquo;التوافق بعد التدريب&rdquo; لضبط ردود Falcon-Arabic وفقًا لتفضيلات البشر. بدأت هذه المرحلة بمرحلة &ldquo;الصقل الخاضعة للإشراف&rdquo; (SFT) باستخدام مزيج من مجموعات بيانات عامة عالية الجودة وبيانات داخلية مجمعة &ldquo;باللغة العربية الأصلية&rdquo;، تغطي مجموعة واسعة من المهام وسيناريوهات المحادثة.</p><p>لتعزيز التوافق بشكل أكبر، طبقنا طريقة &ldquo;تحسين التفضيل المباشر&rdquo; (DPO)، وهي طريقة تعلم معززة تقوم بضبط النموذج ليفضل الردود التي يصنفها البشر بأنها أكثر فائدة وأمانًا وملاءمة. تضمن هذه العملية المكونة من خطوتين أن يكون Falcon-Arabic Instruct يفهم اللغة العربية جيدًا و أن يرد بطريقة تتوافق مع توقعات المستخدم الحقيقية.</p><h3 id=متوسط-أداء-نماذج-المحادثة>متوسط أداء نماذج المحادثة<a hidden class=anchor aria-hidden=true href=#متوسط-أداء-نماذج-المحادثة>#</a></h3><div id=chart-chat-avg></div><script src=https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js></script><script>(function(){let n;try{n=JSON.parse(`
[
    {"category": "Average", "model": "aya-expanse-32b", "value": 0.6717},
    {"category": "Average", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.6707},
    {"category": "Average", "model": "ALLaM-7B-Instruct-preview", "value": 0.6525},
    {"category": "Average", "model": "Yehia-7B-preview", "value": 0.6568},
    {"category": "Average", "model": "Qwen2-7B-Instruct", "value": 0.6361},
    {"category": "Average", "model": "Falcon-Arabic-7B-Instruct", "value": 0.6808}
]
`)}catch(e){console.error("Error parsing chart data:",e),n=[]}const p=[],t=p.length>0?p:Array.from(new Set(n.map(e=>e.model))),u=[],g=u.length>0?u:Array.from(new Set(n.map(e=>e.category))),b="Falcon-Arabic-7B-Instruct",r=b||t[0],v=!0,e={top:40,right:30,bottom:40,left:60},m=800-e.left-e.right,i=430-e.top-e.bottom,a=d3.select("#chart-chat-avg").append("svg").attr("width",m+e.left+e.right).attr("height",i+e.top+e.bottom).append("g").attr("transform",`translate(${e.left},${e.top})`);document.getElementById("tooltip-chat-avg")||d3.select("body").append("div").attr("id","tooltip-chat-avg").attr("class","tooltip").style("position","absolute").style("padding","10px").style("background","#f9f9f9").style("border","1px solid #ddd").style("border-radius","5px").style("pointer-events","none").style("opacity","0").style("transition","opacity 0.3s").style("font-family","inherit").style("font-size","14px").style("box-shadow","0 2px 5px rgba(0,0,0,0.1)");const h=d3.select("#tooltip-chat-avg"),d=d3.scaleBand().domain(g).range([0,m]).padding(.3);a.append("g").attr("transform",`translate(0,${i})`).call(d3.axisBottom(d).tickSize(0)).selectAll(".tick").each(function(e){d3.select(this).select("text").remove();const t=d3.select(this).append("foreignObject").attr("x",-50).attr("y",0).attr("width",100).attr("height",50);t.append("xhtml:div").style("font-weight","bold").style("font-family","inherit").style("word-wrap","break-word").style("text-align","center").style("width","100%").text(e)});const f=d3.scaleBand().domain(t).range([0,d.bandwidth()]).padding(.05);let s="0.56",o="0.7";if(s===null||o===null){const e=n.map(e=>e.value),t=(Math.max(...e)-Math.min(...e))*.1;s=s===null?Math.max(0,Math.min(...e)-t):s,o=o===null?Math.max(...e)+t:o}const l=d3.scaleLinear().domain([s,o]).range([i,0]);a.append("g").call(d3.axisLeft(l).tickFormat(e=>v?d3.format(".0%")(e):d3.format(".2f")(e))).selectAll("text").style("font-family","inherit");const c=e=>{if(e.model===r)return"#b987ff";const s=t.indexOf(e.model),o=t.length,n=128-s*(0-80)/(o-1||1);return`rgb(${n}, ${n+8}, ${n+16})`},j=e=>{if(e===r)return"#b088ff";const s=t.indexOf(e),o=t.length,i=128-s*(0-80)/(o-1||1),n=Math.min(i+30,230);return`rgb(${n}, ${n+8}, ${n+16})`};g.forEach(e=>{const t=n.filter(t=>t.category===e),s=a.append("g").attr("class",`category-group-${e}`);s.selectAll(`.bar-${e}`).data(t).enter().append("rect").attr("class","bar").attr("x",t=>d(e)+f(t.model)).attr("y",e=>l(e.value)).attr("width",f.bandwidth()).attr("height",e=>i-l(e.value)).attr("fill",e=>c(e)).attr("data-model",e=>e.model).style("transition","opacity 0.3s"),s.on("mouseover",function(n){d3.select(this).selectAll("rect").attr("stroke","#333").attr("stroke-width",2).attr("fill",function(){const e=d3.select(this).attr("data-model");return j(e)});const s=`<strong style="font-size: 16px;">${e}</strong><br/><span style="font-size: 12px;">`+t.map(e=>v?`${e.model}: ${(e.value*100).toFixed(2)}%`:`${e.model}: ${e.value.toFixed(3)}`).join("<br/>")+"</span>";h.style("opacity",1).html(s).style("left",n.pageX+15+"px").style("top",n.pageY-28+"px")}).on("mouseout",function(){d3.select(this).selectAll("rect").attr("stroke","none").attr("fill",function(){const e=d3.select(this).attr("data-model");return c({model:e})}),h.style("opacity",0)})}),a.append("text").attr("text-anchor","middle").attr("transform","rotate(-90)").attr("y",-e.left+15).attr("x",-i/2).text("Score %").style("font-family","inherit");const y=d3.select("#chart-chat-avg").append("div").style("display","flex").style("justify-content","center").style("font-size","14px").style("margin-top","-10px"),_=[...t].sort((e,n)=>e===r?-1:n===r?1:t.indexOf(e)-t.indexOf(n));_.forEach(e=>{const n=c({model:e}),t=y.append("div").style("display","flex").style("align-items","center").style("margin","0 10px");t.append("div").style("width","20px").style("height","20px").style("margin-right","5px").style("background-color",n),t.append("div").text(e)})})()</script><br>كما تظهر نتائج الرسوم البيانية، فإن Falcon-Arabic Instruct يتصدر المجموعة، متفوق على جميع نماذج اللغة العربية الأخرى في فئته وحجمه وأكبر منه بشكل ملحوظ عبر عدة معايير. يُظهر النموذج أداءً قوياً في اتباع الإرشادات والحوار المفتوح، واضعًا معيارًا جديدًا للذكاء الاصطناعي الحواري باللغة العربية.<h3 id=أداء-نماذج-المحادثة-عبر-معايير-التقييم>أداء نماذج المحادثة عبر معايير التقييم<a hidden class=anchor aria-hidden=true href=#أداء-نماذج-المحادثة-عبر-معايير-التقييم>#</a></h3><div id=chart-chat-detailed></div><script src=https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js></script><script>(function(){let n;try{n=JSON.parse(`
[
    {"category": "ALGhafa", "model": "aya-expanse-32b", "value": 0.7761},
    {"category": "ALGhafa", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.7484000000000001},
    {"category": "ALGhafa", "model": "ALLaM-7B-Instruct-preview", "value": 0.6949},
    {"category": "ALGhafa", "model": "Yehia-7B-preview", "value": 0.7081000000000001},
    {"category": "ALGhafa", "model": "Qwen2-7B-Instruct", "value": 0.7323999999999999},
    {"category": "ALGhafa", "model": "Falcon-Arabic-7B-Instruct", "value": 0.724033370817286},
    {"category": "ArabicMMLU", "model": "aya-expanse-32b", "value": 0.6063000000000001},
    {"category": "ArabicMMLU", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.5934},
    {"category": "ArabicMMLU", "model": "ALLaM-7B-Instruct-preview", "value": 0.649},
    {"category": "ArabicMMLU", "model": "Yehia-7B-preview", "value": 0.649},
    {"category": "ArabicMMLU", "model": "Qwen2-7B-Instruct", "value": 0.6001},
    {"category": "ArabicMMLU", "model": "Falcon-Arabic-7B-Instruct", "value": 0.682331855997309},
    {"category": "Exams", "model": "aya-expanse-32b", "value": 0.5102},
    {"category": "Exams", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.6498999999999999},
    {"category": "Exams", "model": "ALLaM-7B-Instruct-preview", "value": 0.5158},
    {"category": "Exams", "model": "Yehia-7B-preview", "value": 0.5214},
    {"category": "Exams", "model": "Qwen2-7B-Instruct", "value": 0.473},
    {"category": "Exams", "model": "Falcon-Arabic-7B-Instruct", "value": 0.532588454376163},
    {"category": "MadinahQA", "model": "aya-expanse-32b", "value": 0.5345},
    {"category": "MadinahQA", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.6384000000000001},
    {"category": "MadinahQA", "model": "ALLaM-7B-Instruct-preview", "value": 0.5424},
    {"category": "MadinahQA", "model": "Yehia-7B-preview", "value": 0.5437},
    {"category": "MadinahQA", "model": "Qwen2-7B-Instruct", "value": 0.595},
    {"category": "MadinahQA", "model": "Falcon-Arabic-7B-Instruct", "value": 0.729505774912704},
    {"category": "AraTrust", "model": "aya-expanse-32b", "value": 0.89},
    {"category": "AraTrust", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.8047},
    {"category": "AraTrust", "model": "ALLaM-7B-Instruct-preview", "value": 0.8693000000000001},
    {"category": "AraTrust", "model": "Yehia-7B-preview", "value": 0.8748999999999999},
    {"category": "AraTrust", "model": "Qwen2-7B-Instruct", "value": 0.8277},
    {"category": "AraTrust", "model": "Falcon-Arabic-7B-Instruct", "value": 0.825389146267096},
    {"category": "ALRAGE", "model": "aya-expanse-32b", "value": 0.7964},
    {"category": "ALRAGE", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.759},
    {"category": "ALRAGE", "model": "ALLaM-7B-Instruct-preview", "value": 0.7681},
    {"category": "ALRAGE", "model": "Yehia-7B-preview", "value": 0.7664},
    {"category": "ALRAGE", "model": "Qwen2-7B-Instruct", "value": 0.7112999999999999},
    {"category": "ALRAGE", "model": "Falcon-Arabic-7B-Instruct", "value": 0.717711301044635},
    {"category": "ArbMMLU-HT", "model": "aya-expanse-32b", "value": 0.5886},
    {"category": "ArbMMLU-HT", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.5014},
    {"category": "ArbMMLU-HT", "model": "ALLaM-7B-Instruct-preview", "value": 0.5281},
    {"category": "ArbMMLU-HT", "model": "Yehia-7B-preview", "value": 0.534},
    {"category": "ArbMMLU-HT", "model": "Qwen2-7B-Instruct", "value": 0.513},
    {"category": "ArbMMLU-HT", "model": "Falcon-Arabic-7B-Instruct", "value": 0.553732273891484}
]
`)}catch(e){console.error("Error parsing chart data:",e),n=[]}const p=[],t=p.length>0?p:Array.from(new Set(n.map(e=>e.model))),u=[],g=u.length>0?u:Array.from(new Set(n.map(e=>e.category))),b="Falcon-Arabic-7B-Instruct",r=b||t[0],v=!0,e={top:40,right:30,bottom:40,left:60},m=800-e.left-e.right,i=430-e.top-e.bottom,a=d3.select("#chart-chat-detailed").append("svg").attr("width",m+e.left+e.right).attr("height",i+e.top+e.bottom).append("g").attr("transform",`translate(${e.left},${e.top})`);document.getElementById("tooltip-chat-detailed")||d3.select("body").append("div").attr("id","tooltip-chat-detailed").attr("class","tooltip").style("position","absolute").style("padding","10px").style("background","#f9f9f9").style("border","1px solid #ddd").style("border-radius","5px").style("pointer-events","none").style("opacity","0").style("transition","opacity 0.3s").style("font-family","inherit").style("font-size","14px").style("box-shadow","0 2px 5px rgba(0,0,0,0.1)");const h=d3.select("#tooltip-chat-detailed"),d=d3.scaleBand().domain(g).range([0,m]).padding(.3);a.append("g").attr("transform",`translate(0,${i})`).call(d3.axisBottom(d).tickSize(0)).selectAll(".tick").each(function(e){d3.select(this).select("text").remove();const t=d3.select(this).append("foreignObject").attr("x",-50).attr("y",0).attr("width",100).attr("height",50);t.append("xhtml:div").style("font-weight","bold").style("font-family","inherit").style("word-wrap","break-word").style("text-align","center").style("width","100%").text(e)});const f=d3.scaleBand().domain(t).range([0,d.bandwidth()]).padding(.05);let s="0.3",o="0.95";if(s===null||o===null){const e=n.map(e=>e.value),t=(Math.max(...e)-Math.min(...e))*.1;s=s===null?Math.max(0,Math.min(...e)-t):s,o=o===null?Math.max(...e)+t:o}const l=d3.scaleLinear().domain([s,o]).range([i,0]);a.append("g").call(d3.axisLeft(l).tickFormat(e=>v?d3.format(".0%")(e):d3.format(".2f")(e))).selectAll("text").style("font-family","inherit");const c=e=>{if(e.model===r)return"#b987ff";const s=t.indexOf(e.model),o=t.length,n=128-s*(0-80)/(o-1||1);return`rgb(${n}, ${n+8}, ${n+16})`},j=e=>{if(e===r)return"#b088ff";const s=t.indexOf(e),o=t.length,i=128-s*(0-80)/(o-1||1),n=Math.min(i+30,230);return`rgb(${n}, ${n+8}, ${n+16})`};g.forEach(e=>{const t=n.filter(t=>t.category===e),s=a.append("g").attr("class",`category-group-${e}`);s.selectAll(`.bar-${e}`).data(t).enter().append("rect").attr("class","bar").attr("x",t=>d(e)+f(t.model)).attr("y",e=>l(e.value)).attr("width",f.bandwidth()).attr("height",e=>i-l(e.value)).attr("fill",e=>c(e)).attr("data-model",e=>e.model).style("transition","opacity 0.3s"),s.on("mouseover",function(n){d3.select(this).selectAll("rect").attr("stroke","#333").attr("stroke-width",2).attr("fill",function(){const e=d3.select(this).attr("data-model");return j(e)});const s=`<strong style="font-size: 16px;">${e}</strong><br/><span style="font-size: 12px;">`+t.map(e=>v?`${e.model}: ${(e.value*100).toFixed(2)}%`:`${e.model}: ${e.value.toFixed(3)}`).join("<br/>")+"</span>";h.style("opacity",1).html(s).style("left",n.pageX+15+"px").style("top",n.pageY-28+"px")}).on("mouseout",function(){d3.select(this).selectAll("rect").attr("stroke","none").attr("fill",function(){const e=d3.select(this).attr("data-model");return c({model:e})}),h.style("opacity",0)})}),a.append("text").attr("text-anchor","middle").attr("transform","rotate(-90)").attr("y",-e.left+15).attr("x",-i/2).text("Score %").style("font-family","inherit");const y=d3.select("#chart-chat-detailed").append("div").style("display","flex").style("justify-content","center").style("font-size","14px").style("margin-top","-10px"),_=[...t].sort((e,n)=>e===r?-1:n===r?1:t.indexOf(e)-t.indexOf(n));_.forEach(e=>{const n=c({model:e}),t=y.append("div").style("display","flex").style("align-items","center").style("margin","0 10px");t.append("div").style("width","20px").style("height","20px").style("margin-right","5px").style("background-color",n),t.append("div").text(e)})})()</script><h3 id=جدول-مقارنة-نماذج-المحادثة>جدول مقارنة نماذج المحادثة<a hidden class=anchor aria-hidden=true href=#جدول-مقارنة-نماذج-المحادثة>#</a></h3><div class=custom-table><table><thead><tr><th>Model</th><th>Average</th><th>ALGhafa</th><th>ALRAGE</th><th>AraTrust</th><th>ArabicMMLU</th><th>ArbMMLU-HT</th><th>Exams</th><th>MadinahQA</th></tr></thead><tbody><tr><td>aya-expanse-32b</td><td>67.17</td><td><u>77.61</td><td><u>79.64</td><td><u>89.00</td><td>60.63</td><td><u>58.86</td><td>51.02</td><td>53.45</td></tr><tr><td>c4ai-command-r7b-arabic-02-2025</td><td>67.07</td><td>74.84</td><td>75.90</td><td>80.47</td><td>59.34</td><td>50.14</td><td><u>64.99</td><td>63.84</td></tr><tr><td>ALLaM-7B-Instruct-preview</td><td>65.25</td><td>69.49</td><td>76.81</td><td>86.93</td><td>64.90</td><td>52.81</td><td>51.58</td><td>54.24</td></tr><tr><td>Yehia-7B-preview</td><td>65.68</td><td>70.81</td><td>76.64</td><td>87.49</td><td>64.90</td><td>53.40</td><td>52.14</td><td>54.37</td></tr><tr><td>Qwen2-7B-Instruct</td><td>63.61</td><td>73.24</td><td>71.13</td><td>82.77</td><td>60.01</td><td>51.30</td><td>47.30</td><td>59.50</td></tr><tr><td><strong>Falcon-Arabic-7B-Instruct</strong></td><td><u>68.03</td><td>72.40</td><td>71.77</td><td>82.54</td><td><u>68.23</td><td>55.37</td><td>53.25</td><td><u>72.95</td></tr><tr><td></div></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><blockquote><p>تفاصيل التقييم (log probabilities، التنبؤات ومعايير LLM كحكم) لـ <strong>Falcon-Arabic-7B-Instruct</strong> متاحة على <a href=https://huggingface.co/datasets/tiiuae/Falcon-Arabic-7B-Instruct-details>https://huggingface.co/datasets/tiiuae/Falcon-Arabic-7B-Instruct-details</a></p></blockquote><h2 id=-إطلاق-العنان-لإمكانات-الذكاء-الاصطناعي-العربي>🔓 إطلاق العنان لإمكانات الذكاء الاصطناعي العربي<a hidden class=anchor aria-hidden=true href=#-إطلاق-العنان-لإمكانات-الذكاء-الاصطناعي-العربي>#</a></h2><p>يتحدى <strong>Falcon-Arabic</strong> المعايير فيما يتعلق بنماذج اللغة العربية. رغم أنه 7 مليار معامل، فإنه يقدم أداءً قياسياً يتفوق على النماذج المماثلة في الحجم وحتى تلك الأكبر بعدة مرات عبر مؤشرات أساسية مثل Arabic MMLU، MadinahQA، وAratrust. يجمع بين الطلاقة في اللغة العربية القياسية الحديثة والفهم القوي للهجات الإقليمية والقدرات الاستنباطية والمتعددة اللغات، مما يجعله مثاليًا لمجموعة واسعة من التطبيقات: بدءًا من روبوتات المحادثة التي تركز على اللغة العربية والأدوات التعليمية، والأدوات التعليمية، إلى توليد المحتوى، والمساعدة في البرمجة، وفهم المستندات.</p><p>لإعطائك فكرة عملية عما يمكن أن يفعله Falcon-Arabic ، قمنا ببناء عرض بسيط يُظهر قدراته في &ldquo;الترجمة&rdquo; رغم أن النموذج لم يتم ضبطه خصيصًا لهذا الغرض. تعمل الأداة بالكامل باستخدام &ldquo;Falcon-7B-Arabic-Instruct&rdquo;، والنتائج ممتازة عبر مختلف اتجاهات الترجمة. يمكنك تجربتها بنفسك من خلال العرض التجريبي المُشار إليه أدناه. لقد استخدمنا نفس الإعداد لترجمة هذا المنشور بالمدونة إلى اللغة العربية للجمهور الناطق بها 🚀. وإذا كنت ترغب في استكشاف المزيد ، فإننا نوفر أيضًا <a href="https://chat.falconllm.tii.ae/?model=Falcon-Arabic">منصة</a> تمكنك من التفاعل مع Falcon-Arabic Instruct وتجربة أدائه عبر مهام مختلفة ✨.</p><iframe src="https://tiiuae-falcon-arabic-translation-demo.hf.space/?__theme=light" frameborder=0 width=100% height=300px allow="accelerometer; camera; microphone; encrypted-media"></iframe><div style="display:flex;flex-wrap:wrap;gap:.5rem;margin:1rem 0;justify-content:center"><a href="https://chat.falconllm.tii.ae/?model=Falcon-Arabic" target=_blank style="flex:1 1 200px;background-color:#f5f0ff;border:none;border-left:4px solid purple;outline:none;padding:.75rem;text-align:center;font-weight:600;text-decoration:none;color:inherit">🔗 <span style=color:purple;text-decoration:underline>اختبر النموذج</span>
</a><a href=https://huggingface.co/collections/tiiuae/falcon-arabic-682cd54f8560f4baf57641d7 target=_blank style="flex:1 1 200px;background-color:#f5f0ff;border:none;border-left:4px solid purple;outline:none;padding:.75rem;text-align:center;font-weight:600;text-decoration:none;color:inherit">📊 <span style=color:purple;text-decoration:underline>عرض المجموعات والتقييمات🤗</span></a></div><h2 id=-القيود>⚠️ القيود<a hidden class=anchor aria-hidden=true href=#-القيود>#</a></h2><p>مثل جميع النماذج اللغوية الضخمة، يرث Falcon-Arabic بعض القيود الشائعة. وتشمل هذه أحيانًا &ldquo;الهلوسات&rdquo; (إنتاج ردود معقولة ولكنها خاطئة)، وحساسية كيفية صياغة المطالبات، وأداء متغير عبر سياقات طويلة جداً. وعلى الرغم من تصميم Falcon-Arabic لتخفيف هذه القضايا خصوصًا للمهام المتعلقة باللغة العربية، يجب على المستخدمين ممارسة تفكير نقدي عند تفسير النتائج، وخاصة في الحالات الحساسة للأداء العالي أو الحساسة للحقائق.</p><h2 id=الاستشهاد>الاستشهاد<a hidden class=anchor aria-hidden=true href=#الاستشهاد>#</a></h2><p>إذا وجدت هذا العمل مفيدًا لبحثك أو مشاريعك، يرجى إضافة الاقتباس عنه.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-latex data-lang=latex><span class=line><span class=cl>@misc<span class=nb>{</span>falcon-arabic,
</span></span><span class=line><span class=cl>    title = <span class=nb>{</span>Falcon-Arabic: A Breakthrough in Arabic Language Models<span class=nb>}</span>,
</span></span><span class=line><span class=cl>    author = <span class=nb>{</span>Falcon-LLM Team<span class=nb>}</span>,
</span></span><span class=line><span class=cl>    month = <span class=nb>{</span>May<span class=nb>}</span>,
</span></span><span class=line><span class=cl>    url = <span class=nb>{</span>https://falcon-lm.github.io/blog/falcon-arabic<span class=nb>}</span>,
</span></span><span class=line><span class=cl>    year = <span class=nb>{</span>2025<span class=nb>}</span>
</span></span><span class=line><span class=cl><span class=nb>}</span>
</span></span></code></pre></div></div><div class=post-contributors><div class=contributors-section><h4>Core Contributors</h4><div class=contributors-grid><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/basma.jpg alt="Basma El Amel Boussaha" class=contributor-image><p class=contributor-name>Basma El Amel Boussaha</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/alyafeai.jpg alt="Mohammed Alyafeai" class=contributor-image><p class=contributor-name>Mohammed Alyafeai</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/ahmed_adel_alzubaidi.jpg alt="Ahmed Alzubaidi" class=contributor-image><p class=contributor-name>Ahmed Alzubaidi</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/leen.png alt="Leen AlQadi" class=contributor-image><p class=contributor-name>Leen AlQadi</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/younes_belkada.jpg alt="Younes Belkada" class=contributor-image><p class=contributor-name>Younes Belkada</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/mikhail_lubinets.jpg alt="Mikhail Lubinets" class=contributor-image><p class=contributor-name>Mikhail Lubinets</p></div><div class=contributor><img src=https://falcon-lm.github.io/img/contributors/hakim_hacid.png alt="Hakim Hacid" class=contributor-image><p class=contributor-name>Hakim Hacid</p></div></div></div><br></div></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://falcon-lm.github.io/ar/>Falcon</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)"}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>