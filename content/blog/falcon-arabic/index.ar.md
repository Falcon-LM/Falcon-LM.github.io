---
# title: "Falcon-Arabic: قفزة نوعية في نماذج اللغة العربية"
title: "Falcon-Arabic: نقلة نوعية في نماذج اللغة العربية"
date: 2025-05-17T12:00:00Z
weight: 1
# aliases: ["/first"]
# tags: ["Research"]
# draft: true
# comments: false
# description: "Desc Text."
# disable_share: false
# hide_meta: false
# hide_summary: false # to hide summary in list
# hide_footer: false
math: true
# search_hidden: false # to hide from search page
show_reading_time: true
show_bread_crumbs: true
show_post_nav_links: false # the prev/next after the content
show_code_copy_buttons: true
show_word_count: true
#use_hugo_toc: true
#show_toc: true
# toc_open: true # default expand all
cover:
    image: "cover_1.png"
    # can also paste direct link from external site
    # ex. https://i.ibb.co/K0HVPBd/paper-mod-profilemode.png
    alt: "<alt falcon 3>"
    caption: ""
    relative: true # To use relative path for cover image, used in hugo Page-bundles
    responsive_images: true
header:
#   background: "" # background css value
    background_image: "/img/falcon_arabic_cover.png"
    gradient: true
    blur: true
contributors:
    core:
        - name: Basma El Amel Boussaha
          image: img/contributors/basma.jpg
        - name: Mohammed Alyafeai
          image: img/contributors/alyafeai.jpg
        - name: Ahmed Alzubaidi
          image: img/contributors/ahmed_alzubaidi.jpg
        - name: Leen AlQadi
          image: img/contributors/leen.png
        - name: Younes Belkada
          image: img/contributors/younes_belkada.jpg
        - name: Mikhail Lubinets
          image: img/contributors/mikhail_lubinets.jpg
        - name: Hakim Hacid
          image: img/contributors/hakim.png
---
<div dir="rtl" class="translation-notice">
  <p>
    تنبيه: تم ترجمة هذا المقال بواسطة <span class="llm-name">Falcon-Arabic</span> 🦅
  </p>
</div>

<div dir="rtl">

نحن متحمسون للإعلان عن Falcon-Arabic، نموذج لغوي كبير يحتوي على 7 مليار معامل ويعد معيارًا جديدًا لمعالجة اللغة العربية طبيعيًا. مبني على بنية Falcon 3 المتعددة اللغات، يدعم Falcon-Arabic اللغة العربية واللغة الإنجليزية وعدد من اللغات الأخرى. يتفوق في المعرفة العامة والقواعد النحوية العربية والاستدلال الرياضي وحل المشاكل المعقدة وفهم تنوع اللهجات العربية. 

يدعم Falcon-Arabic  طول سياق بمقدار 32 ألف رمز  (token)، مما يمكنه من التعامل مع الوثائق الطويلة، وتمكين تطبيقات متقدمة مثل توليد المحتوى المدعوم بالاسترجاع (RAG)، وإنشاء محتوى عميق، والمهام المعرفية.

يقوم Falcon-Arabic بإعادة تعريف حدود ما يمكن تحقيقه فيما يتعلق بالنماذج اللغوية العربية. فهو يفوق بكثير النماذج الأخرى ذات الحجم المماثل وحتى تلك الأكبر بأربعة أضعاف، سواء كانت نماذج عربية الأصل أو نماذج تم تكييفها من لغات أخرى. وهذا يجعل Falcon-Arabic ليس فقط نموذجاً رائداً من حيث الأداء، بل أيضاً حلاً فريداً وفعالاً ومتاحاً للباحثين والمطورين المهتمين باللغة العربية.

<!-- ## 🚀 نقدم Falcon-Arabic: تقدم LLM للعالم الناطق بالعربية -->
## 🚀 نقدم Falcon-Arabic: نحو تطوير نماذج لغوية كبيرة للعالم الناطق بالعربية


<!--
في السنوات الأخيرة، قامت النماذج اللغوية الكبيرة بتحويل الذكاء الاصطناعي، وتمكنت من تشغيل الأدوات للترجمة وإنشاء المحتوى والمساعدة الافتراضية وغيرها الكثير. ولكن معظم هذا التقدم ركز على اللغات الممثلة بشدة مثل الإنجليزية، تاركاً اللغات مثل العربية دون تمثيل كافٍ. تشكل اللغة العربية تحديات فريدة فهي غنية بالنحو، ثنائية اللهجة (تشمل كلاً من اللغة العربية القياسية الحديثة (MSA) واللهجات الإقليمية المتنوعة)، وتستخدم من قبل سكان ثقافيين متنوعين للغاية. وتطوير نماذج اللغة العربية القوية ضروري لضمان تضمين المجتمعات الناطقة بالعربية بالكامل في ثورة الذكاء الاصطناعي. -->

في السنوات الأخيرة، قامت النماذج اللغوية الكبيرة بإحداث قفزة نوعية في الذكاء الاصطناعي، وتمكنت من توفير أدوات للترجمة وإنشاء المحتوى والمساعدة الافتراضية وغيرها الكثير. ولكن معظم هذا التقدم ركز على لغات معينة مثل الإنجليزية، تاركاً لغات اخرى، مثل العربية، دون تمثيل كافٍ. تشكل اللغة العربية تحديات فريدة فهي غنية بالنحو، ثنائية اللهجة (تشمل كلاً من اللغة العربية المعاصرة واللهجات المحلية المتنوعة)، وتستخدم من قبل سكان متنوعين ثقافيا. إن تطوير نماذج اللغة العربية متقدمة المستوى  يعد أمراً ضرورياً لضمان حصول المجتمعات الناطقة بالعربية على المزايا التي نشهدها مع ثورة الذكاء الاصطناعي.

بناءً على هذه الرؤية، نعلن لكم عن **Falcon-Arabic**، نسخة متخصصة من [عائلة نماذج **Falcon 3**](https://huggingface.co/collections/tiiuae/falcon3-67605ae03578be86e4e87026)، المطورة من قبل [**معهد الابتكار التكنولوجي (TII)**](https://www.tii.ae/) في دولة الإمارات العربية المتحدة. اكتسبت عائلة Falcon شهرة عالمية بفضل قدرتها القوية على التعامل مع اللغات المتعددة ونهجها المفتوح المصدر. يبني Falcon-Arabic على هذا الإرث، حيث يجلب قدرات متقدمة في فهم اللغة العربية وتوليدها. ومن خلال تدريب النموذج للتعامل مع اللغة العربية المعاصرة وبعض اللهجات المحورية، يملأ Falcon-Arabic فجوة حرجة في تكنولوجيا اللغة، مما يمكّن ذكاءً عربيًا أكثر طبيعية وذكيًا وشاملًا عبر الخليج والشرق الأوسط وشمال أفريقيا.


{{< figure src="radar.png" alt="Pretrained models performance" >}}
<!-- <a id="pull-figures"></a>
<div style="display: flex; justify-content: center; flex-wrap: wrap; gap: 20px;">
  <img src="{{ .RelPermalink }}radar.png" alt="Pretrained models performance" style="width: 100%; max-width: 800px; height: auto;">
</div> -->

## 🧪 Falcon-Arabic قد حطّ رحاله  - إليكم وصفة التدريب

بدأ بناء Falcon-Arabic بقرار استراتيجي: بدلاً من تدريب نموذج من الصفر، اخترنا تكييف أساس متعدد اللغات قوي. وفي مشهد نماذج اللغة العربية، هناك ثلاث طرق رئيسية: التدريب من الصفر (على سبيل المثال، Jais-native)، تكييف النماذج متعددة اللغات (مثل Allam أو Fanar)، أو استخدام النماذج التي تدعم اللغة العربية بشكل أصلي بجانب لغات أخرى (مثل Qwen أو LLaMA). عند النظر إلى لوحة المتصدرين الخاصة بـ Open Arabic LLM (https://huggingface.co/spaces/OALL/Open-Arabic-LLM-Leaderboard)، أصبح من الواضح أن النماذج المتكيفة والمتعددة اللغات تفوقت باستمرار على غيرها من حيث الكفاءة والقدرة. للاستفادة من هذا الزخم، قمنا باختيار Falcon 3-7B، وهو نموذج يحقق توازن عملي بين الأداء وكفاءة الموارد ضمن عائلة Falcon 3 المطورة من قبل معهد الابتكار التكنولوجي (TII).

كان التحدي الأساسي هو تكييف Falcon 3-7B، الذي يفتقر أصلاً لدعم اللغة العربية على مستوى المحلل اللغوي والكوديبات. لقد عالجنا ذلك بإضافة "32,000 كلمة عربية محددة" إلى قاموس المحلل اللغوي، وتطبيق إستراتيجية تهيئة جديدة للكودات تعتمد على "تشابه النصوص". تعمل هذه التقنية على تعيين الكلمات العربية الجديدة إلى رموز دلالية متعلقة بالكودات الموجودة بالفعل، مما يسمح للنموذج باكتساب المعرفة السابقة وتسريع التعلم خاصة حول المشاعر والمفاهيم المجردة وأنماط الاستدلال. أعطى هذا Falcon-Arabic بداية جيدة لفهم وإنتاج نص عالي الجودة باللغة العربية.

مع وجود المحلل اللغوي والرموز الدلالية في مكانها الصحيح، بدأنا بتدريب مستمر باستخدام مجموعات بيانات عالية الجودة بنسبة 100٪ أصلية باللغة العربية، وتجنبنا استخدام المحتوى المترجم آلياً لتقليل الانحياز الثقافي وحفظ الأصالة اللغوية. اتبع التدريب منهجاً متعدد المراحل: ركزت المراحل المبكرة على "المعرفة العامة ومحتوى غني باللهجة العربية" لتثبيت النموذج وتعزيز القدرات المنطقية، بينما ركزت المراحل اللاحقة على "الرياضيات والبرمجة والاستدلال". كانت النتيجة نموذج يتحدث العربية بطلاقة عبر اللهجات ويحتفظ بقوة Falcon متعددة اللغات وقدرات الاستدلال، متخطياً حدود الذكاء الاصطناعي الأولى باللغة العربية.


### متوسط أداء النماذج المسبقة التدريب
{{< barplot_vertical id="pretrained-avg" highlight="Falcon-Arabic-7B-Base" ymin="0.40" ymax="0.7" ylabel="Score %" >}}
[
    {"category": "Average", "model": "AceGPT-v2-32B", "value": 0.6174},
    {"category": "Average", "model": "Qwen2.5-14B", "value": 0.5426},
    {"category": "Average", "model": "AceGPT-13B", "value": 0.4721},
    {"category": "Average", "model": "gemma-2-9b-it", "value": 0.4664},
    {"category": "Average", "model": "Llama-3.1-8B", "value": 0.5164},
    {"category": "Average", "model": "Qwen2.5-7B", "value": 0.41969999999999996},
    {"category": "Average", "model": "Falcon-Arabic-7B-Base", "value": 0.6257}
]
{{< /barplot_vertical >}}

<!-- ## 📊 Falcon-Arabic: رفع معايير نماذج اللغة العربية -->
## 📊 Falcon-Arabic: الارتقاء بمعايير النماذج اللغوية العربية الكبيرة

قمنا بتقييم Falcon-Arabic على OALL v2، وهو المعيار الرائد لنماذج اللغة العربية. يتضمن ست مهام متعددة الخيارات مثل MMLU العربي الأصلي والمترجم، والامتحانات العربية، وغافة، ومدينة QA، وأرتوث، وواحد لتوليد المعايير، أرج. تفوق Falcon-Arabic على جميع نماذج اللغة العربية الحالية في نطاق حجمها ويتجاوز حتى النماذج الأربعة مرات أكبر. يقود في المعايير الرئيسية مثل MMLU العربي، والامتحانات، ومدينة QA، وأرتوث، واضعة معيارًا جديدًا لنماذج اللغة العربية الأولية.


{{< barplot_vertical id="pretrained-detailed" highlight="Falcon-Arabic-7B-Base" ymin="0.2" ymax="0.9" ylabel="Score %" >}}
[
    {"category": "ALGhafa", "model": "AceGPT-v2-32B", "value": 0.5493},
    {"category": "ALGhafa", "model": "Qwen2.5-14B", "value": 0.6931999999999999},
    {"category": "ALGhafa", "model": "AceGPT-13B", "value": 0.48229999999999995},
    {"category": "ALGhafa", "model": "gemma-2-9b-it", "value": 0.4792},
    {"category": "ALGhafa", "model": "Llama-3.1-8B", "value": 0.6434000000000001},
    {"category": "ALGhafa", "model": "Qwen2.5-7B", "value": 0.3172},
    {"category": "ALGhafa", "model": "Falcon-Arabic-7B-Base", "value": 0.67},
    {"category": "ArabicMMLU", "model": "AceGPT-v2-32B", "value": 0.6315},
    {"category": "ArabicMMLU", "model": "Qwen2.5-14B", "value": 0.4637},
    {"category": "ArabicMMLU", "model": "AceGPT-13B", "value": 0.4138},
    {"category": "ArabicMMLU", "model": "gemma-2-9b-it", "value": 0.3628},
    {"category": "ArabicMMLU", "model": "Llama-3.1-8B", "value": 0.5228},
    {"category": "ArabicMMLU", "model": "Qwen2.5-7B", "value": 0.3736},
    {"category": "ArabicMMLU", "model": "Falcon-Arabic-7B-Base", "value": 0.65},
    {"category": "Exams", "model": "AceGPT-v2-32B", "value": 0.486},
    {"category": "Exams", "model": "Qwen2.5-14B", "value": 0.3743},
    {"category": "Exams", "model": "AceGPT-13B", "value": 0.36869999999999997},
    {"category": "Exams", "model": "gemma-2-9b-it", "value": 0.2793},
    {"category": "Exams", "model": "Llama-3.1-8B", "value": 0.4004},
    {"category": "Exams", "model": "Qwen2.5-7B", "value": 0.3799},
    {"category": "Exams", "model": "Falcon-Arabic-7B-Base", "value": 0.53},
    {"category": "MadinahQA", "model": "AceGPT-v2-32B", "value": 0.5971},
    {"category": "MadinahQA", "model": "Qwen2.5-14B", "value": 0.3038},
    {"category": "MadinahQA", "model": "AceGPT-13B", "value": 0.35369999999999996},
    {"category": "MadinahQA", "model": "gemma-2-9b-it", "value": 0.317},
    {"category": "MadinahQA", "model": "Llama-3.1-8B", "value": 0.43079999999999996},
    {"category": "MadinahQA", "model": "Qwen2.5-7B", "value": 0.2711},
    {"category": "MadinahQA", "model": "Falcon-Arabic-7B-Base", "value": 0.49},
    {"category": "AraTrust", "model": "AceGPT-v2-32B", "value": 0.8396},
    {"category": "AraTrust", "model": "Qwen2.5-14B", "value": 0.7045999999999999},
    {"category": "AraTrust", "model": "AceGPT-13B", "value": 0.5650999999999999},
    {"category": "AraTrust", "model": "gemma-2-9b-it", "value": 0.7715},
    {"category": "AraTrust", "model": "Llama-3.1-8B", "value": 0.7198},
    {"category": "AraTrust", "model": "Qwen2.5-7B", "value": 0.5366},
    {"category": "AraTrust", "model": "Falcon-Arabic-7B-Base", "value": 0.85},
    {"category": "ALRAGE", "model": "AceGPT-v2-32B", "value": 0.6896},
    {"category": "ALRAGE", "model": "Qwen2.5-14B", "value": 0.7403},
    {"category": "ALRAGE", "model": "AceGPT-13B", "value": 0.7996},
    {"category": "ALRAGE", "model": "gemma-2-9b-it", "value": 0.8047},
    {"category": "ALRAGE", "model": "Llama-3.1-8B", "value": 0.4708},
    {"category": "ALRAGE", "model": "Qwen2.5-7B", "value": 0.6268},
    {"category": "ALRAGE", "model": "Falcon-Arabic-7B-Base", "value": 0.64},
    {"category": "ArbMMLU-HT", "model": "AceGPT-v2-32B", "value": 0.5287},
    {"category": "ArbMMLU-HT", "model": "Qwen2.5-14B", "value": 0.5184000000000001},
    {"category": "ArbMMLU-HT", "model": "AceGPT-13B", "value": 0.3212},
    {"category": "ArbMMLU-HT", "model": "gemma-2-9b-it", "value": 0.2501},
    {"category": "ArbMMLU-HT", "model": "Llama-3.1-8B", "value": 0.4267},
    {"category": "ArbMMLU-HT", "model": "Qwen2.5-7B", "value": 0.433},
    {"category": "ArbMMLU-HT", "model": "Falcon-Arabic-7B-Base", "value": 0.55}
]
{{< /barplot_vertical >}}


### جدول مقارنة النماذج المسبقة التدريب

<!-- <details>
<summary class="bold"> Detailed results: </summary> -->

{{< rawhtml >}}<div class="custom-table"> {{< /rawhtml >}}
| Model   | Average    | ALGhafa | ArabicMMLU | Exams | MadinahQA | AraTrust | ALRAGE | ArbMMLU-HT |
|---------|---------|------------|-------|-----------|----------|--------|------------|--------|
| AceGPT-v2-32B | 61.74 | 54.93  | 63.15     | 48.6| <u>59.71   | 83.96   | 68.96 | 52.87    |
| Qwen2.5-14B | 54.26 | <u>69.32</u>  | 46.37     | 37.43| 30.38    | 70.46   | 74.03 | 51.84     |
| AceGPT-13B | 47.21 | 48.23  | 41.38     | 36.87| 35.37    | 56.51   | 79.96 | 32.12     |
| gemma-2-9b-it | 46.64 | 47.92  | 36.28     | 27.93| 31.7    | 77.15   | <u>80.47 | 25.01     |
| Llama-3.1-8B | 51.64 | 64.34  | 52.28     | 40.04| 43.08    | 71.98   | 47.08 | 42.67     |
| Qwen2.5-7B | 41.97 | 31.72  | 37.36     | 37.99| 27.11    | 53.66   | 62.68 | 43.30     |
| **Falcon-Arabic-7B-Base** | <u>62.57</u> | 67.17  | <u>64.85     | <u>52.89| 48.79    | <u>85.36   | 63.71 | <u>55.25     |
{{< rawhtml >}}</div> {{< /rawhtml >}}

<!-- </details> -->

## 🗣️ من التدريب الأولي إلى الدردشة: تدريب Falcon-Arabic على المحادثات


بعد الانتهاء من مرحلة تدريب النموذج الأساسي، أجرينا مرحلة "التوافق بعد التدريب" لضبط ردود Falcon-Arabic وفقًا لتفضيلات البشر. بدأت هذه المرحلة بمرحلة "الصقل الخاضعة للإشراف" (SFT)  باستخدام مزيج من مجموعات بيانات عامة عالية الجودة وبيانات داخلية مجمعة "باللغة العربية الأصلية"، تغطي مجموعة من المهام وسيناريوهات المحادثة.

لتعزيز التوافق بشكل أكبر، طبقنا طريقة "تحسين التفضيل المباشر" (DPO)، وهي طريقة تعلم تعزيز تقوم بضبط النموذج ليفضل الردود التي يصنفها البشر بأنها أكثر فائدة وأمانًا وملاءمة. تضمن هذه العملية المكونة من خطوتين أن يكون Falcon-Arabic Instruct يفهم اللغة العربية جيدًا ولكنه يرد بطريقة تتوافق مع توقعات المستخدم الحقيقية.

### متوسط أداء نماذج المحادثة

{{< barplot_vertical id="chat-avg" highlight="Falcon-Arabic-7B-Instruct" ymin="0.56" ymax="0.7" ylabel="Score %" >}}
[
    {"category": "Average", "model": "aya-expanse-32b", "value": 0.6717},
    {"category": "Average", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.6707},
    {"category": "Average", "model": "ALLaM-7B-Instruct-preview", "value": 0.6525},
    {"category": "Average", "model": "Yehia-7B-preview", "value": 0.6568},
    {"category": "Average", "model": "Qwen2-7B-Instruct", "value": 0.6361},
    {"category": "Average", "model": "Falcon-Arabic-7B-Instruct", "value": 0.683}
]
{{< /barplot_vertical >}}

كما تظهر نتائج الرسوم البيانية، فإن Falcon-Arabic Instruct يتصدر المجموعة، متفوقة على جميع نماذج اللغة العربية الأخرى في فئتها وحجمها وأكبر منها بشكل ملحوظ عبر عدة معايير. يُظهر النموذج أداءً قوياً في اتباع الإرشادات والحوار المفتوح، واضعًا معيارًا جديدًا للذكاء الاصطناعي الحواري باللغة العربية.

### أداء نماذج المحادثة عبر معايير التقييم

{{< barplot_vertical id="chat-detailed" highlight="Falcon-Arabic-7B-Instruct" ymin="0.3" ymax="0.95" ylabel="Score %" >}}
[
    {"category": "ALGhafa", "model": "aya-expanse-32b", "value": 0.7761},
    {"category": "ALGhafa", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.7484000000000001},
    {"category": "ALGhafa", "model": "ALLaM-7B-Instruct-preview", "value": 0.6949},
    {"category": "ALGhafa", "model": "Yehia-7B-preview", "value": 0.7081000000000001},
    {"category": "ALGhafa", "model": "Qwen2-7B-Instruct", "value": 0.7323999999999999},
    {"category": "ALGhafa", "model": "Falcon-Arabic-7B-Instruct", "value": 0.7237},
    {"category": "ArabicMMLU", "model": "aya-expanse-32b", "value": 0.6063000000000001},
    {"category": "ArabicMMLU", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.5934},
    {"category": "ArabicMMLU", "model": "ALLaM-7B-Instruct-preview", "value": 0.649},
    {"category": "ArabicMMLU", "model": "Yehia-7B-preview", "value": 0.649},
    {"category": "ArabicMMLU", "model": "Qwen2-7B-Instruct", "value": 0.6001},
    {"category": "ArabicMMLU", "model": "Falcon-Arabic-7B-Instruct", "value": 0.6827},
    {"category": "Exams", "model": "aya-expanse-32b", "value": 0.5102},
    {"category": "Exams", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.6498999999999999},
    {"category": "Exams", "model": "ALLaM-7B-Instruct-preview", "value": 0.5158},
    {"category": "Exams", "model": "Yehia-7B-preview", "value": 0.5214},
    {"category": "Exams", "model": "Qwen2-7B-Instruct", "value": 0.473},
    {"category": "Exams", "model": "Falcon-Arabic-7B-Instruct", "value": 0.5345},
    {"category": "MadinahQA", "model": "aya-expanse-32b", "value": 0.5345},
    {"category": "MadinahQA", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.6384000000000001},
    {"category": "MadinahQA", "model": "ALLaM-7B-Instruct-preview", "value": 0.5424},
    {"category": "MadinahQA", "model": "Yehia-7B-preview", "value": 0.5437},
    {"category": "MadinahQA", "model": "Qwen2-7B-Instruct", "value": 0.595},
    {"category": "MadinahQA", "model": "Falcon-Arabic-7B-Instruct", "value": 0.7363},
    {"category": "AraTrust", "model": "aya-expanse-32b", "value": 0.89},
    {"category": "AraTrust", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.8047},
    {"category": "AraTrust", "model": "ALLaM-7B-Instruct-preview", "value": 0.8693000000000001},
    {"category": "AraTrust", "model": "Yehia-7B-preview", "value": 0.8748999999999999},
    {"category": "AraTrust", "model": "Qwen2-7B-Instruct", "value": 0.8277},
    {"category": "AraTrust", "model": "Falcon-Arabic-7B-Instruct", "value": 0.8262},
    {"category": "ALRAGE", "model": "aya-expanse-32b", "value": 0.7964},
    {"category": "ALRAGE", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.759},
    {"category": "ALRAGE", "model": "ALLaM-7B-Instruct-preview", "value": 0.7681},
    {"category": "ALRAGE", "model": "Yehia-7B-preview", "value": 0.7664},
    {"category": "ALRAGE", "model": "Qwen2-7B-Instruct", "value": 0.7112999999999999},
    {"category": "ALRAGE", "model": "Falcon-Arabic-7B-Instruct", "value": 0.7226},
    {"category": "ArbMMLU-HT", "model": "aya-expanse-32b", "value": 0.5886},
    {"category": "ArbMMLU-HT", "model": "c4ai-command-r7b-arabic-02-2025", "value": 0.5014},
    {"category": "ArbMMLU-HT", "model": "ALLaM-7B-Instruct-preview", "value": 0.5281},
    {"category": "ArbMMLU-HT", "model": "Yehia-7B-preview", "value": 0.534},
    {"category": "ArbMMLU-HT", "model": "Qwen2-7B-Instruct", "value": 0.513},
    {"category": "ArbMMLU-HT", "model": "Falcon-Arabic-7B-Instruct", "value": 0.5547}
]
{{< /barplot_vertical >}}


### جدول مقارنة نماذج المحادثة

<!-- <details>
<summary class="bold"> Detailed results: </summary> -->

{{< rawhtml >}}<div class="custom-table"> {{< /rawhtml >}}
| Model                           |     Average |  ALGhafa |   ALRAGE |   AraTrust |   ArabicMMLU |   ArbMMLU-HT |   Exams |   MadinahQA |
|--------------------------------|----------|---------|-----------|-------------|-------------|--------|------------|-------|
| aya-expanse-32b                 | 67.17 |    <u>77.61 |   <u>79.64 |     <u>89.00 |       60.63 |       <u>58.86 |  51.02 |      53.45 |
| c4ai-command-r7b-arabic-02-2025 | 67.07 |    74.84 |   75.90 |     80.47 |       59.34 |       50.14 | <u>64.99 |      63.84 |
| ALLaM-7B-Instruct-preview       | 65.25 |    69.49 |   76.81 |     86.93 |       64.90 |       52.81 |  51.58 |      54.24 |
| Yehia-7B-preview                | 65.68 |    70.81 |   76.64 |     87.49 |       64.90 |       53.40 |  52.14 |      54.37 |
| Qwen2-7B-Instruct               | 63.61 |    73.24 |   71.13 |     82.77 |       60.01 |       51.30 |  47.30 |      59.50 |
| **Falcon-Arabic-7B-Instruct**       | <u>68.30 |    72.37 |   72.26 |     82.62 |       <u>68.27 |       55.47 |  53.45 |      <u>73.63 |
{{< rawhtml >}}</div> {{< /rawhtml >}}
<!-- </details> -->

<!-- ## 🔓 فتح إمكانات الذكاء الاصطناعي باللغة العربية -->
## 🔓 إطلاق العنان لإمكانات الذكاء الاصطناعي العربي

يتحدى Falcon-Arabic المعايير فيما يتعلق بنماذج اللغة العربية. رغم أنه 7 مليار معامل، فإنه يقدم أداءً قياسياً يتفوق على النماذج المماثلة في الحجم وحتى تلك الأكبر بعدة مرات عبر مؤشرات أساسية مثل MMLU العربي، ومدينة QA، وأرثوث. يجمع بين الطلاقة في اللغة العربية القياسية الحديثة والفهم القوي للهجات الإقليمية والقدرات الاستنباطية والمتعددة اللغات، مما يجعله مثاليًا لمجموعة واسعة من التطبيقات: بدءًا من روبوتات الدردشة العربية أولاً وأدوات تعليمية لإنشاء المحتوى ومساعدة الكود وفهم المستندات. 

لإعطائك فكرة عملية عما يمكن أن يفعله Falcon-Arabic ، قمنا ببناء عرض بسيط يُظهر قدراته في "الترجمة" رغم أن النموذج لم يتم ضبطه خصيصًا لهذا الغرض. تعمل الأداة بالكامل باستخدام "Falcon-3B-Arabic-Instruct"، والنتائج ممتازة عبر مختلف اتجاهات الترجمة. يمكنك تجربتها بنفسك من خلال العرض التجريبي المُشار إليه أدناه. لقد استخدمنا نفس الإعداد لترجمة هذا المنشور بالمدونة إلى اللغة العربية للجمهور الناطق بها 🚀. وإذا كنت ترغب في استكشاف المزيد ، فإننا نوفر أيضًا منصة تمكنك من التفاعل مع Falcon-Arabic Instruct وتجربة أدائه عبر مهام مختلفة ✨.

{{< rawhtml >}}

<iframe
  src="https://tiiuae-falcon-arabic-translation-demo.hf.space/?__theme=light"
  frameborder="0"
  width="100%"
  height="300px"
  allow="accelerometer; camera; microphone; encrypted-media"
></iframe>
{{< /rawhtml >}}
<div style="
  display: flex;
  flex-wrap: wrap;
  gap: 0.5rem;
  margin: 1rem 0;
  justify-content: center;
">
  <a href="https://chat.falconllm.tii.ae" target="_blank" style="
    flex: 1 1 200px;
    background-color: #f5f0ff;
    border: none;
    border-left: 4px solid #800080;
    outline: none;
    padding: 0.75rem;
    text-align: center;
    font-weight: 600;
    text-decoration: none;
    color: inherit;
  ">
    🔗 <span style="color: #800080; text-decoration: underline;">اختبر النموذج</span>
  </a>
  <a href="https://huggingface.co/collections/tiiuae/falcon-arabic-682cd54f8560f4baf57641d7" target="_blank" style="
    flex: 1 1 200px;
    background-color: #f5f0ff;
    border: none;
    border-left: 4px solid #800080;
    outline: none;
    padding: 0.75rem;
    text-align: center;
    font-weight: 600;
    text-decoration: none;
    color: inherit;
  ">
    📊 <span style="color: #800080; text-decoration: underline;">عرض المجموعات والدرجات</span>
  </a>
</div>

## ⚠️ القيود
مثل جميع النماذج اللغوية الضخمة، يرث Falcon-Arabic بعض القيود الشائعة. وتشمل هذه أحيانًا "الهلاوس" (إنتاج ردود معقولة ولكنها خاطئة)، وحساسية كيفية صياغة المطالبات، وأداء متغير عبر سياقات طويلة جداً. وعلى الرغم من تصميم Falcon-Arabic لتخفيف هذه القضايا خصوصًا للمهام المتعلقة باللغة العربية، يجب على المستخدمين تطبيق تفكير نقدي عند تفسير النتائج، وخاصة في الحالات الحساسة للأداء العالي أو الحساسة للحقائق.


## الاستشهاد
إذا وجدت هذا العمل مفيدًا لبحثك أو مشاريعك، يرجى إضافة الاقتباس عنه.

```latex
@misc{falcon-arabic,
    title = {Falcon-Arabic: A Breakthrough in Arabic Language Models},
    author = {Falcon-LLM Team},
    month = {May},
    url = {https://falcon-lm.github.io/blog/falcon-arabic},
    year = {2025}
}
```

</div>